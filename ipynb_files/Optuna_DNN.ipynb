{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(8888)\n",
    "torch.manual_seed(8888)\n",
    "np.random.seed(8888)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', DEVICE)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOF ID</th>\n",
       "      <th>name</th>\n",
       "      <th>topology</th>\n",
       "      <th>First nodular symmetry code</th>\n",
       "      <th>First nodular character</th>\n",
       "      <th>First nodular ID</th>\n",
       "      <th>Second nodular symmetry code</th>\n",
       "      <th>Second nodular character</th>\n",
       "      <th>Second nodular ID</th>\n",
       "      <th>Connecting building block ID</th>\n",
       "      <th>...</th>\n",
       "      <th>D_func-S-0-all</th>\n",
       "      <th>D_func-S-1-all</th>\n",
       "      <th>D_func-S-2-all</th>\n",
       "      <th>D_func-S-3-all</th>\n",
       "      <th>D_func-alpha-0-all</th>\n",
       "      <th>D_func-alpha-1-all</th>\n",
       "      <th>D_func-alpha-2-all</th>\n",
       "      <th>D_func-alpha-3-all</th>\n",
       "      <th>bulk</th>\n",
       "      <th>shear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>acs_sym_7_mc_4_L_12</td>\n",
       "      <td>acs</td>\n",
       "      <td>7</td>\n",
       "      <td>metaliic</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>metallic</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.128650</td>\n",
       "      <td>11.231780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>acs_sym_7_mc_4_L_13</td>\n",
       "      <td>acs</td>\n",
       "      <td>7</td>\n",
       "      <td>metaliic</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>metallic</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.759740</td>\n",
       "      <td>11.627400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>acs_sym_7_mc_4_L_20</td>\n",
       "      <td>acs</td>\n",
       "      <td>7</td>\n",
       "      <td>metaliic</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>metallic</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.911607</td>\n",
       "      <td>5.467771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>acs_sym_7_mc_4_L_24</td>\n",
       "      <td>acs</td>\n",
       "      <td>7</td>\n",
       "      <td>metaliic</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>metallic</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.867950</td>\n",
       "      <td>4.384087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>acs_sym_7_mc_4_L_26</td>\n",
       "      <td>acs</td>\n",
       "      <td>7</td>\n",
       "      <td>metaliic</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>metallic</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>7.366024</td>\n",
       "      <td>5.053149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MOF ID                 name topology  First nodular symmetry code  \\\n",
       "0       3  acs_sym_7_mc_4_L_12      acs                            7   \n",
       "1       4  acs_sym_7_mc_4_L_13      acs                            7   \n",
       "2      12  acs_sym_7_mc_4_L_20      acs                            7   \n",
       "3      16  acs_sym_7_mc_4_L_24      acs                            7   \n",
       "4      18  acs_sym_7_mc_4_L_26      acs                            7   \n",
       "\n",
       "  First nodular character  First nodular ID  Second nodular symmetry code  \\\n",
       "0                metaliic                 4                             7   \n",
       "1                metaliic                 4                             7   \n",
       "2                metaliic                 4                             7   \n",
       "3                metaliic                 4                             7   \n",
       "4                metaliic                 4                             7   \n",
       "\n",
       "  Second nodular character  Second nodular ID  Connecting building block ID  \\\n",
       "0                 metallic                  4                            12   \n",
       "1                 metallic                  4                            13   \n",
       "2                 metallic                  4                            20   \n",
       "3                 metallic                  4                            24   \n",
       "4                 metallic                  4                            26   \n",
       "\n",
       "   ...  D_func-S-0-all  D_func-S-1-all  D_func-S-2-all  D_func-S-3-all  \\\n",
       "0  ...             0.0            0.00            0.00            0.00   \n",
       "1  ...             0.0           -0.02           -0.04            0.02   \n",
       "2  ...             0.0            0.00            0.00            0.00   \n",
       "3  ...             0.0            0.00            0.00            0.00   \n",
       "4  ...             0.0           -0.02           -0.04            0.00   \n",
       "\n",
       "   D_func-alpha-0-all  D_func-alpha-1-all  D_func-alpha-2-all  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                -3.9                -7.8   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                -3.9                -7.8   \n",
       "\n",
       "   D_func-alpha-3-all       bulk      shear  \n",
       "0                 0.0  14.128650  11.231780  \n",
       "1                 0.3  14.759740  11.627400  \n",
       "2                 0.0   8.911607   5.467771  \n",
       "3                 0.0   6.867950   4.384087  \n",
       "4                -1.8   7.366024   5.053149  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pprint\n",
    "import yaml\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from torchmetrics import R2Score\n",
    "toacco_geo = pd.read_csv(\"feature/toacco_geo2_mit_order.csv\")\n",
    "toacco_geo_chem = pd.read_csv(\"feature/toacco_geo_chem_erase_mit_order.csv\")\n",
    "toacco_geo = toacco_geo.iloc[:,2:]\n",
    "toacco_geo_chem = toacco_geo_chem.iloc[:,2:]\n",
    "# define the data\n",
    "data = toacco_geo_chem\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10, random_state = 42)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometric = ['Di', 'Df', 'Dif', 'rho', 'VSA','GSA', 'VPOV', 'GPOV', 'POAV_vol_frac', 'PONAV_vol_frac', 'GPOAV','GPONAV', 'POAV', 'PONAV']\n",
    "RAC = ['f-chi-0-all', 'f-chi-1-all', 'f-chi-2-all',\n",
    "       'f-chi-3-all', 'f-Z-0-all', 'f-Z-1-all', 'f-Z-2-all', 'f-Z-3-all',\n",
    "       'f-I-0-all', 'f-I-1-all', 'f-I-2-all', 'f-I-3-all', 'f-T-0-all',\n",
    "       'f-T-1-all', 'f-T-2-all', 'f-T-3-all', 'f-S-0-all', 'f-S-1-all',\n",
    "       'f-S-2-all', 'f-S-3-all', 'mc-chi-0-all', 'mc-chi-1-all',\n",
    "       'mc-chi-2-all', 'mc-chi-3-all', 'mc-Z-0-all', 'mc-Z-1-all',\n",
    "       'mc-Z-2-all', 'mc-Z-3-all', 'mc-I-0-all', 'mc-I-1-all', 'mc-I-2-all',\n",
    "       'mc-I-3-all', 'mc-T-0-all', 'mc-T-1-all', 'mc-T-2-all', 'mc-T-3-all',\n",
    "       'mc-S-0-all', 'mc-S-1-all', 'mc-S-2-all', 'mc-S-3-all',\n",
    "       'D_mc-chi-0-all', 'D_mc-chi-1-all', 'D_mc-chi-2-all', 'D_mc-chi-3-all',\n",
    "       'D_mc-Z-0-all', 'D_mc-Z-1-all', 'D_mc-Z-2-all', 'D_mc-Z-3-all',\n",
    "       'D_mc-I-0-all', 'D_mc-I-1-all', 'D_mc-I-2-all', 'D_mc-I-3-all',\n",
    "       'D_mc-T-0-all', 'D_mc-T-1-all', 'D_mc-T-2-all', 'D_mc-T-3-all',\n",
    "       'D_mc-S-0-all', 'D_mc-S-1-all', 'D_mc-S-2-all', 'D_mc-S-3-all',\n",
    "       'f-lig-chi-0', 'f-lig-chi-1', 'f-lig-chi-2', 'f-lig-chi-3', 'f-lig-Z-0',\n",
    "       'f-lig-Z-1', 'f-lig-Z-2', 'f-lig-Z-3', 'f-lig-I-0', 'f-lig-I-1',\n",
    "       'f-lig-I-2', 'f-lig-I-3', 'f-lig-T-0', 'f-lig-T-1', 'f-lig-T-2',\n",
    "       'f-lig-T-3', 'f-lig-S-0', 'f-lig-S-1', 'f-lig-S-2', 'f-lig-S-3',\n",
    "       'lc-chi-0-all', 'lc-chi-1-all', 'lc-chi-2-all', 'lc-chi-3-all',\n",
    "       'lc-Z-0-all', 'lc-Z-1-all', 'lc-Z-2-all', 'lc-Z-3-all', 'lc-I-0-all',\n",
    "       'lc-I-1-all', 'lc-I-2-all', 'lc-I-3-all', 'lc-T-0-all', 'lc-T-1-all',\n",
    "       'lc-T-2-all', 'lc-T-3-all', 'lc-S-0-all', 'lc-S-1-all', 'lc-S-2-all',\n",
    "        'lc-S-3-all', 'lc-alpha-0-all', 'lc-alpha-1-all', 'lc-alpha-2-all',\n",
    "       'lc-alpha-3-all', 'D_lc-chi-0-all', 'D_lc-chi-1-all', 'D_lc-chi-2-all',\n",
    "       'D_lc-chi-3-all', 'D_lc-Z-0-all', 'D_lc-Z-1-all', 'D_lc-Z-2-all',\n",
    "       'D_lc-Z-3-all', 'D_lc-I-0-all', 'D_lc-I-1-all', 'D_lc-I-2-all',\n",
    "       'D_lc-I-3-all', 'D_lc-T-0-all', 'D_lc-T-1-all', 'D_lc-T-2-all',\n",
    "       'D_lc-T-3-all', 'D_lc-S-0-all', 'D_lc-S-1-all', 'D_lc-S-2-all',\n",
    "       'D_lc-S-3-all', 'D_lc-alpha-0-all', 'D_lc-alpha-1-all',\n",
    "       'D_lc-alpha-2-all', 'D_lc-alpha-3-all', 'func-chi-0-all',\n",
    "       'func-chi-1-all', 'func-chi-2-all', 'func-chi-3-all', 'func-Z-0-all',\n",
    "       'func-Z-1-all', 'func-Z-2-all', 'func-Z-3-all', 'func-I-0-all',\n",
    "       'func-I-1-all', 'func-I-2-all', 'func-I-3-all', 'func-T-0-all',\n",
    "       'func-T-1-all', 'func-T-2-all', 'func-T-3-all', 'func-S-0-all',\n",
    "       'func-S-1-all', 'func-S-2-all', 'func-S-3-all', 'func-alpha-0-all',\n",
    "       'func-alpha-1-all', 'func-alpha-2-all', 'func-alpha-3-all',\n",
    "       'D_func-chi-0-all', 'D_func-chi-1-all', 'D_func-chi-2-all',\n",
    "       'D_func-chi-3-all', 'D_func-Z-0-all', 'D_func-Z-1-all',\n",
    "       'D_func-Z-2-all', 'D_func-Z-3-all', 'D_func-I-0-all', 'D_func-I-1-all',\n",
    "       'D_func-I-2-all', 'D_func-I-3-all', 'D_func-T-0-all', 'D_func-T-1-all',\n",
    "       'D_func-T-2-all', 'D_func-T-3-all', 'D_func-S-0-all', 'D_func-S-1-all',\n",
    "       'D_func-S-2-all', 'D_func-S-3-all', 'D_func-alpha-0-all',\n",
    "       'D_func-alpha-1-all', 'D_func-alpha-2-all', 'D_func-alpha-3-all']\n",
    "property_ = [\"bulk\"]\n",
    "## define the domain\n",
    "geo = geometric + property_\n",
    "RAC_geo = geometric + RAC + property_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "class mofdata(Dataset):\n",
    "    \n",
    "    def __init__(self,df,property_,features):\n",
    "        self.property_ = df[property_].values.tolist()\n",
    "        self.features = scaler.fit_transform(df[features].values).tolist()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.property_)\n",
    "        \n",
    "    def get_batch_property(self,idx):\n",
    "        return np.array(self.property_[idx])\n",
    "        \n",
    "    def get_batch_features(self,idx):\n",
    "        return np.array(self.features[idx])\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        batch_features = torch.tensor(self.get_batch_features(idx),dtype = torch.float)\n",
    "        batch_property = torch.tensor(self.get_batch_property(idx),dtype = torch.float)\n",
    "        \n",
    "        return batch_features,batch_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 14])\n",
      "torch.Size([32, 1])\n",
      "1973\n",
      "987\n",
      "0\n",
      "1973\n",
      "987\n",
      "1\n",
      "1974\n",
      "986\n",
      "2\n",
      "2960\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 3, shuffle = True)\n",
    "'''\n",
    "please define your features in here\n",
    "'''\n",
    "total = mofdata(data,property_,geometric)\n",
    "\n",
    "\n",
    "\n",
    "total_loader = torch.utils.data.DataLoader(total,batch_size=32,shuffle=True)\n",
    "for i, (data_x,data_y) in enumerate(total_loader):\n",
    "   if i ==0: \n",
    "    print(data_x.shape)\n",
    "    print(data_y.shape)\n",
    "    break\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(total)):\n",
    "    print(len(train_idx))\n",
    "    print(len(val_idx))\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    \n",
    "    print(fold)\n",
    "print(len(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.9954],\n",
      "        [ 2.3826],\n",
      "        [ 1.0323],\n",
      "        [ 5.2610],\n",
      "        [ 0.5304],\n",
      "        [ 5.1938],\n",
      "        [ 2.2296],\n",
      "        [ 0.3924],\n",
      "        [14.4174],\n",
      "        [ 3.3116],\n",
      "        [ 0.3508],\n",
      "        [ 2.9189],\n",
      "        [ 2.8823],\n",
      "        [ 1.6282],\n",
      "        [ 7.7763],\n",
      "        [ 9.8922],\n",
      "        [ 3.1457],\n",
      "        [ 3.0399],\n",
      "        [ 5.2105],\n",
      "        [12.0392],\n",
      "        [ 2.7658],\n",
      "        [ 5.0973],\n",
      "        [ 5.2768],\n",
      "        [ 2.1316],\n",
      "        [ 2.8034],\n",
      "        [ 2.8183],\n",
      "        [ 3.2147],\n",
      "        [ 8.7848],\n",
      "        [ 8.9193],\n",
      "        [ 6.1438],\n",
      "        [ 4.9205],\n",
      "        [ 2.6578]])\n",
      "tensor([[ 2.4065],\n",
      "        [ 0.2654],\n",
      "        [14.6528],\n",
      "        [ 7.4105],\n",
      "        [ 2.0427],\n",
      "        [15.8726],\n",
      "        [ 3.7077],\n",
      "        [ 3.6722],\n",
      "        [17.4804],\n",
      "        [ 2.1710],\n",
      "        [ 5.7088],\n",
      "        [ 3.2248],\n",
      "        [47.3727],\n",
      "        [ 8.1558],\n",
      "        [ 2.4618],\n",
      "        [ 1.0704],\n",
      "        [ 9.5141],\n",
      "        [ 6.4779],\n",
      "        [ 6.0311],\n",
      "        [17.1871],\n",
      "        [ 0.7190],\n",
      "        [ 1.6268],\n",
      "        [ 2.2018],\n",
      "        [ 6.1625],\n",
      "        [ 3.9570],\n",
      "        [ 8.0957],\n",
      "        [ 0.8440],\n",
      "        [ 7.3469],\n",
      "        [10.8487],\n",
      "        [ 2.0773],\n",
      "        [ 2.8164],\n",
      "        [10.8718]])\n",
      "tensor([[36.0434],\n",
      "        [ 3.7566],\n",
      "        [ 2.9156],\n",
      "        [ 1.6863],\n",
      "        [ 2.6370],\n",
      "        [21.4782],\n",
      "        [ 4.6828],\n",
      "        [ 1.5270],\n",
      "        [ 1.5263],\n",
      "        [ 2.0103],\n",
      "        [14.2895],\n",
      "        [ 4.3529],\n",
      "        [ 5.2315],\n",
      "        [ 2.0325],\n",
      "        [ 1.8911],\n",
      "        [ 4.8057],\n",
      "        [ 1.9703],\n",
      "        [ 2.9078],\n",
      "        [ 9.3400],\n",
      "        [ 3.1499],\n",
      "        [ 6.4698],\n",
      "        [41.2426],\n",
      "        [ 2.9363],\n",
      "        [ 5.8995],\n",
      "        [ 0.9843],\n",
      "        [ 3.8579],\n",
      "        [ 7.0804],\n",
      "        [ 2.1823],\n",
      "        [ 2.1734],\n",
      "        [ 8.3298],\n",
      "        [ 6.5823],\n",
      "        [ 0.7073]])\n",
      "tensor([[ 3.7937],\n",
      "        [ 1.0222],\n",
      "        [ 3.5757],\n",
      "        [11.2320],\n",
      "        [ 1.9082],\n",
      "        [13.4348],\n",
      "        [ 2.2128],\n",
      "        [10.8713],\n",
      "        [ 5.6062],\n",
      "        [ 4.5245],\n",
      "        [ 1.5292],\n",
      "        [ 0.6228],\n",
      "        [12.1553],\n",
      "        [ 2.7866],\n",
      "        [18.6574],\n",
      "        [12.6928],\n",
      "        [ 2.9581],\n",
      "        [15.0990],\n",
      "        [ 2.3697],\n",
      "        [11.4677],\n",
      "        [ 3.2424],\n",
      "        [ 7.7611],\n",
      "        [ 3.9391],\n",
      "        [ 5.9897],\n",
      "        [ 6.2868],\n",
      "        [36.9393],\n",
      "        [17.2419],\n",
      "        [ 6.2435],\n",
      "        [ 9.7785],\n",
      "        [ 4.2136],\n",
      "        [ 1.1025],\n",
      "        [ 2.2184]])\n",
      "tensor([[26.7104],\n",
      "        [ 5.2335],\n",
      "        [ 8.6883],\n",
      "        [ 1.7686],\n",
      "        [14.8224],\n",
      "        [ 4.1421],\n",
      "        [ 2.7577],\n",
      "        [ 1.6750],\n",
      "        [ 0.4046],\n",
      "        [51.3835],\n",
      "        [ 4.3538],\n",
      "        [ 2.3587],\n",
      "        [ 3.4956],\n",
      "        [18.1265],\n",
      "        [ 3.7883],\n",
      "        [ 5.1562],\n",
      "        [12.0343],\n",
      "        [15.7839],\n",
      "        [ 2.6180],\n",
      "        [12.6311],\n",
      "        [ 9.8580],\n",
      "        [ 4.4599],\n",
      "        [11.4034],\n",
      "        [ 1.5290],\n",
      "        [ 0.4932],\n",
      "        [14.8251],\n",
      "        [ 4.3736],\n",
      "        [ 8.0942],\n",
      "        [ 1.6551],\n",
      "        [ 4.1463],\n",
      "        [ 2.0041],\n",
      "        [ 1.8614]])\n",
      "tensor([[ 5.8850],\n",
      "        [ 3.3723],\n",
      "        [ 7.1743],\n",
      "        [ 0.3107],\n",
      "        [35.1186],\n",
      "        [ 4.0438],\n",
      "        [21.9218],\n",
      "        [ 2.0437],\n",
      "        [ 0.8618],\n",
      "        [ 3.5858],\n",
      "        [ 2.3230],\n",
      "        [ 1.0015],\n",
      "        [ 7.0276],\n",
      "        [ 2.7185],\n",
      "        [ 8.0538],\n",
      "        [ 8.1138],\n",
      "        [ 1.9099],\n",
      "        [ 0.9407],\n",
      "        [ 2.2959],\n",
      "        [14.4908],\n",
      "        [ 9.9828],\n",
      "        [ 7.0082],\n",
      "        [ 1.5543],\n",
      "        [ 4.2095],\n",
      "        [ 1.9731],\n",
      "        [17.8960],\n",
      "        [ 6.7276],\n",
      "        [ 4.6002],\n",
      "        [ 2.4880],\n",
      "        [ 6.8993],\n",
      "        [ 1.2319],\n",
      "        [ 1.7251]])\n",
      "tensor([[ 3.1522],\n",
      "        [10.9348],\n",
      "        [ 5.7713],\n",
      "        [ 3.6864],\n",
      "        [ 0.7026],\n",
      "        [11.4317],\n",
      "        [ 2.8098],\n",
      "        [21.2875],\n",
      "        [ 2.0435],\n",
      "        [ 1.7852],\n",
      "        [ 1.0102],\n",
      "        [12.0075],\n",
      "        [ 1.8939],\n",
      "        [ 1.7869],\n",
      "        [15.0113],\n",
      "        [ 1.5997],\n",
      "        [ 3.8441],\n",
      "        [ 5.0918],\n",
      "        [ 1.7042],\n",
      "        [ 1.7584],\n",
      "        [ 1.3854],\n",
      "        [10.6158],\n",
      "        [ 4.5918],\n",
      "        [ 6.5418],\n",
      "        [ 1.7956],\n",
      "        [ 0.6884],\n",
      "        [ 4.6042],\n",
      "        [ 3.6114],\n",
      "        [ 3.5346],\n",
      "        [ 6.2267],\n",
      "        [ 5.0177],\n",
      "        [37.7510]])\n",
      "tensor([[ 0.4075],\n",
      "        [ 2.6317],\n",
      "        [13.8407],\n",
      "        [ 7.7344],\n",
      "        [ 1.7119],\n",
      "        [ 1.3440],\n",
      "        [ 3.6320],\n",
      "        [ 5.7928],\n",
      "        [ 9.7038],\n",
      "        [ 5.1689],\n",
      "        [ 6.4357],\n",
      "        [ 1.1410],\n",
      "        [14.9640],\n",
      "        [ 1.1635],\n",
      "        [ 2.7727],\n",
      "        [ 7.9998],\n",
      "        [ 3.1265],\n",
      "        [10.9893],\n",
      "        [ 6.3255],\n",
      "        [ 6.4675],\n",
      "        [ 1.3382],\n",
      "        [ 4.5904],\n",
      "        [ 0.6766],\n",
      "        [ 3.3382],\n",
      "        [ 1.7477],\n",
      "        [ 5.3826],\n",
      "        [ 7.3285],\n",
      "        [ 2.8947],\n",
      "        [ 2.6404],\n",
      "        [ 3.3412],\n",
      "        [ 1.9071],\n",
      "        [ 5.9235]])\n",
      "tensor([[12.0948],\n",
      "        [ 2.1879],\n",
      "        [ 4.4441],\n",
      "        [ 4.3188],\n",
      "        [ 4.5873],\n",
      "        [ 3.3780],\n",
      "        [ 0.5187],\n",
      "        [ 4.2793],\n",
      "        [ 7.9093],\n",
      "        [ 2.3252],\n",
      "        [ 4.0801],\n",
      "        [ 4.1786],\n",
      "        [ 5.7651],\n",
      "        [ 3.4065],\n",
      "        [ 0.8611],\n",
      "        [15.3384],\n",
      "        [ 1.1086],\n",
      "        [ 8.6632],\n",
      "        [ 2.9379],\n",
      "        [ 0.4992],\n",
      "        [ 1.9725],\n",
      "        [ 0.4636],\n",
      "        [ 8.6846],\n",
      "        [ 5.3720],\n",
      "        [ 2.5343],\n",
      "        [ 1.6213],\n",
      "        [ 3.6503],\n",
      "        [ 3.4403],\n",
      "        [15.0393],\n",
      "        [ 8.5646],\n",
      "        [ 9.8277],\n",
      "        [ 1.0513]])\n",
      "tensor([[ 4.1912],\n",
      "        [ 0.4488],\n",
      "        [19.5063],\n",
      "        [ 2.9415],\n",
      "        [ 4.5061],\n",
      "        [ 1.3595],\n",
      "        [ 2.9184],\n",
      "        [ 4.7061],\n",
      "        [ 9.1056],\n",
      "        [ 1.4752],\n",
      "        [ 3.0689],\n",
      "        [ 1.6644],\n",
      "        [ 0.9397],\n",
      "        [16.2404],\n",
      "        [13.0834],\n",
      "        [ 8.3449],\n",
      "        [21.2162],\n",
      "        [ 2.1036],\n",
      "        [ 2.3227],\n",
      "        [ 7.2977],\n",
      "        [ 4.6047],\n",
      "        [ 1.3214],\n",
      "        [ 7.4632],\n",
      "        [ 2.0999],\n",
      "        [11.8539],\n",
      "        [ 1.4672],\n",
      "        [ 4.6416],\n",
      "        [ 3.5097],\n",
      "        [ 3.7328],\n",
      "        [ 4.7558],\n",
      "        [ 9.0550],\n",
      "        [ 2.8076]])\n",
      "tensor([[ 1.1712],\n",
      "        [ 2.3007],\n",
      "        [ 1.0220],\n",
      "        [ 3.2484],\n",
      "        [70.0415],\n",
      "        [ 2.0933],\n",
      "        [ 5.0349],\n",
      "        [ 7.9182],\n",
      "        [ 1.3614],\n",
      "        [10.4990],\n",
      "        [ 6.3933],\n",
      "        [ 3.8390],\n",
      "        [25.9693],\n",
      "        [ 2.0965],\n",
      "        [ 2.3631],\n",
      "        [ 3.8423],\n",
      "        [ 2.6130],\n",
      "        [10.7970],\n",
      "        [10.6571],\n",
      "        [ 4.8462],\n",
      "        [12.5774],\n",
      "        [ 1.7797],\n",
      "        [15.9265],\n",
      "        [ 0.2504],\n",
      "        [ 0.9755],\n",
      "        [ 9.1510],\n",
      "        [ 9.0607],\n",
      "        [ 6.1363],\n",
      "        [ 6.9668],\n",
      "        [ 3.3778],\n",
      "        [ 5.6411],\n",
      "        [ 2.5150]])\n",
      "tensor([[ 7.4946],\n",
      "        [ 0.8149],\n",
      "        [ 3.0800],\n",
      "        [ 6.6540],\n",
      "        [21.4383],\n",
      "        [ 0.2646],\n",
      "        [ 2.7324],\n",
      "        [ 2.1005],\n",
      "        [ 2.6190],\n",
      "        [ 1.1028],\n",
      "        [ 0.5484],\n",
      "        [ 4.3296],\n",
      "        [ 8.1073],\n",
      "        [ 0.6563],\n",
      "        [ 6.8216],\n",
      "        [37.0555],\n",
      "        [ 1.1053],\n",
      "        [ 2.3740],\n",
      "        [ 3.4976],\n",
      "        [ 1.8955],\n",
      "        [ 1.2878],\n",
      "        [ 0.4547],\n",
      "        [ 8.9713],\n",
      "        [ 3.1574],\n",
      "        [ 4.2409],\n",
      "        [ 1.3114],\n",
      "        [ 8.8465],\n",
      "        [ 2.1316],\n",
      "        [ 1.2203],\n",
      "        [ 4.9776],\n",
      "        [ 2.2681],\n",
      "        [18.9790]])\n",
      "tensor([[ 0.9157],\n",
      "        [ 0.5624],\n",
      "        [ 2.0778],\n",
      "        [ 2.8497],\n",
      "        [ 3.7862],\n",
      "        [ 3.2438],\n",
      "        [ 3.5101],\n",
      "        [ 3.9687],\n",
      "        [ 3.7233],\n",
      "        [ 2.6069],\n",
      "        [ 0.7231],\n",
      "        [ 3.6773],\n",
      "        [ 4.1906],\n",
      "        [ 0.1676],\n",
      "        [ 6.8721],\n",
      "        [ 3.6870],\n",
      "        [ 3.5827],\n",
      "        [ 0.1951],\n",
      "        [ 0.9072],\n",
      "        [ 1.6665],\n",
      "        [ 4.4791],\n",
      "        [ 4.1995],\n",
      "        [ 5.6706],\n",
      "        [10.6212],\n",
      "        [13.4806],\n",
      "        [ 8.1122],\n",
      "        [12.5540],\n",
      "        [ 3.0952],\n",
      "        [ 4.9977],\n",
      "        [ 0.9814],\n",
      "        [ 3.4850],\n",
      "        [ 2.6305]])\n",
      "tensor([[ 3.0173],\n",
      "        [ 2.8140],\n",
      "        [ 3.9991],\n",
      "        [ 2.2401],\n",
      "        [ 0.9346],\n",
      "        [ 0.5208],\n",
      "        [ 0.6112],\n",
      "        [ 5.5407],\n",
      "        [ 1.2408],\n",
      "        [ 9.3258],\n",
      "        [ 2.9413],\n",
      "        [ 1.9801],\n",
      "        [ 2.1564],\n",
      "        [ 4.4313],\n",
      "        [ 0.9422],\n",
      "        [ 2.8254],\n",
      "        [ 3.4150],\n",
      "        [ 3.2481],\n",
      "        [ 3.3388],\n",
      "        [ 6.3643],\n",
      "        [ 2.4201],\n",
      "        [37.2846],\n",
      "        [ 4.2456],\n",
      "        [ 8.6115],\n",
      "        [ 1.0643],\n",
      "        [ 1.5334],\n",
      "        [ 0.4014],\n",
      "        [ 1.1674],\n",
      "        [12.3529],\n",
      "        [ 1.0018],\n",
      "        [ 3.2612],\n",
      "        [ 6.5285]])\n",
      "tensor([[ 1.2857],\n",
      "        [ 5.1832],\n",
      "        [ 0.4750],\n",
      "        [23.6961],\n",
      "        [ 3.9553],\n",
      "        [ 0.6164],\n",
      "        [ 1.0298],\n",
      "        [10.6222],\n",
      "        [ 2.7051],\n",
      "        [ 1.9074],\n",
      "        [ 4.9585],\n",
      "        [19.8353],\n",
      "        [ 4.8060],\n",
      "        [ 6.3092],\n",
      "        [ 2.5631],\n",
      "        [43.0286],\n",
      "        [12.0896],\n",
      "        [ 1.7808],\n",
      "        [ 3.6556],\n",
      "        [ 4.4614],\n",
      "        [20.0540],\n",
      "        [ 5.8293],\n",
      "        [ 9.9354],\n",
      "        [ 4.5831],\n",
      "        [13.6014],\n",
      "        [20.9240],\n",
      "        [ 0.5298],\n",
      "        [ 4.5170],\n",
      "        [ 6.4963],\n",
      "        [22.1334],\n",
      "        [ 1.5779],\n",
      "        [ 7.1224]])\n",
      "tensor([[21.3006],\n",
      "        [14.3645],\n",
      "        [ 5.4828],\n",
      "        [ 7.8025],\n",
      "        [ 7.3781],\n",
      "        [ 7.6836],\n",
      "        [ 1.2790],\n",
      "        [ 2.6791],\n",
      "        [ 8.6101],\n",
      "        [13.6953],\n",
      "        [ 0.0311],\n",
      "        [ 3.4270],\n",
      "        [16.0309],\n",
      "        [ 2.5263],\n",
      "        [ 5.4988],\n",
      "        [ 8.5321],\n",
      "        [ 6.5590],\n",
      "        [ 0.7033],\n",
      "        [ 1.7763],\n",
      "        [ 4.1278],\n",
      "        [ 4.1592],\n",
      "        [ 2.9769],\n",
      "        [12.1779],\n",
      "        [ 3.4288],\n",
      "        [ 5.9454],\n",
      "        [ 2.2128],\n",
      "        [ 3.7453],\n",
      "        [ 2.8189],\n",
      "        [ 4.1271],\n",
      "        [ 2.0189],\n",
      "        [ 2.7912],\n",
      "        [ 3.8195]])\n",
      "tensor([[ 5.9483],\n",
      "        [ 4.4601],\n",
      "        [ 1.5566],\n",
      "        [ 8.3670],\n",
      "        [ 0.6038],\n",
      "        [ 3.8139],\n",
      "        [ 3.3695],\n",
      "        [ 8.0184],\n",
      "        [ 2.1142],\n",
      "        [ 2.6516],\n",
      "        [ 5.2528],\n",
      "        [ 5.9992],\n",
      "        [12.2287],\n",
      "        [ 4.9643],\n",
      "        [ 1.8820],\n",
      "        [ 3.9343],\n",
      "        [ 1.1241],\n",
      "        [ 2.6331],\n",
      "        [11.3154],\n",
      "        [ 2.9521],\n",
      "        [ 0.6700],\n",
      "        [ 1.0950],\n",
      "        [ 3.1691],\n",
      "        [ 7.9973],\n",
      "        [ 2.4015],\n",
      "        [ 7.9996],\n",
      "        [15.8594],\n",
      "        [ 1.2749],\n",
      "        [ 5.8017],\n",
      "        [ 2.2181],\n",
      "        [ 8.1088],\n",
      "        [ 9.1890]])\n",
      "tensor([[ 2.2818],\n",
      "        [ 6.4917],\n",
      "        [ 4.4249],\n",
      "        [ 4.4884],\n",
      "        [25.3474],\n",
      "        [ 1.6428],\n",
      "        [ 8.8036],\n",
      "        [ 5.6526],\n",
      "        [ 2.6583],\n",
      "        [10.8252],\n",
      "        [ 6.6202],\n",
      "        [11.6770],\n",
      "        [ 2.9604],\n",
      "        [ 3.2852],\n",
      "        [19.8718],\n",
      "        [27.4163],\n",
      "        [ 4.4366],\n",
      "        [13.4783],\n",
      "        [ 5.0619],\n",
      "        [ 0.2898],\n",
      "        [ 2.3788],\n",
      "        [ 6.6247],\n",
      "        [ 7.0280],\n",
      "        [ 3.9478],\n",
      "        [11.4928],\n",
      "        [ 2.9986],\n",
      "        [ 0.8927],\n",
      "        [ 4.5897],\n",
      "        [16.7157],\n",
      "        [10.5406],\n",
      "        [ 4.9776],\n",
      "        [ 3.7302]])\n",
      "tensor([[ 4.6703],\n",
      "        [ 3.8063],\n",
      "        [ 2.2331],\n",
      "        [ 9.0479],\n",
      "        [ 2.7844],\n",
      "        [ 7.8399],\n",
      "        [ 2.9114],\n",
      "        [ 8.7245],\n",
      "        [ 6.7249],\n",
      "        [ 1.3771],\n",
      "        [ 1.5894],\n",
      "        [ 3.0207],\n",
      "        [ 3.7810],\n",
      "        [ 6.4309],\n",
      "        [ 9.1131],\n",
      "        [ 2.1978],\n",
      "        [ 0.4100],\n",
      "        [ 6.6190],\n",
      "        [ 5.4443],\n",
      "        [ 3.1981],\n",
      "        [16.5047],\n",
      "        [ 3.7530],\n",
      "        [ 1.8960],\n",
      "        [ 1.8454],\n",
      "        [ 2.5028],\n",
      "        [23.9512],\n",
      "        [ 1.0551],\n",
      "        [ 4.7346],\n",
      "        [ 7.1905],\n",
      "        [ 6.3128],\n",
      "        [ 6.2828],\n",
      "        [ 7.9612]])\n",
      "tensor([[ 0.8973],\n",
      "        [ 3.8610],\n",
      "        [ 0.3761],\n",
      "        [25.4394],\n",
      "        [ 6.3137],\n",
      "        [ 0.5461],\n",
      "        [10.3305],\n",
      "        [ 3.8356],\n",
      "        [ 3.5567],\n",
      "        [15.5375],\n",
      "        [ 0.7665],\n",
      "        [ 4.2133],\n",
      "        [ 2.9269],\n",
      "        [ 5.3421],\n",
      "        [17.6005],\n",
      "        [ 1.0164],\n",
      "        [ 1.0237],\n",
      "        [ 1.1437],\n",
      "        [ 3.3455],\n",
      "        [ 3.3646],\n",
      "        [ 3.7801],\n",
      "        [ 5.5310],\n",
      "        [ 2.4477],\n",
      "        [11.1865],\n",
      "        [13.4833],\n",
      "        [ 1.4552],\n",
      "        [10.4786],\n",
      "        [ 9.3785],\n",
      "        [ 4.2759],\n",
      "        [ 0.6302],\n",
      "        [ 0.8310],\n",
      "        [13.7309]])\n",
      "tensor([[ 3.8020],\n",
      "        [13.2091],\n",
      "        [18.1138],\n",
      "        [ 1.6842],\n",
      "        [12.8602],\n",
      "        [ 3.1144],\n",
      "        [ 3.2731],\n",
      "        [ 1.4425],\n",
      "        [ 2.5686],\n",
      "        [ 0.6278],\n",
      "        [ 5.2194],\n",
      "        [17.4356],\n",
      "        [ 3.8642],\n",
      "        [18.9851],\n",
      "        [ 0.6520],\n",
      "        [ 2.9321],\n",
      "        [14.4523],\n",
      "        [26.9979],\n",
      "        [38.9812],\n",
      "        [ 5.1899],\n",
      "        [18.1398],\n",
      "        [ 0.7379],\n",
      "        [ 0.8540],\n",
      "        [21.3076],\n",
      "        [16.5890],\n",
      "        [31.9681],\n",
      "        [ 1.4694],\n",
      "        [ 6.0269],\n",
      "        [ 1.7336],\n",
      "        [ 5.9428],\n",
      "        [ 5.4869],\n",
      "        [ 6.2923]])\n",
      "tensor([[ 2.8265],\n",
      "        [ 5.6730],\n",
      "        [ 8.7251],\n",
      "        [ 1.5839],\n",
      "        [ 3.1819],\n",
      "        [ 9.4382],\n",
      "        [ 1.2877],\n",
      "        [ 0.8353],\n",
      "        [ 7.4760],\n",
      "        [ 4.9151],\n",
      "        [17.6519],\n",
      "        [ 6.3071],\n",
      "        [13.1128],\n",
      "        [14.7597],\n",
      "        [ 5.6348],\n",
      "        [ 2.3015],\n",
      "        [14.6891],\n",
      "        [ 6.7049],\n",
      "        [ 3.0696],\n",
      "        [13.9888],\n",
      "        [24.3468],\n",
      "        [ 5.4968],\n",
      "        [ 0.9829],\n",
      "        [ 4.1203],\n",
      "        [ 3.7780],\n",
      "        [ 3.4404],\n",
      "        [ 4.3867],\n",
      "        [ 3.2234],\n",
      "        [ 2.9267],\n",
      "        [ 2.2420],\n",
      "        [ 1.7506],\n",
      "        [ 3.9959]])\n",
      "tensor([[ 7.7010],\n",
      "        [18.0851],\n",
      "        [ 8.3268],\n",
      "        [ 1.3857],\n",
      "        [ 0.4475],\n",
      "        [ 0.5173],\n",
      "        [ 1.8804],\n",
      "        [ 2.8657],\n",
      "        [ 5.8408],\n",
      "        [ 5.5371],\n",
      "        [ 7.4368],\n",
      "        [ 4.7883],\n",
      "        [ 8.5575],\n",
      "        [19.8599],\n",
      "        [ 3.6662],\n",
      "        [ 8.7541],\n",
      "        [ 0.8743],\n",
      "        [ 3.8657],\n",
      "        [ 5.4985],\n",
      "        [ 4.2662],\n",
      "        [ 1.6716],\n",
      "        [10.0217],\n",
      "        [10.6801],\n",
      "        [ 1.5928],\n",
      "        [ 1.3663],\n",
      "        [ 1.9917],\n",
      "        [ 8.3492],\n",
      "        [ 1.6337],\n",
      "        [ 2.4319],\n",
      "        [ 3.5753],\n",
      "        [ 0.6182],\n",
      "        [ 0.8196]])\n",
      "tensor([[ 3.1612],\n",
      "        [ 2.2170],\n",
      "        [ 7.8151],\n",
      "        [ 6.5216],\n",
      "        [12.4615],\n",
      "        [ 2.9383],\n",
      "        [ 2.6432],\n",
      "        [ 4.6918],\n",
      "        [ 1.0796],\n",
      "        [ 3.2853],\n",
      "        [ 8.1749],\n",
      "        [ 2.9482],\n",
      "        [ 8.7863],\n",
      "        [ 6.1916],\n",
      "        [ 4.3394],\n",
      "        [ 5.0654],\n",
      "        [ 2.3765],\n",
      "        [ 3.6814],\n",
      "        [ 3.1731],\n",
      "        [ 2.6028],\n",
      "        [ 0.3108],\n",
      "        [ 5.8379],\n",
      "        [12.3082],\n",
      "        [ 6.5705],\n",
      "        [ 5.8006],\n",
      "        [ 5.6401],\n",
      "        [ 0.6804],\n",
      "        [ 8.5382],\n",
      "        [ 2.4116],\n",
      "        [ 1.7217],\n",
      "        [ 6.1302],\n",
      "        [ 1.5767]])\n",
      "tensor([[ 0.2935],\n",
      "        [ 0.8474],\n",
      "        [ 5.5671],\n",
      "        [ 0.9080],\n",
      "        [ 0.4626],\n",
      "        [ 6.1630],\n",
      "        [ 2.1301],\n",
      "        [ 6.8337],\n",
      "        [ 2.6718],\n",
      "        [ 1.1672],\n",
      "        [ 4.3143],\n",
      "        [ 1.8253],\n",
      "        [ 8.9713],\n",
      "        [ 1.6599],\n",
      "        [ 2.7511],\n",
      "        [ 4.1007],\n",
      "        [ 1.6403],\n",
      "        [22.9258],\n",
      "        [ 7.9740],\n",
      "        [10.3919],\n",
      "        [ 1.3831],\n",
      "        [32.9455],\n",
      "        [ 1.7617],\n",
      "        [ 2.7075],\n",
      "        [ 2.6517],\n",
      "        [ 0.7461],\n",
      "        [ 4.5257],\n",
      "        [ 5.6017],\n",
      "        [ 5.5113],\n",
      "        [ 6.0397],\n",
      "        [ 6.0100],\n",
      "        [ 7.4153]])\n",
      "tensor([[ 4.7116],\n",
      "        [ 1.6526],\n",
      "        [ 4.0088],\n",
      "        [ 1.6657],\n",
      "        [ 2.1756],\n",
      "        [15.0121],\n",
      "        [ 1.7859],\n",
      "        [ 4.1745],\n",
      "        [16.9026],\n",
      "        [ 3.8861],\n",
      "        [ 1.0861],\n",
      "        [ 1.9136],\n",
      "        [ 5.2750],\n",
      "        [ 2.4144],\n",
      "        [ 3.9199],\n",
      "        [20.2087],\n",
      "        [ 1.0210],\n",
      "        [ 7.4511],\n",
      "        [ 3.7546],\n",
      "        [ 5.9020],\n",
      "        [ 5.7286],\n",
      "        [23.2688],\n",
      "        [25.7743],\n",
      "        [ 9.5337],\n",
      "        [ 5.7523],\n",
      "        [ 9.0592],\n",
      "        [ 2.2283],\n",
      "        [ 7.2168],\n",
      "        [ 5.3411],\n",
      "        [ 1.6816],\n",
      "        [ 8.3456],\n",
      "        [ 1.4875]])\n",
      "tensor([[ 3.3229],\n",
      "        [ 2.7509],\n",
      "        [ 1.3017],\n",
      "        [ 4.5112],\n",
      "        [ 1.9111],\n",
      "        [ 4.9231],\n",
      "        [ 3.8544],\n",
      "        [ 0.6497],\n",
      "        [ 3.2964],\n",
      "        [ 4.5199],\n",
      "        [ 6.5067],\n",
      "        [ 2.0825],\n",
      "        [10.8923],\n",
      "        [ 1.8765],\n",
      "        [ 2.4991],\n",
      "        [28.2738],\n",
      "        [ 8.5218],\n",
      "        [ 2.7762],\n",
      "        [ 4.4460],\n",
      "        [ 5.2123],\n",
      "        [ 8.2473],\n",
      "        [29.2653],\n",
      "        [ 0.9621],\n",
      "        [28.3325],\n",
      "        [ 4.0269],\n",
      "        [ 2.4455],\n",
      "        [ 0.2056],\n",
      "        [ 6.1207],\n",
      "        [ 0.2376],\n",
      "        [ 4.9022],\n",
      "        [ 8.7949],\n",
      "        [ 3.1721]])\n",
      "tensor([[ 3.6501],\n",
      "        [ 0.4983],\n",
      "        [ 1.8968],\n",
      "        [ 3.2451],\n",
      "        [22.6131],\n",
      "        [ 6.3890],\n",
      "        [ 4.0364],\n",
      "        [11.5699],\n",
      "        [ 1.2859],\n",
      "        [ 6.2514],\n",
      "        [17.5843],\n",
      "        [ 4.3027],\n",
      "        [ 4.0255],\n",
      "        [ 0.7955],\n",
      "        [ 4.2414],\n",
      "        [ 3.8861],\n",
      "        [ 4.7914],\n",
      "        [ 1.6874],\n",
      "        [ 8.5723],\n",
      "        [ 1.1346],\n",
      "        [ 0.6053],\n",
      "        [ 2.3189],\n",
      "        [ 6.4854],\n",
      "        [ 2.1417],\n",
      "        [ 0.2940],\n",
      "        [12.9309],\n",
      "        [18.1345],\n",
      "        [ 0.6876],\n",
      "        [15.7379],\n",
      "        [ 3.3764],\n",
      "        [ 5.6359],\n",
      "        [ 6.3700]])\n",
      "tensor([[ 0.7543],\n",
      "        [ 0.7576],\n",
      "        [ 1.0917],\n",
      "        [13.3883],\n",
      "        [10.5493],\n",
      "        [ 3.8704],\n",
      "        [14.4753],\n",
      "        [ 2.3803],\n",
      "        [ 1.3556],\n",
      "        [ 2.5825],\n",
      "        [ 1.3432],\n",
      "        [ 4.6942],\n",
      "        [ 3.4308],\n",
      "        [ 3.7395],\n",
      "        [ 1.9382],\n",
      "        [ 2.6812],\n",
      "        [ 4.2416],\n",
      "        [ 8.6768],\n",
      "        [ 2.8976],\n",
      "        [ 1.0627],\n",
      "        [ 1.5455],\n",
      "        [ 3.3707],\n",
      "        [ 3.4431],\n",
      "        [ 1.6629],\n",
      "        [ 2.4672],\n",
      "        [28.0735],\n",
      "        [ 1.5868],\n",
      "        [ 9.7121],\n",
      "        [ 8.1681],\n",
      "        [11.0707],\n",
      "        [ 0.2937],\n",
      "        [18.8135]])\n",
      "tensor([[ 5.4048],\n",
      "        [10.3348],\n",
      "        [ 1.9954],\n",
      "        [16.9748],\n",
      "        [ 5.2426],\n",
      "        [ 4.8574],\n",
      "        [ 0.4240],\n",
      "        [ 4.4785],\n",
      "        [ 1.7678],\n",
      "        [ 1.0079],\n",
      "        [ 2.5360],\n",
      "        [ 6.0617],\n",
      "        [18.1605],\n",
      "        [ 5.8501],\n",
      "        [31.9294],\n",
      "        [ 1.9044],\n",
      "        [ 1.6421],\n",
      "        [ 1.5265],\n",
      "        [13.1189],\n",
      "        [ 3.9266],\n",
      "        [ 0.7364],\n",
      "        [ 6.9237],\n",
      "        [ 6.2965],\n",
      "        [46.3081],\n",
      "        [ 3.4441],\n",
      "        [ 4.5545],\n",
      "        [ 1.9406],\n",
      "        [ 6.3469],\n",
      "        [ 1.2615],\n",
      "        [ 2.9864],\n",
      "        [ 0.2791],\n",
      "        [ 4.5668]])\n",
      "tensor([[ 2.1742],\n",
      "        [ 1.6082],\n",
      "        [ 2.1615],\n",
      "        [20.5455],\n",
      "        [ 1.3763],\n",
      "        [ 1.9105],\n",
      "        [ 2.4652],\n",
      "        [ 2.1134],\n",
      "        [17.2757],\n",
      "        [ 1.3028],\n",
      "        [ 0.8635],\n",
      "        [ 2.8039],\n",
      "        [ 2.4850],\n",
      "        [ 5.4618],\n",
      "        [ 8.5032],\n",
      "        [ 2.8255],\n",
      "        [ 3.7458],\n",
      "        [ 0.6428],\n",
      "        [ 7.2429],\n",
      "        [ 3.9421],\n",
      "        [ 5.7679],\n",
      "        [ 9.2150],\n",
      "        [19.5529],\n",
      "        [ 8.9967],\n",
      "        [ 4.6081],\n",
      "        [ 3.8601],\n",
      "        [ 2.2583],\n",
      "        [10.4516],\n",
      "        [ 0.4913],\n",
      "        [ 4.4542],\n",
      "        [ 1.0412],\n",
      "        [ 1.2670]])\n",
      "tensor([[ 0.4802],\n",
      "        [19.2891],\n",
      "        [ 1.6434],\n",
      "        [ 0.5058],\n",
      "        [ 5.3390],\n",
      "        [13.5662],\n",
      "        [ 8.6004],\n",
      "        [ 2.4113],\n",
      "        [ 2.6408],\n",
      "        [ 4.0376],\n",
      "        [ 2.3202],\n",
      "        [ 6.0299],\n",
      "        [ 0.3939],\n",
      "        [ 1.4727],\n",
      "        [ 4.7068],\n",
      "        [ 4.0765],\n",
      "        [ 3.4472],\n",
      "        [ 6.0409],\n",
      "        [11.6540],\n",
      "        [ 2.6183],\n",
      "        [ 0.2577],\n",
      "        [ 1.3372],\n",
      "        [ 7.7589],\n",
      "        [ 6.5459],\n",
      "        [ 5.2742],\n",
      "        [ 6.6942],\n",
      "        [ 1.6141],\n",
      "        [ 2.1381],\n",
      "        [25.7738],\n",
      "        [ 1.6048],\n",
      "        [ 3.7953],\n",
      "        [ 1.2003]])\n",
      "tensor([[ 6.2851],\n",
      "        [10.6615],\n",
      "        [ 3.9144],\n",
      "        [ 3.2381],\n",
      "        [13.2437],\n",
      "        [ 0.5301],\n",
      "        [11.2005],\n",
      "        [ 7.2413],\n",
      "        [ 0.8136],\n",
      "        [18.4035],\n",
      "        [15.1352],\n",
      "        [37.9498],\n",
      "        [ 1.1953],\n",
      "        [ 0.6978],\n",
      "        [ 2.8982],\n",
      "        [ 3.8691],\n",
      "        [14.7902],\n",
      "        [ 2.5089],\n",
      "        [ 0.9442],\n",
      "        [ 2.5923],\n",
      "        [ 1.3010],\n",
      "        [19.7763],\n",
      "        [ 1.1031],\n",
      "        [14.3613],\n",
      "        [16.9312],\n",
      "        [ 5.7675],\n",
      "        [ 5.0523],\n",
      "        [ 1.2652],\n",
      "        [ 3.8455],\n",
      "        [ 8.8517],\n",
      "        [ 1.7167],\n",
      "        [ 5.6796]])\n",
      "tensor([[22.2657],\n",
      "        [ 6.8007],\n",
      "        [ 5.8437],\n",
      "        [ 9.3842],\n",
      "        [11.5884],\n",
      "        [ 4.3880],\n",
      "        [ 3.6570],\n",
      "        [12.5676],\n",
      "        [14.9226],\n",
      "        [15.5083],\n",
      "        [ 2.1567],\n",
      "        [ 2.0383],\n",
      "        [ 1.3248],\n",
      "        [ 2.9948],\n",
      "        [ 5.3826],\n",
      "        [ 5.2889],\n",
      "        [ 4.5645],\n",
      "        [16.9996],\n",
      "        [ 1.9546],\n",
      "        [ 2.6299],\n",
      "        [10.4431],\n",
      "        [ 3.1122],\n",
      "        [ 6.1019],\n",
      "        [ 0.5227],\n",
      "        [ 1.4523],\n",
      "        [ 6.7157],\n",
      "        [ 2.6699],\n",
      "        [ 2.5202],\n",
      "        [ 8.6774],\n",
      "        [ 5.2336],\n",
      "        [21.4548],\n",
      "        [12.1997]])\n",
      "tensor([[ 4.6290],\n",
      "        [ 8.6545],\n",
      "        [ 5.0095],\n",
      "        [26.0204],\n",
      "        [ 4.1371],\n",
      "        [ 3.3150],\n",
      "        [ 9.5411],\n",
      "        [23.4932],\n",
      "        [ 3.0274],\n",
      "        [ 5.4311],\n",
      "        [ 2.6725],\n",
      "        [ 6.1628],\n",
      "        [ 1.3267],\n",
      "        [ 1.9209],\n",
      "        [ 4.9592],\n",
      "        [ 2.4407],\n",
      "        [10.5208],\n",
      "        [ 8.3271],\n",
      "        [ 3.3997],\n",
      "        [10.3775],\n",
      "        [ 0.3473],\n",
      "        [ 2.5612],\n",
      "        [ 4.8560],\n",
      "        [ 4.4224],\n",
      "        [ 8.7608],\n",
      "        [ 9.5953],\n",
      "        [ 3.8191],\n",
      "        [ 3.5700],\n",
      "        [ 2.3352],\n",
      "        [ 0.8124],\n",
      "        [14.5130],\n",
      "        [13.8593]])\n",
      "tensor([[ 1.9271],\n",
      "        [ 1.2027],\n",
      "        [ 1.5562],\n",
      "        [ 2.1947],\n",
      "        [22.6166],\n",
      "        [ 1.6518],\n",
      "        [ 4.2476],\n",
      "        [ 4.5605],\n",
      "        [ 1.9552],\n",
      "        [10.7776],\n",
      "        [ 3.5241],\n",
      "        [ 6.0690],\n",
      "        [14.4533],\n",
      "        [ 2.8962],\n",
      "        [ 7.8957],\n",
      "        [ 2.5953],\n",
      "        [ 0.9704],\n",
      "        [ 1.6285],\n",
      "        [10.1242],\n",
      "        [ 0.3635],\n",
      "        [ 4.8268],\n",
      "        [ 1.3428],\n",
      "        [ 4.1859],\n",
      "        [ 2.8362],\n",
      "        [ 6.8812],\n",
      "        [ 2.7668],\n",
      "        [17.4146],\n",
      "        [ 9.1064],\n",
      "        [42.4100],\n",
      "        [ 2.3194],\n",
      "        [ 0.5876],\n",
      "        [ 3.3939]])\n",
      "tensor([[ 2.0419],\n",
      "        [ 6.0717],\n",
      "        [ 5.2513],\n",
      "        [ 4.7709],\n",
      "        [ 8.8303],\n",
      "        [ 5.5951],\n",
      "        [ 6.4949],\n",
      "        [ 3.6098],\n",
      "        [ 0.4055],\n",
      "        [ 3.0905],\n",
      "        [ 1.3993],\n",
      "        [ 2.7910],\n",
      "        [ 2.4996],\n",
      "        [ 2.5746],\n",
      "        [ 2.1627],\n",
      "        [ 3.7762],\n",
      "        [ 2.8806],\n",
      "        [ 4.0511],\n",
      "        [ 4.5519],\n",
      "        [ 4.7707],\n",
      "        [ 3.5924],\n",
      "        [ 2.1217],\n",
      "        [ 6.5904],\n",
      "        [ 0.7681],\n",
      "        [12.4078],\n",
      "        [ 5.9940],\n",
      "        [24.8622],\n",
      "        [ 0.6094],\n",
      "        [ 5.7864],\n",
      "        [ 3.1176],\n",
      "        [ 4.6729],\n",
      "        [ 2.1245]])\n",
      "tensor([[ 1.3620],\n",
      "        [ 1.2667],\n",
      "        [ 1.4383],\n",
      "        [ 0.5948],\n",
      "        [13.3198],\n",
      "        [ 3.5978],\n",
      "        [ 0.8742],\n",
      "        [ 7.9456],\n",
      "        [13.8683],\n",
      "        [ 5.9692],\n",
      "        [ 8.9063],\n",
      "        [ 1.4502],\n",
      "        [ 0.8335],\n",
      "        [10.9875],\n",
      "        [37.3960],\n",
      "        [ 3.9308],\n",
      "        [24.3579],\n",
      "        [ 7.5458],\n",
      "        [13.4407],\n",
      "        [ 1.7509],\n",
      "        [ 4.4781],\n",
      "        [14.1699],\n",
      "        [ 6.0893],\n",
      "        [ 4.3358],\n",
      "        [17.2120],\n",
      "        [28.2471],\n",
      "        [ 2.9866],\n",
      "        [ 4.6285],\n",
      "        [ 0.9061],\n",
      "        [ 7.9596],\n",
      "        [16.3424],\n",
      "        [ 0.2066]])\n",
      "tensor([[12.0933],\n",
      "        [ 9.6013],\n",
      "        [ 1.9536],\n",
      "        [ 8.2766],\n",
      "        [ 0.5271],\n",
      "        [20.3734],\n",
      "        [ 3.2489],\n",
      "        [ 1.5354],\n",
      "        [ 0.6514],\n",
      "        [ 1.0977],\n",
      "        [ 4.6987],\n",
      "        [ 3.9241],\n",
      "        [28.9538],\n",
      "        [ 3.5435],\n",
      "        [ 0.7369],\n",
      "        [ 2.9472],\n",
      "        [ 4.9649],\n",
      "        [ 6.0141],\n",
      "        [ 3.2595],\n",
      "        [ 1.7580],\n",
      "        [ 8.7207],\n",
      "        [ 2.1678],\n",
      "        [ 2.8667],\n",
      "        [10.5857],\n",
      "        [ 7.4391],\n",
      "        [ 3.4456],\n",
      "        [ 5.1013],\n",
      "        [26.7623],\n",
      "        [ 2.9584],\n",
      "        [ 2.7623],\n",
      "        [ 0.6883],\n",
      "        [ 3.6894]])\n",
      "tensor([[ 1.9811],\n",
      "        [ 6.8679],\n",
      "        [ 3.4863],\n",
      "        [ 3.2676],\n",
      "        [13.3822],\n",
      "        [ 2.9575],\n",
      "        [ 5.0123],\n",
      "        [ 6.2934],\n",
      "        [15.8120],\n",
      "        [ 2.8738],\n",
      "        [ 0.6439],\n",
      "        [ 4.3789],\n",
      "        [ 3.0757],\n",
      "        [ 0.2944],\n",
      "        [ 0.7286],\n",
      "        [ 1.5182],\n",
      "        [ 6.2736],\n",
      "        [ 4.1756],\n",
      "        [ 1.2923],\n",
      "        [11.9636],\n",
      "        [ 3.5231],\n",
      "        [ 2.3244],\n",
      "        [ 5.7729],\n",
      "        [ 3.8877],\n",
      "        [ 1.4953],\n",
      "        [ 6.5994],\n",
      "        [ 4.6448],\n",
      "        [ 1.2670],\n",
      "        [ 3.0162],\n",
      "        [24.2170],\n",
      "        [ 4.9242],\n",
      "        [12.2884]])\n",
      "tensor([[ 0.3695],\n",
      "        [ 4.5121],\n",
      "        [12.3472],\n",
      "        [ 1.5230],\n",
      "        [ 2.7446],\n",
      "        [16.5623],\n",
      "        [ 9.5336],\n",
      "        [ 4.9164],\n",
      "        [ 0.3686],\n",
      "        [11.7011],\n",
      "        [19.7807],\n",
      "        [10.6703],\n",
      "        [ 3.5343],\n",
      "        [ 3.9579],\n",
      "        [ 3.9350],\n",
      "        [ 0.7159],\n",
      "        [10.9516],\n",
      "        [ 1.5049],\n",
      "        [ 2.2294],\n",
      "        [ 1.6481],\n",
      "        [ 1.8985],\n",
      "        [ 2.3838],\n",
      "        [ 5.6782],\n",
      "        [ 2.2097],\n",
      "        [ 0.3666],\n",
      "        [ 0.2830],\n",
      "        [ 0.3645],\n",
      "        [ 4.4335],\n",
      "        [ 6.6155],\n",
      "        [ 0.9554],\n",
      "        [12.1654],\n",
      "        [ 2.2702]])\n",
      "tensor([[ 3.1991],\n",
      "        [ 2.3990],\n",
      "        [14.4170],\n",
      "        [ 2.1817],\n",
      "        [ 7.8968],\n",
      "        [11.9613],\n",
      "        [ 1.2495],\n",
      "        [ 8.1002],\n",
      "        [ 1.2716],\n",
      "        [ 2.5450],\n",
      "        [ 0.5112],\n",
      "        [17.1893],\n",
      "        [ 8.7829],\n",
      "        [ 5.0334],\n",
      "        [12.0562],\n",
      "        [ 1.3435],\n",
      "        [ 3.6150],\n",
      "        [ 6.0791],\n",
      "        [ 1.0203],\n",
      "        [ 0.5826],\n",
      "        [12.4754],\n",
      "        [ 2.6428],\n",
      "        [ 4.3463],\n",
      "        [ 7.8460],\n",
      "        [ 6.4490],\n",
      "        [ 8.1594],\n",
      "        [ 3.9999],\n",
      "        [ 3.4402],\n",
      "        [12.3217],\n",
      "        [ 6.8385],\n",
      "        [ 2.6316],\n",
      "        [ 5.5637]])\n",
      "tensor([[ 7.0848],\n",
      "        [ 1.4262],\n",
      "        [ 6.0216],\n",
      "        [ 7.6271],\n",
      "        [ 4.0675],\n",
      "        [ 4.1283],\n",
      "        [ 4.8217],\n",
      "        [ 0.8924],\n",
      "        [ 3.3119],\n",
      "        [ 4.9617],\n",
      "        [ 4.4384],\n",
      "        [35.6702],\n",
      "        [ 0.6868],\n",
      "        [ 0.8570],\n",
      "        [ 6.1023],\n",
      "        [ 8.1977],\n",
      "        [ 7.2181],\n",
      "        [ 1.7183],\n",
      "        [ 0.5976],\n",
      "        [ 2.6348],\n",
      "        [12.9519],\n",
      "        [ 1.1278],\n",
      "        [ 3.0348],\n",
      "        [ 0.8208],\n",
      "        [ 4.4924],\n",
      "        [19.4890],\n",
      "        [ 3.6850],\n",
      "        [ 1.5016],\n",
      "        [ 1.4628],\n",
      "        [ 3.6829],\n",
      "        [ 1.8050],\n",
      "        [ 8.7791]])\n",
      "tensor([[ 8.4260],\n",
      "        [ 7.0476],\n",
      "        [ 1.5635],\n",
      "        [ 3.0140],\n",
      "        [ 5.8005],\n",
      "        [ 1.7855],\n",
      "        [ 7.8533],\n",
      "        [ 1.8983],\n",
      "        [ 1.9520],\n",
      "        [12.4499],\n",
      "        [11.1203],\n",
      "        [ 2.0621],\n",
      "        [ 1.1703],\n",
      "        [10.5701],\n",
      "        [ 2.7617],\n",
      "        [ 6.9763],\n",
      "        [ 7.3261],\n",
      "        [11.3951],\n",
      "        [21.2880],\n",
      "        [45.1000],\n",
      "        [ 1.0756],\n",
      "        [ 1.4252],\n",
      "        [13.5792],\n",
      "        [ 3.1037],\n",
      "        [ 7.5511],\n",
      "        [ 1.3316],\n",
      "        [ 1.0968],\n",
      "        [ 5.7359],\n",
      "        [ 6.2568],\n",
      "        [ 8.0748],\n",
      "        [ 2.8958],\n",
      "        [ 1.5461]])\n",
      "tensor([[ 3.7880],\n",
      "        [ 2.3839],\n",
      "        [15.5152],\n",
      "        [ 2.2824],\n",
      "        [13.0841],\n",
      "        [ 1.3231],\n",
      "        [ 6.7324],\n",
      "        [ 0.2216],\n",
      "        [ 1.2477],\n",
      "        [ 3.8163],\n",
      "        [41.9579],\n",
      "        [ 4.4552],\n",
      "        [ 0.7596],\n",
      "        [ 2.5831],\n",
      "        [ 8.0464],\n",
      "        [14.4731],\n",
      "        [ 3.6978],\n",
      "        [ 1.7632],\n",
      "        [ 4.5796],\n",
      "        [ 5.0295],\n",
      "        [28.9209],\n",
      "        [ 2.6982],\n",
      "        [ 3.0377],\n",
      "        [ 3.5051],\n",
      "        [ 2.4734],\n",
      "        [ 6.7218],\n",
      "        [ 3.4166],\n",
      "        [ 1.3542],\n",
      "        [11.6090],\n",
      "        [ 2.7113],\n",
      "        [ 7.4158],\n",
      "        [ 0.7074]])\n",
      "tensor([[14.1286],\n",
      "        [ 1.4839],\n",
      "        [ 7.0706],\n",
      "        [ 2.6997],\n",
      "        [ 2.2732],\n",
      "        [25.8981],\n",
      "        [ 3.2555],\n",
      "        [ 1.0970],\n",
      "        [ 4.8063],\n",
      "        [27.3107],\n",
      "        [ 2.0628],\n",
      "        [ 4.7430],\n",
      "        [ 1.0622],\n",
      "        [ 6.6245],\n",
      "        [ 3.3248],\n",
      "        [31.4736],\n",
      "        [ 2.1305],\n",
      "        [13.2849],\n",
      "        [ 7.9663],\n",
      "        [ 0.8030],\n",
      "        [ 6.0821],\n",
      "        [ 0.7367],\n",
      "        [12.8572],\n",
      "        [ 1.1348],\n",
      "        [ 2.9495],\n",
      "        [ 1.0531],\n",
      "        [ 5.2476],\n",
      "        [ 2.8498],\n",
      "        [ 6.2485],\n",
      "        [ 3.1422],\n",
      "        [ 2.2641],\n",
      "        [ 3.4881]])\n",
      "tensor([[ 6.8260],\n",
      "        [19.2523],\n",
      "        [ 3.3630],\n",
      "        [ 1.9144],\n",
      "        [ 6.1698],\n",
      "        [ 7.3330],\n",
      "        [18.5243],\n",
      "        [ 2.7855],\n",
      "        [ 3.6054],\n",
      "        [ 0.9734],\n",
      "        [ 2.3902],\n",
      "        [ 1.4738],\n",
      "        [ 5.4737],\n",
      "        [13.2818],\n",
      "        [ 2.2902],\n",
      "        [ 2.8966],\n",
      "        [ 1.5808],\n",
      "        [ 2.4973],\n",
      "        [ 2.4801],\n",
      "        [ 2.3467],\n",
      "        [ 1.9659],\n",
      "        [ 0.6760],\n",
      "        [ 0.5216],\n",
      "        [ 0.5455],\n",
      "        [ 6.2428],\n",
      "        [ 6.2817],\n",
      "        [ 4.0551],\n",
      "        [ 5.5380],\n",
      "        [ 0.2829],\n",
      "        [ 2.9282],\n",
      "        [ 5.7070],\n",
      "        [ 2.3742]])\n",
      "tensor([[ 5.6904],\n",
      "        [ 6.2452],\n",
      "        [ 0.9373],\n",
      "        [ 9.5820],\n",
      "        [ 6.5217],\n",
      "        [ 7.4560],\n",
      "        [ 7.4726],\n",
      "        [ 9.4418],\n",
      "        [12.8616],\n",
      "        [ 2.8455],\n",
      "        [ 9.5966],\n",
      "        [ 2.3393],\n",
      "        [13.5206],\n",
      "        [ 1.2137],\n",
      "        [ 1.7209],\n",
      "        [12.4921],\n",
      "        [11.4443],\n",
      "        [ 0.6888],\n",
      "        [ 1.4928],\n",
      "        [ 1.8413],\n",
      "        [ 2.6624],\n",
      "        [ 1.7554],\n",
      "        [ 6.6906],\n",
      "        [ 6.4289],\n",
      "        [ 3.1952],\n",
      "        [ 4.9385],\n",
      "        [ 4.6981],\n",
      "        [ 7.4992],\n",
      "        [10.4616],\n",
      "        [ 4.9216],\n",
      "        [ 3.8446],\n",
      "        [ 5.8007]])\n",
      "tensor([[ 2.0994],\n",
      "        [ 3.6627],\n",
      "        [ 1.5609],\n",
      "        [ 2.8377],\n",
      "        [ 6.0745],\n",
      "        [ 4.3144],\n",
      "        [ 0.6700],\n",
      "        [12.5982],\n",
      "        [ 0.2929],\n",
      "        [ 4.8121],\n",
      "        [ 2.8372],\n",
      "        [23.4607],\n",
      "        [ 2.9920],\n",
      "        [ 2.1723],\n",
      "        [ 1.3905],\n",
      "        [ 0.9465],\n",
      "        [ 9.3565],\n",
      "        [ 5.4869],\n",
      "        [20.3878],\n",
      "        [ 3.9527],\n",
      "        [ 6.4406],\n",
      "        [26.6616],\n",
      "        [ 3.0602],\n",
      "        [ 1.8636],\n",
      "        [ 3.2477],\n",
      "        [ 6.9273],\n",
      "        [ 8.3533],\n",
      "        [ 7.5475],\n",
      "        [11.4177],\n",
      "        [19.7914],\n",
      "        [ 3.0117],\n",
      "        [ 2.6215]])\n",
      "tensor([[ 7.7676],\n",
      "        [13.5405],\n",
      "        [ 0.2475],\n",
      "        [ 2.5484],\n",
      "        [ 5.1116],\n",
      "        [11.4208],\n",
      "        [ 5.3665],\n",
      "        [ 3.0851],\n",
      "        [ 7.2900],\n",
      "        [ 1.2221],\n",
      "        [14.3953],\n",
      "        [25.7047],\n",
      "        [ 4.3859],\n",
      "        [ 2.9592],\n",
      "        [ 0.7590],\n",
      "        [ 0.6345],\n",
      "        [ 1.4931],\n",
      "        [ 9.6032],\n",
      "        [ 1.7714],\n",
      "        [ 4.3277],\n",
      "        [ 8.1119],\n",
      "        [15.4431],\n",
      "        [ 3.7717],\n",
      "        [ 2.2768],\n",
      "        [ 9.2855],\n",
      "        [ 2.5434],\n",
      "        [ 0.7599],\n",
      "        [14.7521],\n",
      "        [ 2.3471],\n",
      "        [ 2.5097],\n",
      "        [ 7.9605],\n",
      "        [ 2.1895]])\n",
      "tensor([[10.4817],\n",
      "        [ 1.8995],\n",
      "        [ 2.1663],\n",
      "        [18.1518],\n",
      "        [16.2197],\n",
      "        [ 0.5457],\n",
      "        [ 2.5891],\n",
      "        [ 8.7377],\n",
      "        [ 6.4627],\n",
      "        [ 7.1010],\n",
      "        [ 5.6842],\n",
      "        [12.8190],\n",
      "        [ 6.3726],\n",
      "        [24.1799],\n",
      "        [ 4.4093],\n",
      "        [21.1138],\n",
      "        [ 0.4179],\n",
      "        [ 3.1734],\n",
      "        [ 8.0199],\n",
      "        [ 2.6792],\n",
      "        [ 1.0228],\n",
      "        [ 7.4244],\n",
      "        [ 1.9273],\n",
      "        [ 5.2233],\n",
      "        [ 6.7826],\n",
      "        [ 2.5398],\n",
      "        [ 0.2992],\n",
      "        [ 5.4375],\n",
      "        [ 3.8681],\n",
      "        [ 6.1070],\n",
      "        [ 2.1874],\n",
      "        [ 2.1271]])\n",
      "tensor([[ 7.3615],\n",
      "        [19.3861],\n",
      "        [ 4.4041],\n",
      "        [ 7.1170],\n",
      "        [ 4.5664],\n",
      "        [ 3.3264],\n",
      "        [ 1.3089],\n",
      "        [15.4524],\n",
      "        [ 6.2360],\n",
      "        [ 2.7457],\n",
      "        [ 1.8524],\n",
      "        [ 3.6435],\n",
      "        [ 3.0800],\n",
      "        [ 6.4237],\n",
      "        [ 2.1601],\n",
      "        [ 1.5497],\n",
      "        [ 2.4046],\n",
      "        [ 4.2115],\n",
      "        [ 2.4465],\n",
      "        [ 1.7978],\n",
      "        [ 2.7579],\n",
      "        [ 7.1931],\n",
      "        [ 1.1440],\n",
      "        [10.1899],\n",
      "        [ 2.7153],\n",
      "        [ 2.6747],\n",
      "        [14.7752],\n",
      "        [ 1.0678],\n",
      "        [ 0.6341],\n",
      "        [ 5.7433],\n",
      "        [ 6.9293],\n",
      "        [ 6.7596]])\n",
      "tensor([[ 3.7609],\n",
      "        [ 2.6532],\n",
      "        [ 3.3797],\n",
      "        [ 4.3586],\n",
      "        [ 0.3614],\n",
      "        [ 9.4348],\n",
      "        [37.5872],\n",
      "        [ 3.8195],\n",
      "        [ 2.5375],\n",
      "        [ 3.6680],\n",
      "        [ 3.1779],\n",
      "        [ 2.4051],\n",
      "        [10.8903],\n",
      "        [ 3.4618],\n",
      "        [ 5.3880],\n",
      "        [ 5.9437],\n",
      "        [17.2817],\n",
      "        [ 3.9853],\n",
      "        [ 3.2167],\n",
      "        [ 0.4819],\n",
      "        [ 0.9986],\n",
      "        [ 2.8704],\n",
      "        [ 0.6326],\n",
      "        [12.4853],\n",
      "        [ 4.5699],\n",
      "        [ 0.6147],\n",
      "        [ 6.6015],\n",
      "        [ 1.7109],\n",
      "        [ 0.7503],\n",
      "        [ 2.1849],\n",
      "        [ 0.1841],\n",
      "        [ 1.1781]])\n",
      "tensor([[ 5.4666],\n",
      "        [ 1.7436],\n",
      "        [10.3677],\n",
      "        [ 1.5343],\n",
      "        [ 1.4643],\n",
      "        [ 2.1842],\n",
      "        [ 9.7454],\n",
      "        [ 4.3628],\n",
      "        [ 8.7887],\n",
      "        [ 2.9230],\n",
      "        [ 2.3492],\n",
      "        [19.8174],\n",
      "        [ 2.8769],\n",
      "        [ 0.7520],\n",
      "        [16.7301],\n",
      "        [ 5.3777],\n",
      "        [17.4420],\n",
      "        [ 5.8720],\n",
      "        [ 1.6333],\n",
      "        [ 3.3603],\n",
      "        [ 1.9816],\n",
      "        [ 0.3101],\n",
      "        [ 9.3415],\n",
      "        [ 7.7137],\n",
      "        [11.0076],\n",
      "        [ 6.8712],\n",
      "        [ 4.9899],\n",
      "        [ 2.8161],\n",
      "        [ 0.3519],\n",
      "        [ 9.0929],\n",
      "        [15.2606],\n",
      "        [ 3.3641]])\n",
      "tensor([[ 2.5071],\n",
      "        [11.3865],\n",
      "        [ 2.3129],\n",
      "        [ 1.1283],\n",
      "        [ 3.9580],\n",
      "        [ 9.0949],\n",
      "        [ 5.9863],\n",
      "        [ 3.3086],\n",
      "        [ 1.4667],\n",
      "        [ 2.6708],\n",
      "        [ 3.3281],\n",
      "        [ 5.6968],\n",
      "        [ 2.7213],\n",
      "        [ 9.3892],\n",
      "        [ 5.2933],\n",
      "        [ 7.5646],\n",
      "        [ 4.0910],\n",
      "        [ 0.3945],\n",
      "        [ 5.2543],\n",
      "        [ 1.5383],\n",
      "        [ 3.6276],\n",
      "        [11.5442],\n",
      "        [ 1.0574],\n",
      "        [ 2.1879],\n",
      "        [ 2.0887],\n",
      "        [ 0.7989],\n",
      "        [ 0.1545],\n",
      "        [ 1.0747],\n",
      "        [ 1.2767],\n",
      "        [ 6.5562],\n",
      "        [ 3.1923],\n",
      "        [ 7.3538]])\n",
      "tensor([[11.7375],\n",
      "        [ 5.8496],\n",
      "        [ 1.0720],\n",
      "        [ 2.4625],\n",
      "        [ 3.8239],\n",
      "        [ 0.8196],\n",
      "        [ 5.7583],\n",
      "        [ 1.7437],\n",
      "        [12.2106],\n",
      "        [ 3.3676],\n",
      "        [22.7454],\n",
      "        [11.8078],\n",
      "        [ 1.1406],\n",
      "        [ 3.6349],\n",
      "        [ 2.8026],\n",
      "        [ 3.3810],\n",
      "        [11.5489],\n",
      "        [ 6.6908],\n",
      "        [ 0.5499],\n",
      "        [ 0.6184],\n",
      "        [ 1.7030],\n",
      "        [19.3610],\n",
      "        [ 5.0001],\n",
      "        [ 7.8313],\n",
      "        [10.1291],\n",
      "        [ 2.1683],\n",
      "        [13.0311],\n",
      "        [ 2.7918],\n",
      "        [ 0.4229],\n",
      "        [ 8.8929],\n",
      "        [16.9160],\n",
      "        [11.1366]])\n",
      "tensor([[ 8.3926],\n",
      "        [ 4.0962],\n",
      "        [ 3.2405],\n",
      "        [ 0.1748],\n",
      "        [11.6080],\n",
      "        [ 1.8092],\n",
      "        [10.7661],\n",
      "        [ 3.2678],\n",
      "        [ 3.6606],\n",
      "        [ 1.0400],\n",
      "        [ 2.9851],\n",
      "        [ 6.0676],\n",
      "        [ 1.9724],\n",
      "        [ 2.8761],\n",
      "        [ 1.2169],\n",
      "        [ 5.2135],\n",
      "        [ 4.8116],\n",
      "        [ 3.5544],\n",
      "        [ 1.6543],\n",
      "        [ 4.4419],\n",
      "        [ 5.3182],\n",
      "        [ 4.5058],\n",
      "        [ 0.8230],\n",
      "        [ 2.7448],\n",
      "        [ 0.5455],\n",
      "        [ 0.9949],\n",
      "        [11.9688],\n",
      "        [ 8.9180],\n",
      "        [ 1.8031],\n",
      "        [ 4.1112],\n",
      "        [ 9.1464],\n",
      "        [ 2.4076]])\n",
      "tensor([[ 1.9357],\n",
      "        [24.0888],\n",
      "        [27.7378],\n",
      "        [ 7.6724],\n",
      "        [33.7605],\n",
      "        [ 2.8619],\n",
      "        [ 4.3969],\n",
      "        [ 8.2566],\n",
      "        [ 3.7148],\n",
      "        [ 4.5624],\n",
      "        [ 8.1196],\n",
      "        [ 4.3332],\n",
      "        [ 2.0107],\n",
      "        [10.5845],\n",
      "        [ 2.6466],\n",
      "        [ 7.0213],\n",
      "        [ 0.5342],\n",
      "        [ 0.8757],\n",
      "        [ 2.3035],\n",
      "        [ 1.2498],\n",
      "        [11.6192],\n",
      "        [ 3.0464],\n",
      "        [ 5.1988],\n",
      "        [13.0010],\n",
      "        [ 5.4851],\n",
      "        [ 3.4102],\n",
      "        [ 4.2613],\n",
      "        [20.8245],\n",
      "        [ 3.5465],\n",
      "        [ 0.5212],\n",
      "        [ 7.0951],\n",
      "        [10.5312]])\n",
      "tensor([[ 1.4236],\n",
      "        [ 9.3066],\n",
      "        [ 2.0436],\n",
      "        [66.6586],\n",
      "        [ 2.4192],\n",
      "        [ 0.6210],\n",
      "        [ 2.2354],\n",
      "        [ 0.7316],\n",
      "        [15.0580],\n",
      "        [ 1.8818],\n",
      "        [ 9.7762],\n",
      "        [ 4.7330],\n",
      "        [ 1.8981],\n",
      "        [14.5737],\n",
      "        [ 3.4531],\n",
      "        [ 1.3217],\n",
      "        [ 1.1757],\n",
      "        [ 2.5432],\n",
      "        [ 6.0956],\n",
      "        [ 2.8977],\n",
      "        [ 2.5018],\n",
      "        [11.5492],\n",
      "        [ 5.1343],\n",
      "        [ 3.2583],\n",
      "        [ 1.4882],\n",
      "        [ 0.9311],\n",
      "        [ 2.9811],\n",
      "        [ 3.8805],\n",
      "        [10.0452],\n",
      "        [18.0338],\n",
      "        [ 3.4705],\n",
      "        [ 1.9122]])\n",
      "tensor([[15.9683],\n",
      "        [ 5.1863],\n",
      "        [ 6.5238],\n",
      "        [ 0.6427],\n",
      "        [ 1.2662],\n",
      "        [ 2.5374],\n",
      "        [ 3.4620],\n",
      "        [11.2965],\n",
      "        [ 8.0907],\n",
      "        [ 5.9658],\n",
      "        [ 2.2775],\n",
      "        [ 1.1017],\n",
      "        [ 2.4186],\n",
      "        [ 4.7565],\n",
      "        [ 0.6211],\n",
      "        [ 6.9461],\n",
      "        [11.7228],\n",
      "        [ 6.5420],\n",
      "        [ 3.7332],\n",
      "        [ 0.8780],\n",
      "        [ 0.8943],\n",
      "        [ 0.6039],\n",
      "        [ 1.8637],\n",
      "        [ 3.9760],\n",
      "        [ 3.7185],\n",
      "        [ 3.2686],\n",
      "        [ 2.4240],\n",
      "        [ 1.5280],\n",
      "        [80.3370],\n",
      "        [ 2.7091],\n",
      "        [ 3.5287],\n",
      "        [ 9.5395]])\n",
      "tensor([[ 9.8434],\n",
      "        [ 1.1984],\n",
      "        [ 0.4706],\n",
      "        [ 0.6221],\n",
      "        [ 7.0329],\n",
      "        [ 2.2095],\n",
      "        [ 3.6324],\n",
      "        [ 2.6688],\n",
      "        [16.7424],\n",
      "        [ 2.2740],\n",
      "        [10.6063],\n",
      "        [ 5.5912],\n",
      "        [ 1.4626],\n",
      "        [ 6.5437],\n",
      "        [ 3.8628],\n",
      "        [ 8.0492],\n",
      "        [ 3.9476],\n",
      "        [ 9.9875],\n",
      "        [ 3.0911],\n",
      "        [ 2.0364],\n",
      "        [ 0.6117],\n",
      "        [ 0.8056],\n",
      "        [ 0.6291],\n",
      "        [ 6.3552],\n",
      "        [ 2.5540],\n",
      "        [ 6.3153],\n",
      "        [ 0.0886],\n",
      "        [ 2.2976],\n",
      "        [ 4.5674],\n",
      "        [12.0076],\n",
      "        [ 3.6719],\n",
      "        [ 6.6684]])\n",
      "tensor([[ 4.6119],\n",
      "        [ 0.4374],\n",
      "        [18.1435],\n",
      "        [ 2.3276],\n",
      "        [ 3.2440],\n",
      "        [ 5.9281],\n",
      "        [ 1.8630],\n",
      "        [ 4.2928],\n",
      "        [ 1.5355],\n",
      "        [17.0372],\n",
      "        [ 5.7485],\n",
      "        [10.8237],\n",
      "        [13.0848],\n",
      "        [24.3566],\n",
      "        [ 8.6986],\n",
      "        [ 3.7379],\n",
      "        [ 0.9556],\n",
      "        [ 2.1288],\n",
      "        [10.1743],\n",
      "        [24.9244],\n",
      "        [ 5.6264],\n",
      "        [ 4.4210],\n",
      "        [ 3.9694],\n",
      "        [ 4.3349],\n",
      "        [ 1.4932],\n",
      "        [ 0.5589],\n",
      "        [21.8133],\n",
      "        [ 1.4061],\n",
      "        [ 7.2495],\n",
      "        [ 4.3620],\n",
      "        [ 3.1168],\n",
      "        [ 0.3793]])\n",
      "tensor([[ 0.6368],\n",
      "        [ 1.5477],\n",
      "        [ 2.6305],\n",
      "        [27.5325],\n",
      "        [ 2.4772],\n",
      "        [ 2.6750],\n",
      "        [ 3.5979],\n",
      "        [ 6.7594],\n",
      "        [ 7.0593],\n",
      "        [ 3.4911],\n",
      "        [ 2.4066],\n",
      "        [ 7.5988],\n",
      "        [10.3907],\n",
      "        [ 2.5827],\n",
      "        [24.4794],\n",
      "        [ 5.5304],\n",
      "        [ 3.0493],\n",
      "        [ 1.2774],\n",
      "        [ 7.3035],\n",
      "        [ 0.8266],\n",
      "        [ 2.3514],\n",
      "        [ 1.7529],\n",
      "        [19.3066],\n",
      "        [ 6.5119],\n",
      "        [ 6.3354],\n",
      "        [ 1.2150],\n",
      "        [ 4.4645],\n",
      "        [14.3994],\n",
      "        [ 1.3364],\n",
      "        [ 1.3699],\n",
      "        [ 1.7036],\n",
      "        [20.0507]])\n",
      "tensor([[18.0328],\n",
      "        [ 5.4245],\n",
      "        [ 3.2964],\n",
      "        [ 1.6232],\n",
      "        [ 4.1094],\n",
      "        [ 6.1094],\n",
      "        [10.4305],\n",
      "        [ 4.4386],\n",
      "        [ 1.8577],\n",
      "        [ 1.7422],\n",
      "        [16.3522],\n",
      "        [ 4.3856],\n",
      "        [ 4.4854],\n",
      "        [ 9.4851],\n",
      "        [16.6304],\n",
      "        [ 6.6228],\n",
      "        [ 0.3683],\n",
      "        [ 8.1654],\n",
      "        [ 0.9560],\n",
      "        [ 1.1496],\n",
      "        [ 3.3952],\n",
      "        [ 3.7006],\n",
      "        [ 4.8106],\n",
      "        [30.5539],\n",
      "        [ 9.3175],\n",
      "        [12.7269],\n",
      "        [ 5.4987],\n",
      "        [16.8843],\n",
      "        [ 7.9506],\n",
      "        [ 0.5564],\n",
      "        [ 7.5921],\n",
      "        [ 3.5063]])\n",
      "tensor([[ 4.1782],\n",
      "        [ 7.4426],\n",
      "        [ 1.2118],\n",
      "        [11.4703],\n",
      "        [10.3168],\n",
      "        [ 3.9996],\n",
      "        [ 2.2695],\n",
      "        [10.9879],\n",
      "        [ 6.5556],\n",
      "        [ 3.7867],\n",
      "        [ 0.9422],\n",
      "        [ 1.1954],\n",
      "        [ 2.5433],\n",
      "        [ 0.3939],\n",
      "        [ 1.5509],\n",
      "        [ 5.5741],\n",
      "        [ 2.8831],\n",
      "        [ 7.5838],\n",
      "        [ 3.6804],\n",
      "        [12.2352],\n",
      "        [19.8694],\n",
      "        [ 1.4726],\n",
      "        [ 0.9701],\n",
      "        [17.2813],\n",
      "        [ 3.1048],\n",
      "        [ 2.1300],\n",
      "        [ 3.7336],\n",
      "        [ 1.0190],\n",
      "        [ 0.2764],\n",
      "        [13.2373],\n",
      "        [ 8.6008],\n",
      "        [ 3.8302]])\n",
      "tensor([[ 5.9816],\n",
      "        [ 4.0115],\n",
      "        [ 2.6085],\n",
      "        [ 5.9584],\n",
      "        [ 4.8317],\n",
      "        [ 0.2130],\n",
      "        [ 8.2515],\n",
      "        [ 1.6467],\n",
      "        [ 0.6100],\n",
      "        [ 2.0552],\n",
      "        [ 2.2291],\n",
      "        [20.0487],\n",
      "        [ 3.2711],\n",
      "        [ 6.7037],\n",
      "        [ 5.9318],\n",
      "        [ 2.2642],\n",
      "        [ 5.6438],\n",
      "        [ 1.2538],\n",
      "        [ 6.1115],\n",
      "        [ 2.3179],\n",
      "        [ 5.0363],\n",
      "        [ 3.7038],\n",
      "        [ 5.3254],\n",
      "        [ 5.0442],\n",
      "        [ 1.9373],\n",
      "        [ 5.9615],\n",
      "        [ 0.3039],\n",
      "        [19.3170],\n",
      "        [11.8097],\n",
      "        [ 1.7577],\n",
      "        [11.3182],\n",
      "        [ 1.8850]])\n",
      "tensor([[ 6.6641],\n",
      "        [ 9.7983],\n",
      "        [ 5.0168],\n",
      "        [ 4.0015],\n",
      "        [ 0.9632],\n",
      "        [ 0.3756],\n",
      "        [ 4.3583],\n",
      "        [ 5.3862],\n",
      "        [ 8.8041],\n",
      "        [11.9276],\n",
      "        [ 3.6409],\n",
      "        [ 8.4555],\n",
      "        [ 8.7842],\n",
      "        [ 2.4506],\n",
      "        [ 8.6422],\n",
      "        [ 1.8848],\n",
      "        [11.0393],\n",
      "        [13.5956],\n",
      "        [ 5.3029],\n",
      "        [46.6763],\n",
      "        [ 0.3670],\n",
      "        [ 3.6385],\n",
      "        [ 6.8137],\n",
      "        [ 3.9092],\n",
      "        [ 2.4293],\n",
      "        [ 0.7060],\n",
      "        [ 2.7724],\n",
      "        [ 9.4219],\n",
      "        [ 9.5024],\n",
      "        [ 1.4374],\n",
      "        [ 7.5893],\n",
      "        [ 7.1837]])\n",
      "tensor([[ 0.7004],\n",
      "        [ 7.7153],\n",
      "        [ 2.9647],\n",
      "        [ 7.4918],\n",
      "        [17.0885],\n",
      "        [ 2.1842],\n",
      "        [ 2.9610],\n",
      "        [ 7.6366],\n",
      "        [ 8.6615],\n",
      "        [ 4.0704],\n",
      "        [ 7.3939],\n",
      "        [ 1.9424],\n",
      "        [ 5.9821],\n",
      "        [14.3659],\n",
      "        [ 7.0906],\n",
      "        [ 4.8587],\n",
      "        [ 1.9077],\n",
      "        [ 0.9362],\n",
      "        [ 2.3214],\n",
      "        [ 7.3578],\n",
      "        [ 4.3708],\n",
      "        [ 2.7041],\n",
      "        [ 5.7422],\n",
      "        [23.2923],\n",
      "        [ 3.4317],\n",
      "        [ 3.3309],\n",
      "        [ 3.5052],\n",
      "        [ 8.9805],\n",
      "        [ 2.5108],\n",
      "        [17.9577],\n",
      "        [ 2.1006],\n",
      "        [20.3432]])\n",
      "tensor([[14.4709],\n",
      "        [ 0.8892],\n",
      "        [10.3349],\n",
      "        [ 1.0435],\n",
      "        [ 0.7890],\n",
      "        [ 3.2848],\n",
      "        [ 1.9387],\n",
      "        [ 2.8406],\n",
      "        [24.4516],\n",
      "        [ 3.0932],\n",
      "        [ 3.4329],\n",
      "        [10.4061],\n",
      "        [12.2575],\n",
      "        [ 5.1131],\n",
      "        [ 9.9898],\n",
      "        [ 3.4106],\n",
      "        [ 5.2240],\n",
      "        [ 2.5903],\n",
      "        [ 7.0221],\n",
      "        [15.2669],\n",
      "        [ 5.1265],\n",
      "        [ 2.8457],\n",
      "        [18.2143],\n",
      "        [ 8.2234],\n",
      "        [10.0627],\n",
      "        [ 8.6890],\n",
      "        [16.1839],\n",
      "        [12.7126],\n",
      "        [ 1.1990],\n",
      "        [ 0.9004],\n",
      "        [ 3.7169],\n",
      "        [ 4.7254]])\n",
      "tensor([[ 4.0533],\n",
      "        [ 0.5803],\n",
      "        [ 2.7707],\n",
      "        [ 4.2025],\n",
      "        [ 3.0549],\n",
      "        [ 2.5032],\n",
      "        [ 6.2099],\n",
      "        [ 4.7436],\n",
      "        [16.0365],\n",
      "        [ 1.6045],\n",
      "        [17.0763],\n",
      "        [ 2.8845],\n",
      "        [ 3.4785],\n",
      "        [ 8.7176],\n",
      "        [ 4.0524],\n",
      "        [ 2.2863],\n",
      "        [ 0.8081],\n",
      "        [ 3.7861],\n",
      "        [ 3.7786],\n",
      "        [13.1283],\n",
      "        [15.4243],\n",
      "        [10.1674],\n",
      "        [ 3.6010],\n",
      "        [16.6666],\n",
      "        [ 4.0841],\n",
      "        [30.4070],\n",
      "        [ 4.9713],\n",
      "        [ 6.1907],\n",
      "        [ 5.0247],\n",
      "        [ 4.1736],\n",
      "        [ 4.7693],\n",
      "        [ 7.3660]])\n",
      "tensor([[ 4.1723],\n",
      "        [ 6.8743],\n",
      "        [ 3.7864],\n",
      "        [15.9137],\n",
      "        [22.2808],\n",
      "        [ 2.9110],\n",
      "        [ 0.7640],\n",
      "        [ 0.8139],\n",
      "        [10.7952],\n",
      "        [ 5.3703],\n",
      "        [ 3.6819],\n",
      "        [ 3.6047],\n",
      "        [ 8.9111],\n",
      "        [ 4.1514],\n",
      "        [13.6268],\n",
      "        [ 3.3298],\n",
      "        [ 5.7829],\n",
      "        [ 1.2092],\n",
      "        [ 2.5513],\n",
      "        [ 4.4875],\n",
      "        [ 0.7305],\n",
      "        [ 1.2394],\n",
      "        [24.6982],\n",
      "        [ 7.8110],\n",
      "        [19.1240],\n",
      "        [ 3.1198],\n",
      "        [ 4.5030],\n",
      "        [18.4532],\n",
      "        [ 5.5678],\n",
      "        [ 1.2881],\n",
      "        [ 5.5998],\n",
      "        [ 1.8709]])\n",
      "tensor([[ 2.6920],\n",
      "        [10.5363],\n",
      "        [ 2.5509],\n",
      "        [37.0332],\n",
      "        [ 0.6912],\n",
      "        [ 1.7058],\n",
      "        [ 1.6599],\n",
      "        [ 0.9234],\n",
      "        [ 2.7992],\n",
      "        [ 2.8573],\n",
      "        [ 5.7726],\n",
      "        [ 8.4687],\n",
      "        [ 0.9638],\n",
      "        [ 1.1567],\n",
      "        [ 5.5948],\n",
      "        [11.8316],\n",
      "        [ 6.0467],\n",
      "        [ 2.1395],\n",
      "        [ 3.7907],\n",
      "        [ 2.9301],\n",
      "        [ 6.1342],\n",
      "        [36.3180],\n",
      "        [ 3.5929],\n",
      "        [ 3.4919],\n",
      "        [ 0.4552],\n",
      "        [ 2.8280],\n",
      "        [29.6127],\n",
      "        [18.4783],\n",
      "        [ 4.9097],\n",
      "        [ 1.7904],\n",
      "        [ 3.7798],\n",
      "        [ 1.3902]])\n",
      "tensor([[ 4.9129],\n",
      "        [ 5.0097],\n",
      "        [ 2.5633],\n",
      "        [10.7602],\n",
      "        [ 1.3511],\n",
      "        [ 2.0185],\n",
      "        [ 6.6080],\n",
      "        [ 0.4564],\n",
      "        [ 1.5752],\n",
      "        [ 0.6956],\n",
      "        [ 0.7058],\n",
      "        [ 1.9236],\n",
      "        [ 8.0438],\n",
      "        [ 3.2794],\n",
      "        [ 1.6816],\n",
      "        [ 2.0648],\n",
      "        [ 5.8264],\n",
      "        [18.2090],\n",
      "        [ 3.1091],\n",
      "        [ 0.4771],\n",
      "        [ 2.5914],\n",
      "        [ 0.9784],\n",
      "        [ 7.8087],\n",
      "        [ 7.6629],\n",
      "        [10.5887],\n",
      "        [ 1.0667],\n",
      "        [ 4.3770],\n",
      "        [15.1285],\n",
      "        [ 3.3051],\n",
      "        [ 5.8573],\n",
      "        [14.1398],\n",
      "        [ 5.5970]])\n",
      "tensor([[ 9.1225],\n",
      "        [ 7.0040],\n",
      "        [ 3.0986],\n",
      "        [ 1.2196],\n",
      "        [ 5.4265],\n",
      "        [ 0.8011],\n",
      "        [ 1.9610],\n",
      "        [ 2.8284],\n",
      "        [ 1.7178],\n",
      "        [ 6.9444],\n",
      "        [ 0.6084],\n",
      "        [ 5.0609],\n",
      "        [ 0.8525],\n",
      "        [ 3.2576],\n",
      "        [ 3.6128],\n",
      "        [10.8647],\n",
      "        [ 0.7254],\n",
      "        [ 1.8529],\n",
      "        [ 3.9288],\n",
      "        [ 0.3288],\n",
      "        [24.3610],\n",
      "        [31.7446],\n",
      "        [ 7.1700],\n",
      "        [ 1.8185],\n",
      "        [20.2555],\n",
      "        [ 5.8000],\n",
      "        [ 7.3267],\n",
      "        [ 2.1826],\n",
      "        [ 1.8990],\n",
      "        [ 3.2301],\n",
      "        [ 3.1911],\n",
      "        [10.0303]])\n",
      "tensor([[ 8.7382],\n",
      "        [ 1.5888],\n",
      "        [ 4.7442],\n",
      "        [ 3.1074],\n",
      "        [ 2.6629],\n",
      "        [ 5.2516],\n",
      "        [ 1.4882],\n",
      "        [ 2.8412],\n",
      "        [11.6790],\n",
      "        [ 7.6607],\n",
      "        [ 2.1880],\n",
      "        [ 6.0000],\n",
      "        [ 5.3206],\n",
      "        [ 1.6753],\n",
      "        [ 2.1476],\n",
      "        [ 2.0023],\n",
      "        [12.7735],\n",
      "        [ 1.7002],\n",
      "        [ 2.5549],\n",
      "        [ 5.3972],\n",
      "        [ 8.5588],\n",
      "        [ 5.3017],\n",
      "        [ 5.4602],\n",
      "        [ 1.5347],\n",
      "        [ 4.5111],\n",
      "        [ 9.0621],\n",
      "        [ 9.0031],\n",
      "        [ 1.6564],\n",
      "        [ 4.5609],\n",
      "        [ 2.8974],\n",
      "        [ 5.2593],\n",
      "        [ 6.4255]])\n",
      "tensor([[ 0.5637],\n",
      "        [10.7344],\n",
      "        [24.6984],\n",
      "        [ 8.6137],\n",
      "        [ 1.5642],\n",
      "        [11.5885],\n",
      "        [ 3.7800],\n",
      "        [ 2.2990],\n",
      "        [31.2652],\n",
      "        [ 0.3696],\n",
      "        [11.0355],\n",
      "        [ 5.3052],\n",
      "        [ 4.1824],\n",
      "        [32.5936],\n",
      "        [21.4554],\n",
      "        [11.4832],\n",
      "        [ 1.0886],\n",
      "        [ 3.0533],\n",
      "        [13.2626],\n",
      "        [ 1.3799],\n",
      "        [ 5.9102],\n",
      "        [ 0.2354],\n",
      "        [ 4.2728],\n",
      "        [ 0.8611],\n",
      "        [13.8194],\n",
      "        [ 3.7045],\n",
      "        [ 2.2120],\n",
      "        [15.8326],\n",
      "        [ 8.9899],\n",
      "        [ 9.3832],\n",
      "        [ 1.9562],\n",
      "        [ 7.3639]])\n",
      "tensor([[ 0.4398],\n",
      "        [30.6340],\n",
      "        [ 5.0167],\n",
      "        [ 2.3246],\n",
      "        [ 0.6843],\n",
      "        [ 7.4904],\n",
      "        [ 4.8463],\n",
      "        [13.6184],\n",
      "        [13.7329],\n",
      "        [ 8.0324],\n",
      "        [ 2.8320],\n",
      "        [ 3.4996],\n",
      "        [10.5238],\n",
      "        [ 0.9830],\n",
      "        [ 8.8888],\n",
      "        [ 7.3617],\n",
      "        [10.6802],\n",
      "        [ 4.0841],\n",
      "        [ 8.9212],\n",
      "        [ 0.6269],\n",
      "        [ 8.4519],\n",
      "        [ 3.5312],\n",
      "        [ 3.3654],\n",
      "        [ 9.2922],\n",
      "        [ 1.1743],\n",
      "        [ 0.9540],\n",
      "        [13.8735],\n",
      "        [ 2.8147],\n",
      "        [ 0.4532],\n",
      "        [ 4.0417],\n",
      "        [19.3794],\n",
      "        [19.3283]])\n",
      "tensor([[ 0.3573],\n",
      "        [ 4.9534],\n",
      "        [ 0.7686],\n",
      "        [ 3.2331],\n",
      "        [ 0.3331],\n",
      "        [ 4.0794],\n",
      "        [ 6.5356],\n",
      "        [ 2.7423],\n",
      "        [ 1.6820],\n",
      "        [ 1.7214],\n",
      "        [ 1.9703],\n",
      "        [ 1.2438],\n",
      "        [ 4.5472],\n",
      "        [ 2.3012],\n",
      "        [ 6.1994],\n",
      "        [ 6.7584],\n",
      "        [ 1.8316],\n",
      "        [ 2.3713],\n",
      "        [11.4352],\n",
      "        [ 2.4949],\n",
      "        [ 2.5463],\n",
      "        [ 5.0612],\n",
      "        [10.4740],\n",
      "        [16.0532],\n",
      "        [ 5.7433],\n",
      "        [ 1.4784],\n",
      "        [ 4.8719],\n",
      "        [ 1.8886],\n",
      "        [ 2.4587],\n",
      "        [ 1.6417],\n",
      "        [ 0.7516],\n",
      "        [ 4.5974]])\n",
      "tensor([[ 2.5139],\n",
      "        [ 3.6217],\n",
      "        [ 3.2284],\n",
      "        [ 4.0573],\n",
      "        [ 1.9771],\n",
      "        [ 1.2065],\n",
      "        [ 2.7616],\n",
      "        [ 4.4674],\n",
      "        [12.1060],\n",
      "        [ 2.2597],\n",
      "        [ 3.0172],\n",
      "        [ 1.2775],\n",
      "        [ 2.5516],\n",
      "        [ 1.1903],\n",
      "        [ 6.3496],\n",
      "        [ 1.3402],\n",
      "        [ 4.1407],\n",
      "        [ 3.7960],\n",
      "        [ 1.8611],\n",
      "        [ 5.2788],\n",
      "        [ 0.7457],\n",
      "        [ 8.9845],\n",
      "        [ 1.5593],\n",
      "        [ 2.3804],\n",
      "        [ 9.1225],\n",
      "        [ 2.2387],\n",
      "        [10.1773],\n",
      "        [ 1.3333],\n",
      "        [ 3.1058],\n",
      "        [ 6.6930],\n",
      "        [11.6118],\n",
      "        [ 0.8730]])\n",
      "tensor([[10.6545],\n",
      "        [ 2.9258],\n",
      "        [ 9.3463],\n",
      "        [16.8171],\n",
      "        [ 1.6498],\n",
      "        [12.4722],\n",
      "        [10.0998],\n",
      "        [ 2.3316],\n",
      "        [23.7805],\n",
      "        [ 2.4736],\n",
      "        [ 8.2946],\n",
      "        [23.5189],\n",
      "        [ 1.3396],\n",
      "        [ 3.6205],\n",
      "        [ 0.7528],\n",
      "        [ 0.7668],\n",
      "        [14.9537],\n",
      "        [ 1.9914],\n",
      "        [ 1.8956],\n",
      "        [ 8.9678],\n",
      "        [ 8.3907],\n",
      "        [ 3.7854],\n",
      "        [ 3.9700],\n",
      "        [12.3118],\n",
      "        [ 9.4462],\n",
      "        [ 4.5535],\n",
      "        [ 6.4806],\n",
      "        [ 5.1942],\n",
      "        [ 4.6646],\n",
      "        [ 2.5080],\n",
      "        [30.5424],\n",
      "        [ 2.2025]])\n",
      "tensor([[ 4.6991],\n",
      "        [11.8903],\n",
      "        [13.4466],\n",
      "        [ 1.6707],\n",
      "        [ 2.6001],\n",
      "        [ 1.6130],\n",
      "        [ 6.9345],\n",
      "        [ 0.4160],\n",
      "        [ 9.5925],\n",
      "        [ 2.2626],\n",
      "        [ 3.1232],\n",
      "        [ 9.4027],\n",
      "        [19.4571],\n",
      "        [ 1.9566],\n",
      "        [ 6.9043],\n",
      "        [ 8.1213],\n",
      "        [ 6.5660],\n",
      "        [ 4.4832],\n",
      "        [ 5.0665],\n",
      "        [ 0.8365],\n",
      "        [ 6.3492],\n",
      "        [ 4.6068],\n",
      "        [ 1.5256],\n",
      "        [ 5.7987],\n",
      "        [ 9.6084],\n",
      "        [ 5.5776],\n",
      "        [ 7.2952],\n",
      "        [ 3.4012],\n",
      "        [ 2.9159],\n",
      "        [ 1.8610],\n",
      "        [12.7597],\n",
      "        [ 2.1383]])\n",
      "tensor([[ 3.9044],\n",
      "        [ 5.4574],\n",
      "        [ 2.8043],\n",
      "        [ 3.4535],\n",
      "        [ 3.4145],\n",
      "        [ 3.2304],\n",
      "        [ 2.1434],\n",
      "        [ 5.0859],\n",
      "        [30.1324],\n",
      "        [ 6.8468],\n",
      "        [ 7.5556],\n",
      "        [11.6823],\n",
      "        [ 6.4720],\n",
      "        [11.3153],\n",
      "        [ 2.6764],\n",
      "        [ 6.5626],\n",
      "        [ 0.2210],\n",
      "        [ 2.0332],\n",
      "        [ 2.4727],\n",
      "        [16.4028],\n",
      "        [ 2.1324],\n",
      "        [ 6.4744],\n",
      "        [ 4.4492],\n",
      "        [ 1.7867],\n",
      "        [ 2.0495],\n",
      "        [ 3.7642],\n",
      "        [ 1.4520],\n",
      "        [ 3.2554],\n",
      "        [20.6836],\n",
      "        [ 1.3651],\n",
      "        [ 2.0125],\n",
      "        [ 1.6362]])\n",
      "tensor([[ 4.2460],\n",
      "        [ 9.6209],\n",
      "        [13.6446],\n",
      "        [ 5.0483],\n",
      "        [21.7865],\n",
      "        [ 1.9939],\n",
      "        [ 6.9040],\n",
      "        [ 5.3473],\n",
      "        [ 8.3659],\n",
      "        [12.2113],\n",
      "        [ 2.5480],\n",
      "        [ 1.5884],\n",
      "        [ 0.8840],\n",
      "        [ 2.4837],\n",
      "        [ 2.6397],\n",
      "        [ 2.9641],\n",
      "        [13.4760],\n",
      "        [16.7833],\n",
      "        [ 4.7501],\n",
      "        [ 4.1149],\n",
      "        [ 4.2608],\n",
      "        [11.3924],\n",
      "        [ 8.9116],\n",
      "        [12.3312],\n",
      "        [ 8.5655],\n",
      "        [21.5671],\n",
      "        [ 4.9498],\n",
      "        [ 1.6663],\n",
      "        [10.4677],\n",
      "        [30.6211],\n",
      "        [ 1.1332],\n",
      "        [ 7.1902]])\n",
      "tensor([[14.3402],\n",
      "        [ 4.7556],\n",
      "        [ 5.2049],\n",
      "        [ 4.3251],\n",
      "        [ 2.8341],\n",
      "        [33.4889],\n",
      "        [ 0.9341],\n",
      "        [10.0622],\n",
      "        [ 2.0818],\n",
      "        [ 8.8491],\n",
      "        [ 4.0377],\n",
      "        [ 3.4444],\n",
      "        [10.1247],\n",
      "        [ 6.3036],\n",
      "        [ 1.5432],\n",
      "        [ 3.5495],\n",
      "        [ 0.3995],\n",
      "        [ 7.2983],\n",
      "        [ 2.7797],\n",
      "        [ 1.5942],\n",
      "        [ 0.3804],\n",
      "        [ 1.3041],\n",
      "        [15.2493],\n",
      "        [ 6.7226],\n",
      "        [ 8.3520],\n",
      "        [ 0.8313],\n",
      "        [ 1.8949],\n",
      "        [ 1.3856],\n",
      "        [ 2.2071],\n",
      "        [18.0118],\n",
      "        [15.6987],\n",
      "        [ 9.0741]])\n",
      "tensor([[ 1.4386],\n",
      "        [ 5.0999],\n",
      "        [ 1.3444],\n",
      "        [ 3.2082],\n",
      "        [ 3.1465],\n",
      "        [ 2.9356],\n",
      "        [ 3.9010],\n",
      "        [ 2.1995],\n",
      "        [ 8.8305],\n",
      "        [ 6.3340],\n",
      "        [10.5302],\n",
      "        [ 7.1256],\n",
      "        [ 5.4126],\n",
      "        [ 5.4505],\n",
      "        [ 2.8088],\n",
      "        [ 2.7842],\n",
      "        [ 3.2528],\n",
      "        [12.5629],\n",
      "        [ 7.9460],\n",
      "        [ 4.3651],\n",
      "        [ 5.0898],\n",
      "        [ 3.3358],\n",
      "        [ 3.2677],\n",
      "        [24.7446],\n",
      "        [ 9.6827],\n",
      "        [ 5.3687],\n",
      "        [ 2.7854],\n",
      "        [17.3521],\n",
      "        [ 1.3371],\n",
      "        [ 6.6922],\n",
      "        [24.3789],\n",
      "        [ 9.8124]])\n",
      "tensor([[ 0.6983],\n",
      "        [ 4.0222],\n",
      "        [ 8.3490],\n",
      "        [ 1.8197],\n",
      "        [ 0.8023],\n",
      "        [ 6.8185],\n",
      "        [ 3.0216],\n",
      "        [ 6.8454],\n",
      "        [ 2.2554],\n",
      "        [ 3.9510],\n",
      "        [ 7.2324],\n",
      "        [ 5.1431],\n",
      "        [ 2.4578],\n",
      "        [ 3.3851],\n",
      "        [ 0.7624],\n",
      "        [10.3381],\n",
      "        [ 8.1252],\n",
      "        [ 3.4240],\n",
      "        [ 2.1911],\n",
      "        [ 2.6937],\n",
      "        [14.3085],\n",
      "        [ 0.1926],\n",
      "        [ 3.4913],\n",
      "        [ 6.8319],\n",
      "        [ 9.7823],\n",
      "        [ 4.0669],\n",
      "        [14.5116],\n",
      "        [14.5672],\n",
      "        [13.9680],\n",
      "        [ 9.5724],\n",
      "        [10.8777],\n",
      "        [33.5427]])\n",
      "tensor([[ 5.5578],\n",
      "        [ 1.7574],\n",
      "        [12.7365],\n",
      "        [ 3.4692],\n",
      "        [ 2.2252],\n",
      "        [ 4.8297],\n",
      "        [ 7.9612],\n",
      "        [ 0.2437],\n",
      "        [ 8.8343],\n",
      "        [ 0.5961],\n",
      "        [ 8.4009],\n",
      "        [ 3.4505],\n",
      "        [ 1.4037],\n",
      "        [ 9.4449],\n",
      "        [ 5.3969],\n",
      "        [ 3.7632],\n",
      "        [13.6473],\n",
      "        [21.9606],\n",
      "        [ 1.3402],\n",
      "        [31.7747],\n",
      "        [ 0.8134],\n",
      "        [17.0992],\n",
      "        [ 4.5281],\n",
      "        [ 0.8132],\n",
      "        [ 7.3428],\n",
      "        [ 5.6884],\n",
      "        [ 9.5627],\n",
      "        [ 0.3771],\n",
      "        [ 2.4135],\n",
      "        [ 3.2354],\n",
      "        [ 5.7695],\n",
      "        [ 8.5449]])\n",
      "tensor([[ 3.3248],\n",
      "        [ 3.9534],\n",
      "        [11.8605],\n",
      "        [13.6659],\n",
      "        [ 9.3104],\n",
      "        [40.0244],\n",
      "        [ 9.4600],\n",
      "        [ 2.8667],\n",
      "        [ 1.4003],\n",
      "        [ 7.2852],\n",
      "        [20.9082],\n",
      "        [21.6751],\n",
      "        [11.2591],\n",
      "        [ 1.3001],\n",
      "        [ 2.8013],\n",
      "        [ 3.3040],\n",
      "        [ 0.5225],\n",
      "        [ 0.5484],\n",
      "        [ 5.3213],\n",
      "        [ 1.0803],\n",
      "        [ 6.4129],\n",
      "        [ 2.1560],\n",
      "        [ 8.8724],\n",
      "        [ 2.6750],\n",
      "        [ 3.0670],\n",
      "        [10.2765],\n",
      "        [ 1.6769],\n",
      "        [ 3.3879],\n",
      "        [ 7.2463],\n",
      "        [ 4.4867],\n",
      "        [29.4764],\n",
      "        [ 4.3243]])\n",
      "tensor([[ 3.3990],\n",
      "        [ 0.6343],\n",
      "        [ 7.3158],\n",
      "        [ 2.3225],\n",
      "        [ 5.7643],\n",
      "        [ 0.3337],\n",
      "        [ 1.5522],\n",
      "        [15.2375],\n",
      "        [ 8.0883],\n",
      "        [ 5.9052],\n",
      "        [ 4.2655],\n",
      "        [ 4.3083],\n",
      "        [ 8.2523],\n",
      "        [10.2610],\n",
      "        [ 6.1828],\n",
      "        [10.5705],\n",
      "        [ 3.6478],\n",
      "        [30.2649],\n",
      "        [ 2.6886],\n",
      "        [ 0.3143],\n",
      "        [ 6.1206],\n",
      "        [ 2.6067],\n",
      "        [ 4.4938],\n",
      "        [ 7.2655],\n",
      "        [ 1.4570],\n",
      "        [ 1.4891],\n",
      "        [ 7.3773],\n",
      "        [ 9.4457],\n",
      "        [13.0082],\n",
      "        [ 1.7959],\n",
      "        [17.6695],\n",
      "        [12.7087]])\n",
      "tensor([[ 5.0005],\n",
      "        [ 1.1014],\n",
      "        [ 2.5410],\n",
      "        [15.3214],\n",
      "        [ 6.1372],\n",
      "        [ 1.9122],\n",
      "        [ 2.6863],\n",
      "        [ 1.4466],\n",
      "        [ 4.4865],\n",
      "        [ 3.7775],\n",
      "        [ 2.8981],\n",
      "        [ 8.9779],\n",
      "        [17.8859],\n",
      "        [ 0.1801],\n",
      "        [ 1.5896],\n",
      "        [11.5646],\n",
      "        [ 1.2412],\n",
      "        [11.2233],\n",
      "        [ 5.9853],\n",
      "        [ 0.3943],\n",
      "        [ 1.0733],\n",
      "        [ 5.0757],\n",
      "        [ 1.6795],\n",
      "        [ 1.2603],\n",
      "        [ 3.7426],\n",
      "        [ 3.6370],\n",
      "        [11.2871],\n",
      "        [ 6.0511],\n",
      "        [ 5.0567],\n",
      "        [ 6.1506],\n",
      "        [13.6937],\n",
      "        [ 1.8672]])\n",
      "tensor([[ 2.0067],\n",
      "        [ 2.1376],\n",
      "        [ 3.4175],\n",
      "        [16.4524],\n",
      "        [ 1.8142],\n",
      "        [ 7.9011],\n",
      "        [ 6.7384],\n",
      "        [ 3.4225],\n",
      "        [ 0.5249],\n",
      "        [ 8.1611],\n",
      "        [ 6.1552],\n",
      "        [ 0.2223],\n",
      "        [ 2.7506],\n",
      "        [ 4.3668],\n",
      "        [ 2.5373],\n",
      "        [ 2.7772],\n",
      "        [ 1.3843],\n",
      "        [15.7897],\n",
      "        [ 2.9130],\n",
      "        [ 6.3029],\n",
      "        [ 1.4070],\n",
      "        [ 2.3098],\n",
      "        [36.2155],\n",
      "        [21.9742],\n",
      "        [ 3.8170],\n",
      "        [ 2.1316],\n",
      "        [ 2.2853],\n",
      "        [25.5652],\n",
      "        [ 7.3187],\n",
      "        [ 7.6493],\n",
      "        [19.9469],\n",
      "        [ 1.4484]])\n",
      "tensor([[12.4015],\n",
      "        [ 6.8854],\n",
      "        [10.8668],\n",
      "        [ 8.5968],\n",
      "        [ 4.3135],\n",
      "        [13.9645],\n",
      "        [ 0.5385],\n",
      "        [ 0.3534],\n",
      "        [ 6.8010],\n",
      "        [ 0.9754],\n",
      "        [ 6.2279],\n",
      "        [16.4868],\n",
      "        [ 1.2380],\n",
      "        [ 8.3465],\n",
      "        [ 0.6279],\n",
      "        [ 1.9987],\n",
      "        [ 5.9125],\n",
      "        [ 2.8019],\n",
      "        [ 5.1435],\n",
      "        [ 7.9208],\n",
      "        [ 0.4382],\n",
      "        [ 8.3691],\n",
      "        [ 8.6095],\n",
      "        [ 1.1555],\n",
      "        [ 8.5442],\n",
      "        [18.0582],\n",
      "        [ 4.3864],\n",
      "        [ 1.3576],\n",
      "        [ 3.0684],\n",
      "        [ 2.1636],\n",
      "        [ 7.6670],\n",
      "        [ 4.5085]])\n",
      "tensor([[ 3.0703],\n",
      "        [ 9.0467],\n",
      "        [ 0.3275],\n",
      "        [13.2212],\n",
      "        [ 5.6336],\n",
      "        [ 0.3845],\n",
      "        [ 1.5934],\n",
      "        [23.1739],\n",
      "        [ 1.6863],\n",
      "        [ 3.7167],\n",
      "        [ 4.0890],\n",
      "        [ 7.1444],\n",
      "        [10.3236],\n",
      "        [ 3.0414],\n",
      "        [ 1.1685],\n",
      "        [ 4.2912]])\n"
     ]
    }
   ],
   "source": [
    "for (data_x, data_y) in total_loader:\n",
    "    print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200;\n",
    "def run_training(fold,data,params,feature,property_,save_model):\n",
    "    ## mofdata total in it\n",
    "    ## data = total\n",
    "    if fold != 0:\n",
    "        kfold = KFold(n_splits = fold, shuffle = True)\n",
    "        model = Model(len(feature), dim1 = params[\"num_layers\"],fc_count = params[\"hidden_size\"])\n",
    "        model.to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=params[\"learning_rate\"])\n",
    "        eng = Engine(model,optimizer,device=DEVICE)\n",
    "\n",
    "        early_stopping_iter = 10\n",
    "        early_stopping_counter = 0\n",
    "        all_loss = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(data)):\n",
    "            best_loss = np.inf\n",
    "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "            val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "\n",
    "            train_loader = torch.utils.data.DataLoader(total,batch_size = params[\"batch_size\"], sampler = train_subsampler)\n",
    "            val_loader = torch.utils.data.DataLoader(total,batch_size = params[\"batch_size\"], sampler = val_subsampler)\n",
    "\n",
    "            for epoch in range(EPOCHS):\n",
    "                train_loss = eng.train(train_loader)\n",
    "                valid_loss, rmse,  = eng.evaluate(val_loader)\n",
    "                print(f\"fold: {fold}, epoch: {epoch}, \\\n",
    "                      train_loss : {train_loss}, valid_loss : {valid_loss}\")\n",
    "            \n",
    "                if valid_loss < best_loss:\n",
    "                          best_loss = valid_loss\n",
    "                          if save_model == True:\n",
    "                              torch.save(model.state_dict(),f\"best_model_geometric.pt\")\n",
    "                else:\n",
    "                    early_stopping_counter +=1\n",
    "\n",
    "                if early_stopping_counter > early_stopping_iter:\n",
    "                    break\n",
    "            all_loss.append(best_loss)\n",
    "        \n",
    "        return all_loss    \n",
    "\n",
    "                                \n",
    "                \n",
    "                \n",
    "    \n",
    "    else:\n",
    "        model = Model(len(feature), dim1 = params[\"num_layers\"],fc_count = params[\"hidden_size\"])\n",
    "        model.to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=params[\"learning_rate\"])\n",
    "        eng = Engine(model,optimizer,device=DEVICE)\n",
    "        \n",
    "        best_loss = np.inf\n",
    "        early_stopping_iter = 10\n",
    "        early_stopping_counter = 0\n",
    "        train_loader = torch.utils.data.DataLoader(data,batch_size = params[\"batch_size\"])\n",
    "        val_loader = torch.utils.data.DataLoader(data,batch_size = params[\"batch_size\"])\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss = eng.train(train_loader)\n",
    "            valid_loss = eng.evaluate(val_loader)\n",
    "            print(f\"fold: {fold}, epoch: {epoch}, \\\n",
    "                  train_loss : {train_loss}, valid_loss : {valid_loss}\")\n",
    "\n",
    "            if valid_loss < best_loss:\n",
    "                      best_loss = valid_loss\n",
    "                      if save_model == True:\n",
    "                          torch.save(model.state_dict(),f\"model_{feature}_result.pt\")\n",
    "            else:\n",
    "                early_stopping_counter +=1\n",
    "\n",
    "            if early_stopping_counter > early_stopping_iter:\n",
    "                break     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engine:\n",
    "    def __init__(self,model,optimizer,device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    @staticmethod\n",
    "    def loss_fn(targets,outputs):\n",
    "        \n",
    "        return nn.L1Loss()(outputs,targets)\n",
    "    \n",
    "    def train(self,data_loader):\n",
    "        self.model.train()\n",
    "        final_loss = 0\n",
    "        for (data_x,data_y) in data_loader:\n",
    "            self.optimizer.zero_grad()\n",
    "            inputs = data_x.to(self.device)\n",
    "            targets = data_y.to(self.device)\n",
    "            outputs = self.model(inputs)        \n",
    "            loss = self.loss_fn(targets,outputs)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            final_loss += loss.item()\n",
    "        \n",
    "        return final_loss / len(data_loader)\n",
    "\n",
    "    def evaluate(self,data_loader):\n",
    "        self.model.eval()\n",
    "        final_loss = 0\n",
    "        for (data_x,data_y) in data_loader:\n",
    "            inputs = data_x.to(self.device)\n",
    "            targets = data_y.to(self.device)\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.loss_fn(targets,outputs)\n",
    "            self.optimizer.step()\n",
    "            final_loss += loss.item()\n",
    "            r2 = R2SCORE(target, outputs)\n",
    "        return final_loss / len(data_loader), torch.sqrt(final_loss / len(data_loader)), r2 / len(data_loader)\n",
    "    \n",
    "                \n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_feature, dim1, fc_count):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(in_feature, dim1)\n",
    "        \n",
    "        self.lin_list = torch.nn.ModuleList(\n",
    "            [torch.nn.Linear(dim1,dim1) for i in range(fc_count)]\n",
    "        )\n",
    "        \n",
    "        self.lin2 = torch.nn.Linear(dim1,1)\n",
    "        \n",
    "    def forward(self,data):\n",
    "        \n",
    "        out = F.relu(self.lin1(data))\n",
    "        \n",
    "        for layer in self.lin_list:\n",
    "            out = F.relu(layer(out))\n",
    "            \n",
    "        out = self.lin2(out)\n",
    "        \n",
    "        if out.shape[1] == 1:\n",
    "            return out.view(-1)\n",
    "        \n",
    "        else:\n",
    "            return out\n",
    "        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:47:51,294]\u001b[0m A new study created in memory with name: no-name-3c7fa6c3-7f9f-4c3c-9fb8-c5ea9717aff7\u001b[0m\n",
      "/tmp/ipykernel_26735/925926161.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\",1e-4,0.05),\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([130, 1])) that is different to the input size (torch.Size([130])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([36, 1])) that is different to the input size (torch.Size([36])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 5.667218639737084, valid_loss : 6.162679036458333\n",
      "fold: 0, epoch: 1,                       train_loss : 5.216561294737316, valid_loss : 5.107529799143474\n",
      "fold: 0, epoch: 2,                       train_loss : 4.649856533323016, valid_loss : 4.47592560450236\n",
      "fold: 0, epoch: 3,                       train_loss : 4.287345466159639, valid_loss : 4.269533554712932\n",
      "fold: 0, epoch: 4,                       train_loss : 4.127346685954502, valid_loss : 4.342817624409993\n",
      "fold: 0, epoch: 5,                       train_loss : 4.151362351008824, valid_loss : 3.8713952700297036\n",
      "fold: 0, epoch: 6,                       train_loss : 4.150299844287691, valid_loss : 4.1183234850565595\n",
      "fold: 0, epoch: 7,                       train_loss : 4.1725830804734, valid_loss : 3.950106700261434\n",
      "fold: 0, epoch: 8,                       train_loss : 4.108336505435762, valid_loss : 4.025806188583374\n",
      "fold: 0, epoch: 9,                       train_loss : 4.115937777927944, valid_loss : 4.242871046066284\n",
      "fold: 0, epoch: 10,                       train_loss : 4.132052228564308, valid_loss : 3.8623414834340415\n",
      "fold: 0, epoch: 11,                       train_loss : 4.12157620702471, valid_loss : 4.0263261795043945\n",
      "fold: 0, epoch: 12,                       train_loss : 4.136937039239066, valid_loss : 4.508487542470296\n",
      "fold: 0, epoch: 13,                       train_loss : 4.177784090950375, valid_loss : 4.193531195322673\n",
      "fold: 0, epoch: 14,                       train_loss : 4.145514703932262, valid_loss : 4.064437548319499\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1329307442619685, valid_loss : 4.159409205118815\n",
      "fold: 0, epoch: 16,                       train_loss : 4.150278727213542, valid_loss : 4.083698590596517\n",
      "fold: 1, epoch: 0,                       train_loss : 4.175400143577939, valid_loss : 3.4187870820363364\n",
      "fold: 2, epoch: 0,                       train_loss : 4.136185532524472, valid_loss : 4.021561066309611\n",
      "fold: 3, epoch: 0,                       train_loss : 4.0506172974904375, valid_loss : 4.474819819132487\n",
      "fold: 4, epoch: 0,                       train_loss : 4.14486559232076, valid_loss : 3.801942825317383\n",
      "fold: 5, epoch: 0,                       train_loss : 4.084397701990037, valid_loss : 4.062999169031779\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1802584784371515, valid_loss : 3.812217950820923\n",
      "fold: 7, epoch: 0,                       train_loss : 4.182484865188599, valid_loss : 3.8117764790852866\n",
      "fold: 8, epoch: 0,                       train_loss : 4.032278299331665, valid_loss : 4.933218638102214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:48:06,468]\u001b[0m Trial 0 finished with value: 3.9903782526652014 and parameters: {'num_layers': 6, 'hidden_size': 50, 'batch_size': 130, 'learning_rate': 0.0071408467019819155}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.167384647187733, valid_loss : 3.704118013381958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([160, 1])) that is different to the input size (torch.Size([160])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([104, 1])) that is different to the input size (torch.Size([104])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([136, 1])) that is different to the input size (torch.Size([136])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 6.177944912629969, valid_loss : 6.615502834320068\n",
      "fold: 0, epoch: 1,                       train_loss : 6.076002653907327, valid_loss : 6.469660520553589\n",
      "fold: 0, epoch: 2,                       train_loss : 5.956666357376996, valid_loss : 6.3546717166900635\n",
      "fold: 0, epoch: 3,                       train_loss : 5.8612289709203385, valid_loss : 6.251849174499512\n",
      "fold: 0, epoch: 4,                       train_loss : 5.800774462082806, valid_loss : 6.203948259353638\n",
      "fold: 0, epoch: 5,                       train_loss : 5.6727840199190025, valid_loss : 6.1228766441345215\n",
      "fold: 0, epoch: 6,                       train_loss : 5.564257425420425, valid_loss : 5.987234115600586\n",
      "fold: 0, epoch: 7,                       train_loss : 5.45867602965411, valid_loss : 5.852742910385132\n",
      "fold: 0, epoch: 8,                       train_loss : 5.311802331139059, valid_loss : 5.741689443588257\n",
      "fold: 0, epoch: 9,                       train_loss : 5.186928328345804, valid_loss : 5.586364269256592\n",
      "fold: 0, epoch: 10,                       train_loss : 4.99849058600033, valid_loss : 5.399674892425537\n",
      "fold: 0, epoch: 11,                       train_loss : 4.841008424758911, valid_loss : 5.188438653945923\n",
      "fold: 0, epoch: 12,                       train_loss : 4.691746403189266, valid_loss : 5.133829832077026\n",
      "fold: 0, epoch: 13,                       train_loss : 4.507307038587682, valid_loss : 4.908324241638184\n",
      "fold: 0, epoch: 14,                       train_loss : 4.389594905516681, valid_loss : 4.796216726303101\n",
      "fold: 0, epoch: 15,                       train_loss : 4.296551998923807, valid_loss : 4.64095401763916\n",
      "fold: 0, epoch: 16,                       train_loss : 4.2352659281562355, valid_loss : 4.602006673812866\n",
      "fold: 0, epoch: 17,                       train_loss : 4.165514342925128, valid_loss : 4.551220417022705\n",
      "fold: 0, epoch: 18,                       train_loss : 4.165766379412482, valid_loss : 4.512692213058472\n",
      "fold: 0, epoch: 19,                       train_loss : 4.12338150248808, valid_loss : 4.437325716018677\n",
      "fold: 0, epoch: 20,                       train_loss : 4.10467656920938, valid_loss : 4.401515960693359\n",
      "fold: 0, epoch: 21,                       train_loss : 4.102897363550523, valid_loss : 4.45531702041626\n",
      "fold: 0, epoch: 22,                       train_loss : 4.085565454819623, valid_loss : 4.469591736793518\n",
      "fold: 0, epoch: 23,                       train_loss : 4.103143944459803, valid_loss : 4.4054951667785645\n",
      "fold: 0, epoch: 24,                       train_loss : 4.086361562504488, valid_loss : 4.454838991165161\n",
      "fold: 0, epoch: 25,                       train_loss : 4.101107961991254, valid_loss : 4.3991005420684814\n",
      "fold: 0, epoch: 26,                       train_loss : 4.0992068823646095, valid_loss : 4.38556694984436\n",
      "fold: 0, epoch: 27,                       train_loss : 4.109836101531982, valid_loss : 4.398539066314697\n",
      "fold: 0, epoch: 28,                       train_loss : 4.126550730536966, valid_loss : 4.415377378463745\n",
      "fold: 0, epoch: 29,                       train_loss : 4.091707187540391, valid_loss : 4.390639781951904\n",
      "fold: 0, epoch: 30,                       train_loss : 4.099800025715547, valid_loss : 4.3708354234695435\n",
      "fold: 0, epoch: 31,                       train_loss : 4.092310975579655, valid_loss : 4.498189806938171\n",
      "fold: 0, epoch: 32,                       train_loss : 4.093249306959264, valid_loss : 4.423349857330322\n",
      "fold: 0, epoch: 33,                       train_loss : 4.105001828249763, valid_loss : 4.456935167312622\n",
      "fold: 0, epoch: 34,                       train_loss : 4.094645331887638, valid_loss : 4.3911097049713135\n",
      "fold: 1, epoch: 0,                       train_loss : 4.0856695455663345, valid_loss : 4.525233507156372\n",
      "fold: 2, epoch: 0,                       train_loss : 4.184223020777983, valid_loss : 3.6836135387420654\n",
      "fold: 3, epoch: 0,                       train_loss : 4.153466799679925, valid_loss : 3.8602495193481445\n",
      "fold: 4, epoch: 0,                       train_loss : 4.094116996316349, valid_loss : 4.43544602394104\n",
      "fold: 5, epoch: 0,                       train_loss : 4.181642658570233, valid_loss : 3.8629268407821655\n",
      "fold: 6, epoch: 0,                       train_loss : 4.124416954377118, valid_loss : 4.251923084259033\n",
      "fold: 7, epoch: 0,                       train_loss : 4.165786350474638, valid_loss : 3.911829948425293\n",
      "fold: 8, epoch: 0,                       train_loss : 4.119939551633947, valid_loss : 4.269442319869995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:48:45,934]\u001b[0m Trial 1 finished with value: 4.127348589897156 and parameters: {'num_layers': 6, 'hidden_size': 150, 'batch_size': 160, 'learning_rate': 0.0016745025128723286}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.14314213921042, valid_loss : 4.101985692977905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([90, 1])) that is different to the input size (torch.Size([90])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([54, 1])) that is different to the input size (torch.Size([54])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([26, 1])) that is different to the input size (torch.Size([26])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 5.8252373218536375, valid_loss : 5.545157194137573\n",
      "fold: 0, epoch: 1,                       train_loss : 4.660530678431193, valid_loss : 5.43246203660965\n",
      "fold: 0, epoch: 2,                       train_loss : 4.2226735830307005, valid_loss : 4.539869010448456\n",
      "fold: 0, epoch: 3,                       train_loss : 4.1067557573318485, valid_loss : 4.774790048599243\n",
      "fold: 0, epoch: 4,                       train_loss : 4.0814123551050825, valid_loss : 4.638216614723206\n",
      "fold: 0, epoch: 5,                       train_loss : 4.080243865648906, valid_loss : 4.846254825592041\n",
      "fold: 0, epoch: 6,                       train_loss : 4.07706180413564, valid_loss : 4.393959403038025\n",
      "fold: 0, epoch: 7,                       train_loss : 4.08214803536733, valid_loss : 5.237377941608429\n",
      "fold: 0, epoch: 8,                       train_loss : 4.086931006113688, valid_loss : 4.462173819541931\n",
      "fold: 0, epoch: 9,                       train_loss : 4.077285432815552, valid_loss : 4.712495684623718\n",
      "fold: 0, epoch: 10,                       train_loss : 4.102694678306579, valid_loss : 4.871581077575684\n",
      "fold: 0, epoch: 11,                       train_loss : 4.0926429271698, valid_loss : 4.544390261173248\n",
      "fold: 0, epoch: 12,                       train_loss : 4.081769188245137, valid_loss : 5.164226055145264\n",
      "fold: 0, epoch: 13,                       train_loss : 4.075287000338236, valid_loss : 4.318536996841431\n",
      "fold: 0, epoch: 14,                       train_loss : 4.066409277915954, valid_loss : 4.326421678066254\n",
      "fold: 0, epoch: 15,                       train_loss : 4.079455788930257, valid_loss : 4.457857012748718\n",
      "fold: 1, epoch: 0,                       train_loss : 4.144889585177103, valid_loss : 4.02347058057785\n",
      "fold: 2, epoch: 0,                       train_loss : 4.137869842847189, valid_loss : 3.8211382031440735\n",
      "fold: 3, epoch: 0,                       train_loss : 4.179834191004435, valid_loss : 3.964422821998596\n",
      "fold: 4, epoch: 0,                       train_loss : 4.106334487597148, valid_loss : 4.1081127524375916\n",
      "fold: 5, epoch: 0,                       train_loss : 4.174494727452596, valid_loss : 4.07801878452301\n",
      "fold: 6, epoch: 0,                       train_loss : 4.164762576421102, valid_loss : 3.754493772983551\n",
      "fold: 7, epoch: 0,                       train_loss : 4.1885427554448444, valid_loss : 3.741103231906891\n",
      "fold: 8, epoch: 0,                       train_loss : 4.088899477322896, valid_loss : 4.962003409862518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:49:05,512]\u001b[0m Trial 2 finished with value: 4.123859769105911 and parameters: {'num_layers': 1, 'hidden_size': 60, 'batch_size': 90, 'learning_rate': 0.0489285568793544}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.082400743166605, valid_loss : 4.4672971367836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([170, 1])) that is different to the input size (torch.Size([170])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([114, 1])) that is different to the input size (torch.Size([114])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([126, 1])) that is different to the input size (torch.Size([126])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 6.687767177820206, valid_loss : 5.965519189834595\n",
      "fold: 0, epoch: 1,                       train_loss : 6.613623887300491, valid_loss : 6.0289671421051025\n",
      "fold: 0, epoch: 2,                       train_loss : 6.5727454125881195, valid_loss : 5.941373109817505\n",
      "fold: 0, epoch: 3,                       train_loss : 6.552952796220779, valid_loss : 5.890034198760986\n",
      "fold: 0, epoch: 4,                       train_loss : 6.484756767749786, valid_loss : 5.871023416519165\n",
      "fold: 0, epoch: 5,                       train_loss : 6.442357420921326, valid_loss : 5.809700965881348\n",
      "fold: 0, epoch: 6,                       train_loss : 6.4234082996845245, valid_loss : 5.8215343952178955\n",
      "fold: 0, epoch: 7,                       train_loss : 6.403597176074982, valid_loss : 5.766972303390503\n",
      "fold: 0, epoch: 8,                       train_loss : 6.3594324588775635, valid_loss : 5.728600740432739\n",
      "fold: 0, epoch: 9,                       train_loss : 6.3465977013111115, valid_loss : 5.776071548461914\n",
      "fold: 0, epoch: 10,                       train_loss : 6.313311904668808, valid_loss : 5.689329147338867\n",
      "fold: 0, epoch: 11,                       train_loss : 6.3029274344444275, valid_loss : 5.79948091506958\n",
      "fold: 0, epoch: 12,                       train_loss : 6.287260115146637, valid_loss : 5.698059320449829\n",
      "fold: 0, epoch: 13,                       train_loss : 6.241838991641998, valid_loss : 5.527543067932129\n",
      "fold: 0, epoch: 14,                       train_loss : 6.239221572875977, valid_loss : 5.5420427322387695\n",
      "fold: 0, epoch: 15,                       train_loss : 6.204176425933838, valid_loss : 5.582907438278198\n",
      "fold: 0, epoch: 16,                       train_loss : 6.19635546207428, valid_loss : 5.564660310745239\n",
      "fold: 0, epoch: 17,                       train_loss : 6.186776787042618, valid_loss : 5.657111644744873\n",
      "fold: 0, epoch: 18,                       train_loss : 6.18192845582962, valid_loss : 5.544030427932739\n",
      "fold: 0, epoch: 19,                       train_loss : 6.17462432384491, valid_loss : 5.668910264968872\n",
      "fold: 1, epoch: 0,                       train_loss : 6.041756808757782, valid_loss : 6.742346525192261\n",
      "fold: 2, epoch: 0,                       train_loss : 6.080691069364548, valid_loss : 6.194006443023682\n",
      "fold: 3, epoch: 0,                       train_loss : 6.0805346965789795, valid_loss : 6.1875457763671875\n",
      "fold: 4, epoch: 0,                       train_loss : 6.036998361349106, valid_loss : 6.147477865219116\n",
      "fold: 5, epoch: 0,                       train_loss : 6.117539793252945, valid_loss : 5.6956682205200195\n",
      "fold: 6, epoch: 0,                       train_loss : 6.052904516458511, valid_loss : 6.177502632141113\n",
      "fold: 7, epoch: 0,                       train_loss : 6.1126541793346405, valid_loss : 5.510582208633423\n",
      "fold: 8, epoch: 0,                       train_loss : 6.02165687084198, valid_loss : 6.08732271194458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:49:31,240]\u001b[0m Trial 3 finished with value: 6.064650821685791 and parameters: {'num_layers': 2, 'hidden_size': 150, 'batch_size': 170, 'learning_rate': 0.0006027118442121444}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 5.970261454582214, valid_loss : 6.376512765884399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([120, 1])) that is different to the input size (torch.Size([120])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([24, 1])) that is different to the input size (torch.Size([24])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([56, 1])) that is different to the input size (torch.Size([56])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 5.770782118258269, valid_loss : 4.879627227783203\n",
      "fold: 0, epoch: 1,                       train_loss : 4.921482210573942, valid_loss : 4.089519103368123\n",
      "fold: 0, epoch: 2,                       train_loss : 4.494386424189028, valid_loss : 4.086071332295735\n",
      "fold: 0, epoch: 3,                       train_loss : 4.3549844907677695, valid_loss : 3.8757992585500083\n",
      "fold: 0, epoch: 4,                       train_loss : 4.21518644042637, valid_loss : 3.662656863530477\n",
      "fold: 0, epoch: 5,                       train_loss : 4.218639632929927, valid_loss : 3.6722936630249023\n",
      "fold: 0, epoch: 6,                       train_loss : 4.152468629505323, valid_loss : 3.681868235270182\n",
      "fold: 0, epoch: 7,                       train_loss : 4.258806301199871, valid_loss : 4.233609835306804\n",
      "fold: 0, epoch: 8,                       train_loss : 4.2076504437819775, valid_loss : 3.7697548866271973\n",
      "fold: 0, epoch: 9,                       train_loss : 4.149422821791275, valid_loss : 3.8920772075653076\n",
      "fold: 0, epoch: 10,                       train_loss : 4.140547202981037, valid_loss : 3.8366708755493164\n",
      "fold: 0, epoch: 11,                       train_loss : 4.16969396757043, valid_loss : 3.855933507283529\n",
      "fold: 0, epoch: 12,                       train_loss : 4.112995168437129, valid_loss : 3.8520469665527344\n",
      "fold: 0, epoch: 13,                       train_loss : 4.148814605629963, valid_loss : 3.7365825176239014\n",
      "fold: 0, epoch: 14,                       train_loss : 4.163875600566035, valid_loss : 3.676060517628988\n",
      "fold: 0, epoch: 15,                       train_loss : 4.210450421208921, valid_loss : 4.088967164357503\n",
      "fold: 1, epoch: 0,                       train_loss : 4.207011233205381, valid_loss : 3.5218657652537027\n",
      "fold: 2, epoch: 0,                       train_loss : 4.079528020775837, valid_loss : 4.2123918533325195\n",
      "fold: 3, epoch: 0,                       train_loss : 4.094524476839148, valid_loss : 4.0435324509938555\n",
      "fold: 4, epoch: 0,                       train_loss : 4.0717199885326885, valid_loss : 4.379146973292033\n",
      "fold: 5, epoch: 0,                       train_loss : 4.003558687541796, valid_loss : 5.023015022277832\n",
      "fold: 6, epoch: 0,                       train_loss : 4.247287211210831, valid_loss : 4.162098487218221\n",
      "fold: 7, epoch: 0,                       train_loss : 4.106662853904393, valid_loss : 4.216877778371175\n",
      "fold: 8, epoch: 0,                       train_loss : 4.1221717544223955, valid_loss : 3.928971608479818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:49:43,108]\u001b[0m Trial 4 finished with value: 4.059901467959087 and parameters: {'num_layers': 3, 'hidden_size': 40, 'batch_size': 120, 'learning_rate': 0.0357450823619856}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.149141850678817, valid_loss : 3.448457876841227\n",
      "fold: 0, epoch: 0,                       train_loss : 6.01717819887049, valid_loss : 5.763985872268677\n",
      "fold: 0, epoch: 1,                       train_loss : 6.011136475731345, valid_loss : 5.682482719421387\n",
      "fold: 0, epoch: 2,                       train_loss : 6.0221434761496155, valid_loss : 5.799981594085693\n",
      "fold: 0, epoch: 3,                       train_loss : 6.004382974961224, valid_loss : 5.674022912979126\n",
      "fold: 0, epoch: 4,                       train_loss : 5.983733317431281, valid_loss : 5.673515796661377\n",
      "fold: 0, epoch: 5,                       train_loss : 5.990750368903665, valid_loss : 5.700309753417969\n",
      "fold: 0, epoch: 6,                       train_loss : 5.985527038574219, valid_loss : 5.720397233963013\n",
      "fold: 0, epoch: 7,                       train_loss : 5.969891043270335, valid_loss : 5.663581132888794\n",
      "fold: 0, epoch: 8,                       train_loss : 5.969526851878447, valid_loss : 5.621532917022705\n",
      "fold: 0, epoch: 9,                       train_loss : 5.978765459621654, valid_loss : 5.641582489013672\n",
      "fold: 0, epoch: 10,                       train_loss : 5.9569644086501174, valid_loss : 5.676289319992065\n",
      "fold: 0, epoch: 11,                       train_loss : 5.961758108700023, valid_loss : 5.663472414016724\n",
      "fold: 0, epoch: 12,                       train_loss : 5.943943416371065, valid_loss : 5.705658674240112\n",
      "fold: 0, epoch: 13,                       train_loss : 5.93069143856273, valid_loss : 5.637897968292236\n",
      "fold: 0, epoch: 14,                       train_loss : 5.943400354946361, valid_loss : 5.630577802658081\n",
      "fold: 0, epoch: 15,                       train_loss : 5.939161468954647, valid_loss : 5.60172438621521\n",
      "fold: 0, epoch: 16,                       train_loss : 5.916311712825999, valid_loss : 5.609622001647949\n",
      "fold: 0, epoch: 17,                       train_loss : 5.916519389433019, valid_loss : 5.597477674484253\n",
      "fold: 0, epoch: 18,                       train_loss : 5.907340274137609, valid_loss : 5.64411997795105\n",
      "fold: 1, epoch: 0,                       train_loss : 5.923334850984461, valid_loss : 5.284813642501831\n",
      "fold: 2, epoch: 0,                       train_loss : 5.790848900290096, valid_loss : 6.738812685012817\n",
      "fold: 3, epoch: 0,                       train_loss : 5.734704550574808, valid_loss : 6.773045301437378\n",
      "fold: 4, epoch: 0,                       train_loss : 5.873821819529814, valid_loss : 5.718620538711548\n",
      "fold: 5, epoch: 0,                       train_loss : 5.8202760640312645, valid_loss : 6.3066511154174805\n",
      "fold: 6, epoch: 0,                       train_loss : 5.900338229011087, valid_loss : 5.395951509475708\n",
      "fold: 7, epoch: 0,                       train_loss : 5.879573653726017, valid_loss : 5.5702009201049805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:49:48,604]\u001b[0m Trial 5 finished with value: 5.86061646938324 and parameters: {'num_layers': 3, 'hidden_size': 20, 'batch_size': 160, 'learning_rate': 0.0003178134991138209}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 8, epoch: 0,                       train_loss : 5.878796409158146, valid_loss : 5.453602075576782\n",
      "fold: 9, epoch: 0,                       train_loss : 5.828057822059183, valid_loss : 5.766989231109619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([70, 1])) that is different to the input size (torch.Size([70])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([16, 1])) that is different to the input size (torch.Size([16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 5.66198286643395, valid_loss : 6.3283483505249025\n",
      "fold: 0, epoch: 1,                       train_loss : 5.4643886517255735, valid_loss : 6.408890438079834\n",
      "fold: 0, epoch: 2,                       train_loss : 5.435846261489085, valid_loss : 6.302116012573242\n",
      "fold: 0, epoch: 3,                       train_loss : 5.076048851013184, valid_loss : 5.764177513122559\n",
      "fold: 0, epoch: 4,                       train_loss : 5.258694948294224, valid_loss : 5.364570808410645\n",
      "fold: 0, epoch: 5,                       train_loss : 4.741698760252732, valid_loss : 5.107438945770264\n",
      "fold: 0, epoch: 6,                       train_loss : 4.552599246685322, valid_loss : 4.989919376373291\n",
      "fold: 0, epoch: 7,                       train_loss : 4.407953656636751, valid_loss : 4.923254299163818\n",
      "fold: 0, epoch: 8,                       train_loss : 4.372896335063836, valid_loss : 4.525701332092285\n",
      "fold: 0, epoch: 9,                       train_loss : 4.365612965363723, valid_loss : 5.1630659103393555\n",
      "fold: 0, epoch: 10,                       train_loss : 4.1842634463921575, valid_loss : 5.161421489715576\n",
      "fold: 0, epoch: 11,                       train_loss : 4.251216900654328, valid_loss : 4.642708492279053\n",
      "fold: 0, epoch: 12,                       train_loss : 4.3882966714027605, valid_loss : 4.820390939712524\n",
      "fold: 0, epoch: 13,                       train_loss : 4.2486942792550115, valid_loss : 4.5625701427459715\n",
      "fold: 0, epoch: 14,                       train_loss : 4.077143357350276, valid_loss : 4.135886335372925\n",
      "fold: 0, epoch: 15,                       train_loss : 4.050559673553858, valid_loss : 4.509725284576416\n",
      "fold: 0, epoch: 16,                       train_loss : 4.18773550253648, valid_loss : 4.457520294189453\n",
      "fold: 0, epoch: 17,                       train_loss : 4.049819463338608, valid_loss : 4.691548919677734\n",
      "fold: 0, epoch: 18,                       train_loss : 4.058411365900284, valid_loss : 4.235849475860595\n",
      "fold: 0, epoch: 19,                       train_loss : 4.071548700332642, valid_loss : 4.367751979827881\n",
      "fold: 1, epoch: 0,                       train_loss : 4.137436347130017, valid_loss : 3.6817499160766602\n",
      "fold: 2, epoch: 0,                       train_loss : 4.338419657487136, valid_loss : 4.250249338150025\n",
      "fold: 3, epoch: 0,                       train_loss : 4.122895607581506, valid_loss : 4.544653606414795\n",
      "fold: 4, epoch: 0,                       train_loss : 4.094242701163659, valid_loss : 4.598216581344604\n",
      "fold: 5, epoch: 0,                       train_loss : 4.281488137367444, valid_loss : 3.834838104248047\n",
      "fold: 6, epoch: 0,                       train_loss : 4.10320859688979, valid_loss : 3.77227201461792\n",
      "fold: 7, epoch: 0,                       train_loss : 4.201638441819411, valid_loss : 4.232116222381592\n",
      "fold: 8, epoch: 0,                       train_loss : 4.097232439579108, valid_loss : 4.271977281570434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:50:43,725]\u001b[0m Trial 6 finished with value: 4.152178349494934 and parameters: {'num_layers': 3, 'hidden_size': 140, 'batch_size': 70, 'learning_rate': 0.0019310304218467893}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.245002624316093, valid_loss : 4.199824094772339\n",
      "fold: 0, epoch: 0,                       train_loss : 6.218964038751064, valid_loss : 6.556596660614014\n",
      "fold: 0, epoch: 1,                       train_loss : 6.201018150036152, valid_loss : 6.264344024658203\n",
      "fold: 0, epoch: 2,                       train_loss : 6.039295722276736, valid_loss : 7.374635410308838\n",
      "fold: 0, epoch: 3,                       train_loss : 5.875693033903073, valid_loss : 6.191109943389892\n",
      "fold: 0, epoch: 4,                       train_loss : 5.902614642412234, valid_loss : 6.338088703155518\n",
      "fold: 0, epoch: 5,                       train_loss : 5.756338070600461, valid_loss : 5.583522844314575\n",
      "fold: 0, epoch: 6,                       train_loss : 5.581479524954771, valid_loss : 5.693991184234619\n",
      "fold: 0, epoch: 7,                       train_loss : 5.1712543322489815, valid_loss : 4.9309934854507445\n",
      "fold: 0, epoch: 8,                       train_loss : 5.022402763366699, valid_loss : 5.570617580413819\n",
      "fold: 0, epoch: 9,                       train_loss : 4.466936453794822, valid_loss : 4.499799394607544\n",
      "fold: 0, epoch: 10,                       train_loss : 4.138816298582615, valid_loss : 4.44099760055542\n",
      "fold: 0, epoch: 11,                       train_loss : 4.132362047831218, valid_loss : 4.503804302215576\n",
      "fold: 0, epoch: 12,                       train_loss : 4.042577969722259, valid_loss : 4.903956937789917\n",
      "fold: 0, epoch: 13,                       train_loss : 4.039760482616914, valid_loss : 4.670006370544433\n",
      "fold: 0, epoch: 14,                       train_loss : 4.023942164885692, valid_loss : 4.172336483001709\n",
      "fold: 0, epoch: 15,                       train_loss : 4.099856462234106, valid_loss : 4.33988242149353\n",
      "fold: 0, epoch: 16,                       train_loss : 4.018346522098932, valid_loss : 4.339485311508179\n",
      "fold: 0, epoch: 17,                       train_loss : 4.032501660860502, valid_loss : 4.366580486297607\n",
      "fold: 0, epoch: 18,                       train_loss : 4.100423605014116, valid_loss : 4.520738124847412\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1499143196986275, valid_loss : 4.031407737731934\n",
      "fold: 2, epoch: 0,                       train_loss : 4.275623211493859, valid_loss : 4.232278060913086\n",
      "fold: 3, epoch: 0,                       train_loss : 4.09142910517179, valid_loss : 3.8443902492523194\n",
      "fold: 4, epoch: 0,                       train_loss : 4.453812953753349, valid_loss : 3.7152916431427\n",
      "fold: 5, epoch: 0,                       train_loss : 4.0933086933233795, valid_loss : 3.77453236579895\n",
      "fold: 6, epoch: 0,                       train_loss : 4.395783320451394, valid_loss : 4.033787202835083\n",
      "fold: 7, epoch: 0,                       train_loss : 4.11218880995726, valid_loss : 3.8607699394226076\n",
      "fold: 8, epoch: 0,                       train_loss : 3.963225318835332, valid_loss : 5.442033481597901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:51:12,622]\u001b[0m Trial 7 finished with value: 4.13496307849884 and parameters: {'num_layers': 6, 'hidden_size': 60, 'batch_size': 70, 'learning_rate': 0.00034007298019016945}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.0867785184811325, valid_loss : 4.242803621292114\n",
      "fold: 0, epoch: 0,                       train_loss : 6.071569442749023, valid_loss : 5.322325070699056\n",
      "fold: 0, epoch: 1,                       train_loss : 6.051936104184105, valid_loss : 4.896510044733684\n",
      "fold: 0, epoch: 2,                       train_loss : 6.041624636877151, valid_loss : 5.446890195210774\n",
      "fold: 0, epoch: 3,                       train_loss : 5.9918938137236095, valid_loss : 5.042134126027425\n",
      "fold: 0, epoch: 4,                       train_loss : 6.010094710758755, valid_loss : 5.166466236114502\n",
      "fold: 0, epoch: 5,                       train_loss : 5.981956799825032, valid_loss : 5.065376281738281\n",
      "fold: 0, epoch: 6,                       train_loss : 5.974534784044538, valid_loss : 5.197523593902588\n",
      "fold: 0, epoch: 7,                       train_loss : 5.948428653535389, valid_loss : 5.439206441243489\n",
      "fold: 0, epoch: 8,                       train_loss : 5.914129302615211, valid_loss : 5.341832319895427\n",
      "fold: 0, epoch: 9,                       train_loss : 5.916268939063663, valid_loss : 5.349579493204753\n",
      "fold: 0, epoch: 10,                       train_loss : 5.93036751520066, valid_loss : 5.398094654083252\n",
      "fold: 0, epoch: 11,                       train_loss : 5.896466573079427, valid_loss : 4.994446595509847\n",
      "fold: 0, epoch: 12,                       train_loss : 5.844503402709961, valid_loss : 5.293117682139079\n",
      "fold: 1, epoch: 0,                       train_loss : 5.773170266832624, valid_loss : 5.67358938852946\n",
      "fold: 2, epoch: 0,                       train_loss : 5.711718672797794, valid_loss : 5.894178549448649\n",
      "fold: 3, epoch: 0,                       train_loss : 5.744688737960089, valid_loss : 6.1679426829020185\n",
      "fold: 4, epoch: 0,                       train_loss : 5.705954687935965, valid_loss : 5.820071697235107\n",
      "fold: 5, epoch: 0,                       train_loss : 5.770802951994396, valid_loss : 4.953274091084798\n",
      "fold: 6, epoch: 0,                       train_loss : 5.641290573846726, valid_loss : 6.219160556793213\n",
      "fold: 7, epoch: 0,                       train_loss : 5.611686411358061, valid_loss : 5.991259574890137\n",
      "fold: 8, epoch: 0,                       train_loss : 5.649949187324161, valid_loss : 5.047241767247518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:51:39,292]\u001b[0m Trial 8 finished with value: 5.667366377512614 and parameters: {'num_layers': 2, 'hidden_size': 170, 'batch_size': 130, 'learning_rate': 0.00012184929958604871}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 5.649940309070406, valid_loss : 6.010435422261556\n",
      "fold: 0, epoch: 0,                       train_loss : 5.425145998597145, valid_loss : 3.801385998725891\n",
      "fold: 0, epoch: 1,                       train_loss : 4.215260490775108, valid_loss : 3.8539973497390747\n",
      "fold: 0, epoch: 2,                       train_loss : 4.1805664002895355, valid_loss : 3.8134394884109497\n",
      "fold: 0, epoch: 3,                       train_loss : 4.161111697554588, valid_loss : 3.7457553148269653\n",
      "fold: 0, epoch: 4,                       train_loss : 4.180560007691383, valid_loss : 3.8073395490646362\n",
      "fold: 0, epoch: 5,                       train_loss : 4.187213405966759, valid_loss : 3.842717409133911\n",
      "fold: 0, epoch: 6,                       train_loss : 4.182635515928268, valid_loss : 3.858538508415222\n",
      "fold: 0, epoch: 7,                       train_loss : 4.172576129436493, valid_loss : 3.9289079904556274\n",
      "fold: 0, epoch: 8,                       train_loss : 4.171699747443199, valid_loss : 3.7814091444015503\n",
      "fold: 0, epoch: 9,                       train_loss : 4.166663408279419, valid_loss : 3.8999762535095215\n",
      "fold: 0, epoch: 10,                       train_loss : 4.168047800660133, valid_loss : 3.884767174720764\n",
      "fold: 0, epoch: 11,                       train_loss : 4.165097191929817, valid_loss : 3.872868776321411\n",
      "fold: 0, epoch: 12,                       train_loss : 4.163360178470612, valid_loss : 3.9353328943252563\n",
      "fold: 1, epoch: 0,                       train_loss : 4.16617825627327, valid_loss : 3.9321309328079224\n",
      "fold: 2, epoch: 0,                       train_loss : 4.127286612987518, valid_loss : 4.301758766174316\n",
      "fold: 3, epoch: 0,                       train_loss : 4.099472224712372, valid_loss : 4.396422863006592\n",
      "fold: 4, epoch: 0,                       train_loss : 4.147721171379089, valid_loss : 4.084947109222412\n",
      "fold: 5, epoch: 0,                       train_loss : 4.135948047041893, valid_loss : 4.170137166976929\n",
      "fold: 6, epoch: 0,                       train_loss : 4.108721882104874, valid_loss : 4.402485132217407\n",
      "fold: 7, epoch: 0,                       train_loss : 4.171571210026741, valid_loss : 4.030732870101929\n",
      "fold: 8, epoch: 0,                       train_loss : 4.150582909584045, valid_loss : 4.043883204460144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:51:55,419]\u001b[0m Trial 9 finished with value: 4.134764301776886 and parameters: {'num_layers': 6, 'hidden_size': 120, 'batch_size': 170, 'learning_rate': 0.018829473300838326}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.117740944027901, valid_loss : 4.239389657974243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([30, 1])) that is different to the input size (torch.Size([30])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 5.706395859128974, valid_loss : 3.92440721988678\n",
      "fold: 0, epoch: 1,                       train_loss : 4.264481231067958, valid_loss : 3.6419872045516968\n",
      "fold: 0, epoch: 2,                       train_loss : 4.194069500719563, valid_loss : 3.6585609197616575\n",
      "fold: 0, epoch: 3,                       train_loss : 4.195843493000845, valid_loss : 3.6290691614151003\n",
      "fold: 0, epoch: 4,                       train_loss : 4.199334589283118, valid_loss : 3.617751884460449\n",
      "fold: 0, epoch: 5,                       train_loss : 4.188939758900846, valid_loss : 3.623530316352844\n",
      "fold: 0, epoch: 6,                       train_loss : 4.194311835792627, valid_loss : 3.6194077491760255\n",
      "fold: 0, epoch: 7,                       train_loss : 4.190272867009881, valid_loss : 3.638693833351135\n",
      "fold: 0, epoch: 8,                       train_loss : 4.192752088053843, valid_loss : 3.621183180809021\n",
      "fold: 0, epoch: 9,                       train_loss : 4.193638584587012, valid_loss : 3.619766664505005\n",
      "fold: 0, epoch: 10,                       train_loss : 4.195403637511007, valid_loss : 3.6259121656417848\n",
      "fold: 0, epoch: 11,                       train_loss : 4.191561299763369, valid_loss : 3.6346670389175415\n",
      "fold: 0, epoch: 12,                       train_loss : 4.190196254280176, valid_loss : 3.644235134124756\n",
      "fold: 0, epoch: 13,                       train_loss : 4.199493540806717, valid_loss : 3.6205771446228026\n",
      "fold: 0, epoch: 14,                       train_loss : 4.1999023791109575, valid_loss : 3.6250107288360596\n",
      "fold: 1, epoch: 0,                       train_loss : 4.075104914354474, valid_loss : 4.741044545173645\n",
      "fold: 2, epoch: 0,                       train_loss : 4.0802237183860175, valid_loss : 4.640871858596801\n",
      "fold: 3, epoch: 0,                       train_loss : 4.169440459669306, valid_loss : 3.8454849243164064\n",
      "fold: 4, epoch: 0,                       train_loss : 4.172831358534567, valid_loss : 3.8111804246902468\n",
      "fold: 5, epoch: 0,                       train_loss : 4.087506452303254, valid_loss : 4.56700451374054\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1761974886562045, valid_loss : 3.8407037258148193\n",
      "fold: 7, epoch: 0,                       train_loss : 4.106688585174218, valid_loss : 4.392364287376404\n",
      "fold: 8, epoch: 0,                       train_loss : 4.164619148447272, valid_loss : 3.867353057861328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:53:07,852]\u001b[0m Trial 10 finished with value: 4.1396966075897215 and parameters: {'num_layers': 5, 'hidden_size': 90, 'batch_size': 30, 'learning_rate': 0.005447632576728266}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.142864953266101, valid_loss : 4.073206853866577\n",
      "fold: 0, epoch: 0,                       train_loss : 5.239485222360362, valid_loss : 4.737649281819661\n",
      "fold: 0, epoch: 1,                       train_loss : 4.275750699250595, valid_loss : 4.068776925404866\n",
      "fold: 0, epoch: 2,                       train_loss : 4.106849805168483, valid_loss : 4.251415888468425\n",
      "fold: 0, epoch: 3,                       train_loss : 4.191285257754118, valid_loss : 4.153004169464111\n",
      "fold: 0, epoch: 4,                       train_loss : 4.244557463604471, valid_loss : 4.392083326975505\n",
      "fold: 0, epoch: 5,                       train_loss : 4.12527759178825, valid_loss : 4.233705997467041\n",
      "fold: 0, epoch: 6,                       train_loss : 4.126850242200105, valid_loss : 4.192188421885173\n",
      "fold: 0, epoch: 7,                       train_loss : 4.123312214146489, valid_loss : 4.268661975860596\n",
      "fold: 0, epoch: 8,                       train_loss : 4.110391844873843, valid_loss : 4.256134510040283\n",
      "fold: 0, epoch: 9,                       train_loss : 4.11652484147445, valid_loss : 4.283349831899007\n",
      "fold: 0, epoch: 10,                       train_loss : 4.119765665220178, valid_loss : 4.208212534586589\n",
      "fold: 0, epoch: 11,                       train_loss : 4.162104057229084, valid_loss : 4.216651280721028\n",
      "fold: 0, epoch: 12,                       train_loss : 4.113683151162189, valid_loss : 4.003074089686076\n",
      "fold: 0, epoch: 13,                       train_loss : 4.215868110242098, valid_loss : 4.1516257127126055\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1920720701632295, valid_loss : 4.205953598022461\n",
      "fold: 2, epoch: 0,                       train_loss : 4.177946660829627, valid_loss : 3.593919118245443\n",
      "fold: 3, epoch: 0,                       train_loss : 4.127842218979545, valid_loss : 4.063775062561035\n",
      "fold: 4, epoch: 0,                       train_loss : 4.199494081994762, valid_loss : 3.5236423015594482\n",
      "fold: 5, epoch: 0,                       train_loss : 4.034246040427166, valid_loss : 4.730005820592244\n",
      "fold: 6, epoch: 0,                       train_loss : 4.124418569647747, valid_loss : 4.450265884399414\n",
      "fold: 7, epoch: 0,                       train_loss : 4.127409831337307, valid_loss : 3.992980639139811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:53:11,532]\u001b[0m Trial 11 finished with value: 4.0798438390096035 and parameters: {'num_layers': 4, 'hidden_size': 10, 'batch_size': 120, 'learning_rate': 0.011131412950766839}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 8, epoch: 0,                       train_loss : 4.152452531068222, valid_loss : 4.296943028767903\n",
      "fold: 9, epoch: 0,                       train_loss : 4.1592269565748134, valid_loss : 3.9378788471221924\n",
      "fold: 0, epoch: 0,                       train_loss : 5.249883216360341, valid_loss : 5.583561102549235\n",
      "fold: 0, epoch: 1,                       train_loss : 4.573355747305828, valid_loss : 4.959875265757243\n",
      "fold: 0, epoch: 2,                       train_loss : 4.22231706329014, valid_loss : 4.917719682057698\n",
      "fold: 0, epoch: 3,                       train_loss : 4.1394704010175625, valid_loss : 5.000209013621013\n",
      "fold: 0, epoch: 4,                       train_loss : 4.1678317629772685, valid_loss : 4.8964494069417315\n",
      "fold: 0, epoch: 5,                       train_loss : 4.107098848923393, valid_loss : 4.779736598332723\n",
      "fold: 0, epoch: 6,                       train_loss : 4.134867305340975, valid_loss : 4.418611605962117\n",
      "fold: 0, epoch: 7,                       train_loss : 4.084584391635397, valid_loss : 4.522974332173665\n",
      "fold: 0, epoch: 8,                       train_loss : 4.072579280189846, valid_loss : 4.767746289571126\n",
      "fold: 0, epoch: 9,                       train_loss : 4.180814608283665, valid_loss : 4.615566571553548\n",
      "fold: 0, epoch: 10,                       train_loss : 4.028952018074367, valid_loss : 4.437759240468343\n",
      "fold: 0, epoch: 11,                       train_loss : 4.104258361070053, valid_loss : 4.803039073944092\n",
      "fold: 0, epoch: 12,                       train_loss : 4.04434409348861, valid_loss : 4.48882524172465\n",
      "fold: 0, epoch: 13,                       train_loss : 3.992666374082151, valid_loss : 4.503865003585815\n",
      "fold: 0, epoch: 14,                       train_loss : 4.041670902915623, valid_loss : 4.894453763961792\n",
      "fold: 0, epoch: 15,                       train_loss : 4.07100364436274, valid_loss : 4.737488269805908\n",
      "fold: 0, epoch: 16,                       train_loss : 4.072976361150327, valid_loss : 4.588711102803548\n",
      "fold: 1, epoch: 0,                       train_loss : 4.235119042189225, valid_loss : 3.96783439318339\n",
      "fold: 2, epoch: 0,                       train_loss : 4.1324361096257745, valid_loss : 3.9687936305999756\n",
      "fold: 3, epoch: 0,                       train_loss : 4.120098093281621, valid_loss : 3.8624301751454673\n",
      "fold: 4, epoch: 0,                       train_loss : 4.189626517503158, valid_loss : 4.495653072992961\n",
      "fold: 5, epoch: 0,                       train_loss : 4.17881613192351, valid_loss : 4.139245986938477\n",
      "fold: 6, epoch: 0,                       train_loss : 4.089869519938594, valid_loss : 3.868819793065389\n",
      "fold: 7, epoch: 0,                       train_loss : 4.068624486093936, valid_loss : 4.510602951049805\n",
      "fold: 8, epoch: 0,                       train_loss : 4.1080668698186456, valid_loss : 4.0456327597300215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:53:25,379]\u001b[0m Trial 12 finished with value: 4.170098614692688 and parameters: {'num_layers': 4, 'hidden_size': 50, 'batch_size': 120, 'learning_rate': 0.04394600766694705}. Best is trial 0 with value: 3.9903782526652014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.048412727273029, valid_loss : 4.423361778259277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([140, 1])) that is different to the input size (torch.Size([140])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 6.153012275695801, valid_loss : 5.49374516805013\n",
      "fold: 0, epoch: 1,                       train_loss : 5.5248311996459964, valid_loss : 6.587317943572998\n",
      "fold: 0, epoch: 2,                       train_loss : 4.364180076122284, valid_loss : 4.0255788167317705\n",
      "fold: 0, epoch: 3,                       train_loss : 4.155918252468109, valid_loss : 4.016496578852336\n",
      "fold: 0, epoch: 4,                       train_loss : 3.977236181497574, valid_loss : 4.168200810750325\n",
      "fold: 0, epoch: 5,                       train_loss : 4.003159731626511, valid_loss : 3.6464043458302817\n",
      "fold: 0, epoch: 6,                       train_loss : 4.057653403282165, valid_loss : 3.7429088751475015\n",
      "fold: 0, epoch: 7,                       train_loss : 4.037790167331695, valid_loss : 4.907107830047607\n",
      "fold: 0, epoch: 8,                       train_loss : 4.236979353427887, valid_loss : 3.8246022860209146\n",
      "fold: 0, epoch: 9,                       train_loss : 4.196456861495972, valid_loss : 3.740680376688639\n",
      "fold: 0, epoch: 10,                       train_loss : 4.0728192806243895, valid_loss : 5.48608938852946\n",
      "fold: 0, epoch: 11,                       train_loss : 4.076763725280761, valid_loss : 4.151627540588379\n",
      "fold: 0, epoch: 12,                       train_loss : 3.9511423736810682, valid_loss : 3.9989940325419107\n",
      "fold: 0, epoch: 13,                       train_loss : 4.006055551767349, valid_loss : 3.6203500429789224\n",
      "fold: 0, epoch: 14,                       train_loss : 4.041815841197968, valid_loss : 3.969081401824951\n",
      "fold: 0, epoch: 15,                       train_loss : 4.068843424320221, valid_loss : 3.9202210108439126\n",
      "fold: 1, epoch: 0,                       train_loss : 4.226451599597931, valid_loss : 4.0016504128774\n",
      "fold: 2, epoch: 0,                       train_loss : 4.244810962677002, valid_loss : 4.314160267512004\n",
      "fold: 3, epoch: 0,                       train_loss : 4.026592642068863, valid_loss : 3.790776252746582\n",
      "fold: 4, epoch: 0,                       train_loss : 4.12311065196991, valid_loss : 3.617100556691488\n",
      "fold: 5, epoch: 0,                       train_loss : 4.109806406497955, valid_loss : 4.07179840405782\n",
      "fold: 6, epoch: 0,                       train_loss : 4.113160014152527, valid_loss : 3.6101348400115967\n",
      "fold: 7, epoch: 0,                       train_loss : 3.9923250555992125, valid_loss : 4.059009869893392\n",
      "fold: 8, epoch: 0,                       train_loss : 4.19495108127594, valid_loss : 4.475179831186931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:53:43,093]\u001b[0m Trial 13 finished with value: 3.9678506930669153 and parameters: {'num_layers': 5, 'hidden_size': 90, 'batch_size': 140, 'learning_rate': 0.005244789425110164}. Best is trial 13 with value: 3.9678506930669153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.094571232795715, valid_loss : 4.118346452713013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([190, 1])) that is different to the input size (torch.Size([190])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([106, 1])) that is different to the input size (torch.Size([106])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 6.385921637217204, valid_loss : 6.43851637840271\n",
      "fold: 0, epoch: 1,                       train_loss : 5.990897115071615, valid_loss : 6.351747989654541\n",
      "fold: 0, epoch: 2,                       train_loss : 5.393869137763977, valid_loss : 5.568889379501343\n",
      "fold: 0, epoch: 3,                       train_loss : 4.837756196657817, valid_loss : 4.983861446380615\n",
      "fold: 0, epoch: 4,                       train_loss : 4.281701389948527, valid_loss : 4.446402549743652\n",
      "fold: 0, epoch: 5,                       train_loss : 4.300422302881876, valid_loss : 4.3497138023376465\n",
      "fold: 0, epoch: 6,                       train_loss : 4.039618619283041, valid_loss : 4.1203131675720215\n",
      "fold: 0, epoch: 7,                       train_loss : 4.282712411880493, valid_loss : 4.2279558181762695\n",
      "fold: 0, epoch: 8,                       train_loss : 3.994599469502767, valid_loss : 4.178942918777466\n",
      "fold: 0, epoch: 9,                       train_loss : 4.255110295613607, valid_loss : 4.209041357040405\n",
      "fold: 0, epoch: 10,                       train_loss : 4.248872375488281, valid_loss : 4.31138277053833\n",
      "fold: 0, epoch: 11,                       train_loss : 4.614660247166952, valid_loss : 4.324016094207764\n",
      "fold: 0, epoch: 12,                       train_loss : 4.270195372899374, valid_loss : 4.285194635391235\n",
      "fold: 0, epoch: 13,                       train_loss : 4.049834092458089, valid_loss : 4.163494229316711\n",
      "fold: 0, epoch: 14,                       train_loss : 4.464645576477051, valid_loss : 4.1756123304367065\n",
      "fold: 0, epoch: 15,                       train_loss : 4.121172142028809, valid_loss : 4.2451770305633545\n",
      "fold: 0, epoch: 16,                       train_loss : 3.9511667092641196, valid_loss : 4.276105165481567\n",
      "fold: 0, epoch: 17,                       train_loss : 4.381803433100383, valid_loss : 4.319472551345825\n",
      "fold: 1, epoch: 0,                       train_loss : 4.036610380808512, valid_loss : 4.33837103843689\n",
      "fold: 2, epoch: 0,                       train_loss : 4.013627513249715, valid_loss : 3.951550245285034\n",
      "fold: 3, epoch: 0,                       train_loss : 4.134591690699259, valid_loss : 3.787717819213867\n",
      "fold: 4, epoch: 0,                       train_loss : 4.196669642130534, valid_loss : 4.1417882442474365\n",
      "fold: 5, epoch: 0,                       train_loss : 4.020022169748942, valid_loss : 4.253833055496216\n",
      "fold: 6, epoch: 0,                       train_loss : 4.251882044474284, valid_loss : 3.4487178325653076\n",
      "fold: 7, epoch: 0,                       train_loss : 4.383438650767008, valid_loss : 4.384928345680237\n",
      "fold: 8, epoch: 0,                       train_loss : 4.361544529596965, valid_loss : 3.9894543886184692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:53:58,670]\u001b[0m Trial 14 finished with value: 4.083943843841553 and parameters: {'num_layers': 5, 'hidden_size': 90, 'batch_size': 190, 'learning_rate': 0.005627890140156708}. Best is trial 13 with value: 3.9678506930669153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.132596206665039, valid_loss : 4.422764301300049\n",
      "fold: 0, epoch: 0,                       train_loss : 6.285297226905823, valid_loss : 5.966946283976237\n",
      "fold: 0, epoch: 1,                       train_loss : 5.172276961803436, valid_loss : 5.793078740437825\n",
      "fold: 0, epoch: 2,                       train_loss : 4.333259773254395, valid_loss : 3.8640799522399902\n",
      "fold: 0, epoch: 3,                       train_loss : 4.1807156801223755, valid_loss : 3.6087774435679116\n",
      "fold: 0, epoch: 4,                       train_loss : 4.049111264944076, valid_loss : 3.800030549367269\n",
      "fold: 0, epoch: 5,                       train_loss : 4.227363669872284, valid_loss : 3.90156356493632\n",
      "fold: 0, epoch: 6,                       train_loss : 4.080262327194214, valid_loss : 3.289568026860555\n",
      "fold: 0, epoch: 7,                       train_loss : 4.223887765407563, valid_loss : 3.7659242947896323\n",
      "fold: 0, epoch: 8,                       train_loss : 4.1921486258506775, valid_loss : 4.024130980173747\n",
      "fold: 0, epoch: 9,                       train_loss : 4.271995615959168, valid_loss : 4.4974807898203535\n",
      "fold: 0, epoch: 10,                       train_loss : 4.134804654121399, valid_loss : 3.839677333831787\n",
      "fold: 0, epoch: 11,                       train_loss : 4.434945416450501, valid_loss : 3.6529506047566733\n",
      "fold: 0, epoch: 12,                       train_loss : 4.335062539577484, valid_loss : 3.748581886291504\n",
      "fold: 0, epoch: 13,                       train_loss : 4.171252763271331, valid_loss : 3.858072598775228\n",
      "fold: 0, epoch: 14,                       train_loss : 4.054514342546463, valid_loss : 4.052718798319499\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1601470589637755, valid_loss : 3.6094249884287515\n",
      "fold: 1, epoch: 0,                       train_loss : 4.024588471651077, valid_loss : 3.449261506398519\n",
      "fold: 2, epoch: 0,                       train_loss : 4.012615615129471, valid_loss : 4.249653975168864\n",
      "fold: 3, epoch: 0,                       train_loss : 4.142710363864898, valid_loss : 3.3012002309163413\n",
      "fold: 4, epoch: 0,                       train_loss : 4.000894594192505, valid_loss : 4.113111813863118\n",
      "fold: 5, epoch: 0,                       train_loss : 3.9762929290533067, valid_loss : 3.692143281300863\n",
      "fold: 6, epoch: 0,                       train_loss : 4.212128067016602, valid_loss : 4.258095026016235\n",
      "fold: 7, epoch: 0,                       train_loss : 4.012464934587479, valid_loss : 4.381400187810262\n",
      "fold: 8, epoch: 0,                       train_loss : 3.998658776283264, valid_loss : 4.030802647272746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:54:16,053]\u001b[0m Trial 15 finished with value: 3.853500247001648 and parameters: {'num_layers': 5, 'hidden_size': 80, 'batch_size': 140, 'learning_rate': 0.005948741334654186}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.084797728061676, valid_loss : 3.769765774408976\n",
      "fold: 0, epoch: 0,                       train_loss : 5.933285490671794, valid_loss : 5.191516757011414\n",
      "fold: 0, epoch: 1,                       train_loss : 5.758547782897949, valid_loss : 5.605716347694397\n",
      "fold: 0, epoch: 2,                       train_loss : 5.671236133575439, valid_loss : 5.694836139678955\n",
      "fold: 0, epoch: 3,                       train_loss : 5.55329704284668, valid_loss : 4.907420814037323\n",
      "fold: 0, epoch: 4,                       train_loss : 5.485286045074463, valid_loss : 4.900529086589813\n",
      "fold: 0, epoch: 5,                       train_loss : 5.410104386011759, valid_loss : 4.90626323223114\n",
      "fold: 0, epoch: 6,                       train_loss : 5.326806084314982, valid_loss : 4.925532817840576\n",
      "fold: 0, epoch: 7,                       train_loss : 5.2506659905115765, valid_loss : 4.925739884376526\n",
      "fold: 0, epoch: 8,                       train_loss : 5.168053483963012, valid_loss : 4.530553042888641\n",
      "fold: 0, epoch: 9,                       train_loss : 5.11469087600708, valid_loss : 5.043841004371643\n",
      "fold: 0, epoch: 10,                       train_loss : 5.0433231592178345, valid_loss : 4.901538848876953\n",
      "fold: 0, epoch: 11,                       train_loss : 4.994261614481608, valid_loss : 5.0281548500061035\n",
      "fold: 0, epoch: 12,                       train_loss : 4.929718907674154, valid_loss : 4.562478184700012\n",
      "fold: 0, epoch: 13,                       train_loss : 4.86520582040151, valid_loss : 4.3716540932655334\n",
      "fold: 0, epoch: 14,                       train_loss : 4.830086636543274, valid_loss : 4.361710548400879\n",
      "fold: 0, epoch: 15,                       train_loss : 4.766858100891113, valid_loss : 4.4867613315582275\n",
      "fold: 0, epoch: 16,                       train_loss : 4.726427475611369, valid_loss : 4.390568017959595\n",
      "fold: 1, epoch: 0,                       train_loss : 4.620073652267456, valid_loss : 4.850905418395996\n",
      "fold: 2, epoch: 0,                       train_loss : 4.644920905431111, valid_loss : 4.655206680297852\n",
      "fold: 3, epoch: 0,                       train_loss : 4.611867904663086, valid_loss : 4.627093613147736\n",
      "fold: 4, epoch: 0,                       train_loss : 4.607076692581177, valid_loss : 4.204413950443268\n",
      "fold: 5, epoch: 0,                       train_loss : 4.482913104693095, valid_loss : 4.4805174469947815\n",
      "fold: 6, epoch: 0,                       train_loss : 4.49104528427124, valid_loss : 4.860532701015472\n",
      "fold: 7, epoch: 0,                       train_loss : 4.457457979520162, valid_loss : 4.45246684551239\n",
      "fold: 8, epoch: 0,                       train_loss : 4.403730249404907, valid_loss : 4.99440324306488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:54:46,172]\u001b[0m Trial 16 finished with value: 4.599173581600189 and parameters: {'num_layers': 5, 'hidden_size': 100, 'batch_size': 90, 'learning_rate': 0.0030341080110641997}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.350407528877258, valid_loss : 4.504485368728638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([6, 1])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 4.300274853849232, valid_loss : 4.188711126645406\n",
      "fold: 0, epoch: 1,                       train_loss : 4.146602772594838, valid_loss : 4.110450263818105\n",
      "fold: 0, epoch: 2,                       train_loss : 4.136606340104721, valid_loss : 4.1844062606493635\n",
      "fold: 0, epoch: 3,                       train_loss : 4.159601571408104, valid_loss : 4.124028356870015\n",
      "fold: 0, epoch: 4,                       train_loss : 4.138371594389726, valid_loss : 4.308825389544169\n",
      "fold: 0, epoch: 5,                       train_loss : 4.149569429261854, valid_loss : 4.1161053538322445\n",
      "fold: 0, epoch: 6,                       train_loss : 4.13888920335734, valid_loss : 4.126314481099446\n",
      "fold: 0, epoch: 7,                       train_loss : 4.14698859323723, valid_loss : 4.279464364051819\n",
      "fold: 0, epoch: 8,                       train_loss : 4.1424980614515725, valid_loss : 4.152231017748515\n",
      "fold: 0, epoch: 9,                       train_loss : 4.138942660017406, valid_loss : 4.190834919611613\n",
      "fold: 0, epoch: 10,                       train_loss : 4.14391855934586, valid_loss : 4.166912305355072\n",
      "fold: 0, epoch: 11,                       train_loss : 4.136058414919993, valid_loss : 4.188760789235433\n",
      "fold: 0, epoch: 12,                       train_loss : 4.138766711347558, valid_loss : 4.18126513560613\n",
      "fold: 1, epoch: 0,                       train_loss : 4.116376221849677, valid_loss : 4.391631535689036\n",
      "fold: 2, epoch: 0,                       train_loss : 4.169388284397482, valid_loss : 3.8739538272221883\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1359884743386885, valid_loss : 4.26417388121287\n",
      "fold: 4, epoch: 0,                       train_loss : 4.153039425499877, valid_loss : 4.135433753331502\n",
      "fold: 5, epoch: 0,                       train_loss : 4.112801394659035, valid_loss : 4.459153230985006\n",
      "fold: 6, epoch: 0,                       train_loss : 4.175021643495739, valid_loss : 3.856035133202871\n",
      "fold: 7, epoch: 0,                       train_loss : 4.19120324283057, valid_loss : 3.850129167238871\n",
      "fold: 8, epoch: 0,                       train_loss : 4.146384079804581, valid_loss : 4.1527547915776575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:58:02,766]\u001b[0m Trial 17 finished with value: 4.134226375818253 and parameters: {'num_layers': 5, 'hidden_size': 80, 'batch_size': 10, 'learning_rate': 0.01337480042085052}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.126326510968727, valid_loss : 4.248548173904419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([150, 1])) that is different to the input size (torch.Size([150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([146, 1])) that is different to the input size (torch.Size([146])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 5.8555019696553545, valid_loss : 5.84512996673584\n",
      "fold: 0, epoch: 1,                       train_loss : 5.809066851933797, valid_loss : 5.798659324645996\n",
      "fold: 0, epoch: 2,                       train_loss : 5.756151702668932, valid_loss : 5.766403675079346\n",
      "fold: 0, epoch: 3,                       train_loss : 5.718939489788479, valid_loss : 5.711287260055542\n",
      "fold: 0, epoch: 4,                       train_loss : 5.662430021497938, valid_loss : 5.681402921676636\n",
      "fold: 0, epoch: 5,                       train_loss : 5.619735611809625, valid_loss : 5.628789901733398\n",
      "fold: 0, epoch: 6,                       train_loss : 5.597463819715712, valid_loss : 5.577859401702881\n",
      "fold: 0, epoch: 7,                       train_loss : 5.554917097091675, valid_loss : 5.547517538070679\n",
      "fold: 0, epoch: 8,                       train_loss : 5.500902228885227, valid_loss : 5.501954793930054\n",
      "fold: 0, epoch: 9,                       train_loss : 5.449981556998359, valid_loss : 5.460608005523682\n",
      "fold: 0, epoch: 10,                       train_loss : 5.405191633436415, valid_loss : 5.402167320251465\n",
      "fold: 0, epoch: 11,                       train_loss : 5.37694689962599, valid_loss : 5.379015922546387\n",
      "fold: 0, epoch: 12,                       train_loss : 5.3462264272901745, valid_loss : 5.342461347579956\n",
      "fold: 0, epoch: 13,                       train_loss : 5.311370134353638, valid_loss : 5.296458005905151\n",
      "fold: 0, epoch: 14,                       train_loss : 5.264120353592767, valid_loss : 5.260502815246582\n",
      "fold: 0, epoch: 15,                       train_loss : 5.21816513273451, valid_loss : 5.217672824859619\n",
      "fold: 0, epoch: 16,                       train_loss : 5.162135256661309, valid_loss : 5.180860996246338\n",
      "fold: 0, epoch: 17,                       train_loss : 5.124319261974758, valid_loss : 5.130404710769653\n",
      "fold: 0, epoch: 18,                       train_loss : 5.084734108712938, valid_loss : 5.101398706436157\n",
      "fold: 0, epoch: 19,                       train_loss : 5.041235897276136, valid_loss : 5.05460000038147\n",
      "fold: 0, epoch: 20,                       train_loss : 4.999947283003065, valid_loss : 5.012809991836548\n",
      "fold: 0, epoch: 21,                       train_loss : 4.980492830276489, valid_loss : 4.980917453765869\n",
      "fold: 0, epoch: 22,                       train_loss : 4.93431814511617, valid_loss : 4.934462547302246\n",
      "fold: 0, epoch: 23,                       train_loss : 4.885270118713379, valid_loss : 4.90459132194519\n",
      "fold: 0, epoch: 24,                       train_loss : 4.848562584982978, valid_loss : 4.855905532836914\n",
      "fold: 0, epoch: 25,                       train_loss : 4.812612930933635, valid_loss : 4.810727119445801\n",
      "fold: 0, epoch: 26,                       train_loss : 4.761023667123583, valid_loss : 4.7893335819244385\n",
      "fold: 0, epoch: 27,                       train_loss : 4.74333831999037, valid_loss : 4.735170841217041\n",
      "fold: 0, epoch: 28,                       train_loss : 4.711447212431166, valid_loss : 4.713952541351318\n",
      "fold: 0, epoch: 29,                       train_loss : 4.679581642150879, valid_loss : 4.66672158241272\n",
      "fold: 0, epoch: 30,                       train_loss : 4.658747924698724, valid_loss : 4.637304782867432\n",
      "fold: 0, epoch: 31,                       train_loss : 4.597851554552714, valid_loss : 4.596973419189453\n",
      "fold: 0, epoch: 32,                       train_loss : 4.569970409075419, valid_loss : 4.564461708068848\n",
      "fold: 0, epoch: 33,                       train_loss : 4.541094753477308, valid_loss : 4.534303188323975\n",
      "fold: 0, epoch: 34,                       train_loss : 4.519607014126247, valid_loss : 4.509770154953003\n",
      "fold: 0, epoch: 35,                       train_loss : 4.484908011224535, valid_loss : 4.477463245391846\n",
      "fold: 0, epoch: 36,                       train_loss : 4.456511576970418, valid_loss : 4.439047336578369\n",
      "fold: 0, epoch: 37,                       train_loss : 4.421172473165724, valid_loss : 4.420746326446533\n",
      "fold: 0, epoch: 38,                       train_loss : 4.402370916472541, valid_loss : 4.392791032791138\n",
      "fold: 0, epoch: 39,                       train_loss : 4.377215266227722, valid_loss : 4.371326684951782\n",
      "fold: 0, epoch: 40,                       train_loss : 4.363087097803752, valid_loss : 4.327132344245911\n",
      "fold: 0, epoch: 41,                       train_loss : 4.329486012458801, valid_loss : 4.3185834884643555\n",
      "fold: 0, epoch: 42,                       train_loss : 4.307768861452739, valid_loss : 4.288374543190002\n",
      "fold: 0, epoch: 43,                       train_loss : 4.301421827740139, valid_loss : 4.2739808559417725\n",
      "fold: 0, epoch: 44,                       train_loss : 4.29309528403812, valid_loss : 4.261261701583862\n",
      "fold: 0, epoch: 45,                       train_loss : 4.26488999525706, valid_loss : 4.2419514656066895\n",
      "fold: 0, epoch: 46,                       train_loss : 4.249678677982754, valid_loss : 4.232311725616455\n",
      "fold: 0, epoch: 47,                       train_loss : 4.237294210327996, valid_loss : 4.214035272598267\n",
      "fold: 0, epoch: 48,                       train_loss : 4.2272896899117365, valid_loss : 4.191165328025818\n",
      "fold: 0, epoch: 49,                       train_loss : 4.225172519683838, valid_loss : 4.19132387638092\n",
      "fold: 0, epoch: 50,                       train_loss : 4.220947252379523, valid_loss : 4.169923424720764\n",
      "fold: 0, epoch: 51,                       train_loss : 4.188651084899902, valid_loss : 4.169424414634705\n",
      "fold: 0, epoch: 52,                       train_loss : 4.199624194039239, valid_loss : 4.155019998550415\n",
      "fold: 0, epoch: 53,                       train_loss : 4.18521265188853, valid_loss : 4.147825837135315\n",
      "fold: 0, epoch: 54,                       train_loss : 4.167181875970629, valid_loss : 4.142941117286682\n",
      "fold: 0, epoch: 55,                       train_loss : 4.17123297850291, valid_loss : 4.123513102531433\n",
      "fold: 0, epoch: 56,                       train_loss : 4.155670192506578, valid_loss : 4.131504058837891\n",
      "fold: 0, epoch: 57,                       train_loss : 4.170456210772197, valid_loss : 4.119296669960022\n",
      "fold: 0, epoch: 58,                       train_loss : 4.14247911506229, valid_loss : 4.117223739624023\n",
      "fold: 0, epoch: 59,                       train_loss : 4.147169523768955, valid_loss : 4.12057101726532\n",
      "fold: 0, epoch: 60,                       train_loss : 4.161155700683594, valid_loss : 4.1080238819122314\n",
      "fold: 0, epoch: 61,                       train_loss : 4.148075964715746, valid_loss : 4.102056980133057\n",
      "fold: 0, epoch: 62,                       train_loss : 4.145247300465901, valid_loss : 4.103999853134155\n",
      "fold: 0, epoch: 63,                       train_loss : 4.15180422200097, valid_loss : 4.10683536529541\n",
      "fold: 0, epoch: 64,                       train_loss : 4.126699937714471, valid_loss : 4.0976011753082275\n",
      "fold: 0, epoch: 65,                       train_loss : 4.1485006544325085, valid_loss : 4.1010085344314575\n",
      "fold: 0, epoch: 66,                       train_loss : 4.134673674901326, valid_loss : 4.098147869110107\n",
      "fold: 0, epoch: 67,                       train_loss : 4.136149684588115, valid_loss : 4.102696895599365\n",
      "fold: 0, epoch: 68,                       train_loss : 4.1414097679985895, valid_loss : 4.102210640907288\n",
      "fold: 0, epoch: 69,                       train_loss : 4.144967900382148, valid_loss : 4.1062692403793335\n",
      "fold: 0, epoch: 70,                       train_loss : 4.141223364406162, valid_loss : 4.0927287340164185\n",
      "fold: 0, epoch: 71,                       train_loss : 4.146911766793993, valid_loss : 4.098838686943054\n",
      "fold: 1, epoch: 0,                       train_loss : 4.172213024563259, valid_loss : 3.7586740255355835\n",
      "fold: 2, epoch: 0,                       train_loss : 4.127345456017388, valid_loss : 4.118199467658997\n",
      "fold: 3, epoch: 0,                       train_loss : 4.061406983269586, valid_loss : 4.660633563995361\n",
      "fold: 4, epoch: 0,                       train_loss : 4.10762091477712, valid_loss : 4.387178897857666\n",
      "fold: 5, epoch: 0,                       train_loss : 4.124916897879706, valid_loss : 4.240271806716919\n",
      "fold: 6, epoch: 0,                       train_loss : 4.102844913800557, valid_loss : 4.412062883377075\n",
      "fold: 7, epoch: 0,                       train_loss : 4.178139872021145, valid_loss : 3.7402271032333374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 8, epoch: 0,                       train_loss : 4.185595194498698, valid_loss : 3.773522138595581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:59:08,434]\u001b[0m Trial 18 finished with value: 4.135428643226623 and parameters: {'num_layers': 4, 'hidden_size': 120, 'batch_size': 150, 'learning_rate': 0.0010004321311771795}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1306993166605634, valid_loss : 4.170787811279297\n",
      "fold: 0, epoch: 0,                       train_loss : 6.4255704561869305, valid_loss : 6.165279150009155\n",
      "fold: 0, epoch: 1,                       train_loss : 6.123831780751546, valid_loss : 5.783989429473877\n",
      "fold: 0, epoch: 2,                       train_loss : 5.834265899658203, valid_loss : 5.580902338027954\n",
      "fold: 0, epoch: 3,                       train_loss : 5.454770231246949, valid_loss : 5.11649751663208\n",
      "fold: 0, epoch: 4,                       train_loss : 5.030917739868164, valid_loss : 4.373352766036987\n",
      "fold: 0, epoch: 5,                       train_loss : 4.157214371363322, valid_loss : 4.018876910209656\n",
      "fold: 0, epoch: 6,                       train_loss : 3.9942291577657065, valid_loss : 3.8192667961120605\n",
      "fold: 0, epoch: 7,                       train_loss : 4.197665977478027, valid_loss : 3.7758023738861084\n",
      "fold: 0, epoch: 8,                       train_loss : 4.444220129648844, valid_loss : 3.9389829635620117\n",
      "fold: 0, epoch: 9,                       train_loss : 3.949154289563497, valid_loss : 4.016864538192749\n",
      "fold: 0, epoch: 10,                       train_loss : 3.96492592493693, valid_loss : 4.175624132156372\n",
      "fold: 0, epoch: 11,                       train_loss : 4.134733057022094, valid_loss : 3.8081154823303223\n",
      "fold: 0, epoch: 12,                       train_loss : 3.953996515274048, valid_loss : 4.052196025848389\n",
      "fold: 0, epoch: 13,                       train_loss : 4.258377822240194, valid_loss : 3.846462368965149\n",
      "fold: 0, epoch: 14,                       train_loss : 3.989227533340454, valid_loss : 4.052916765213013\n",
      "fold: 0, epoch: 15,                       train_loss : 4.086313645044963, valid_loss : 4.004886150360107\n",
      "fold: 0, epoch: 16,                       train_loss : 3.910001734892527, valid_loss : 3.8718528747558594\n",
      "fold: 0, epoch: 17,                       train_loss : 4.059038416544596, valid_loss : 4.122498393058777\n",
      "fold: 0, epoch: 18,                       train_loss : 4.0572234471639, valid_loss : 3.8335232734680176\n",
      "fold: 1, epoch: 0,                       train_loss : 3.9998120148976644, valid_loss : 4.1699769496917725\n",
      "fold: 2, epoch: 0,                       train_loss : 3.9358028888702394, valid_loss : 4.34172248840332\n",
      "fold: 3, epoch: 0,                       train_loss : 3.976122983296712, valid_loss : 4.241573691368103\n",
      "fold: 4, epoch: 0,                       train_loss : 3.9982115348180134, valid_loss : 3.7576955556869507\n",
      "fold: 5, epoch: 0,                       train_loss : 3.9576289812723795, valid_loss : 4.802336692810059\n",
      "fold: 6, epoch: 0,                       train_loss : 4.4587802251180015, valid_loss : 3.703300356864929\n",
      "fold: 7, epoch: 0,                       train_loss : 4.415065272649129, valid_loss : 4.321085572242737\n",
      "fold: 8, epoch: 0,                       train_loss : 3.9503797054290772, valid_loss : 4.457493305206299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:59:35,419]\u001b[0m Trial 19 finished with value: 4.140549051761627 and parameters: {'num_layers': 5, 'hidden_size': 190, 'batch_size': 190, 'learning_rate': 0.0036012153035601896}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1674586772918705, valid_loss : 3.8345035314559937\n",
      "fold: 0, epoch: 0,                       train_loss : 5.101595103740692, valid_loss : 5.392687082290649\n",
      "fold: 0, epoch: 1,                       train_loss : 4.241144168376922, valid_loss : 3.8266603151957193\n",
      "fold: 0, epoch: 2,                       train_loss : 4.087333619594574, valid_loss : 5.104814291000366\n",
      "fold: 0, epoch: 3,                       train_loss : 4.004046058654785, valid_loss : 4.931779543558757\n",
      "fold: 0, epoch: 4,                       train_loss : 4.135524642467499, valid_loss : 5.153254747390747\n",
      "fold: 0, epoch: 5,                       train_loss : 4.159235262870789, valid_loss : 3.677938461303711\n",
      "fold: 0, epoch: 6,                       train_loss : 4.041868376731872, valid_loss : 4.255068937937419\n",
      "fold: 0, epoch: 7,                       train_loss : 3.995959663391113, valid_loss : 3.915374199549357\n",
      "fold: 0, epoch: 8,                       train_loss : 4.055278468132019, valid_loss : 5.891658226648967\n",
      "fold: 0, epoch: 9,                       train_loss : 4.051683342456817, valid_loss : 4.725223859151204\n",
      "fold: 0, epoch: 10,                       train_loss : 4.384156405925751, valid_loss : 4.007214228312175\n",
      "fold: 0, epoch: 11,                       train_loss : 4.092097997665405, valid_loss : 3.510997931162516\n",
      "fold: 0, epoch: 12,                       train_loss : 4.090069508552551, valid_loss : 5.02889617284139\n",
      "fold: 0, epoch: 13,                       train_loss : 4.075024998188018, valid_loss : 4.550034999847412\n",
      "fold: 0, epoch: 14,                       train_loss : 3.998535120487213, valid_loss : 4.756796677907308\n",
      "fold: 1, epoch: 0,                       train_loss : 4.023900020122528, valid_loss : 5.213515758514404\n",
      "fold: 2, epoch: 0,                       train_loss : 4.170763576030732, valid_loss : 3.8772669633229575\n",
      "fold: 3, epoch: 0,                       train_loss : 4.0855352759361265, valid_loss : 4.340328534444173\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1972625136375425, valid_loss : 4.120457649230957\n",
      "fold: 5, epoch: 0,                       train_loss : 4.135472619533539, valid_loss : 3.0897509256998696\n",
      "fold: 6, epoch: 0,                       train_loss : 4.209063923358917, valid_loss : 4.356871763865153\n",
      "fold: 7, epoch: 0,                       train_loss : 4.190009152889251, valid_loss : 4.771076520284017\n",
      "fold: 8, epoch: 0,                       train_loss : 4.088941204547882, valid_loss : 4.9015398025512695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:59:50,176]\u001b[0m Trial 20 finished with value: 4.267270557085673 and parameters: {'num_layers': 4, 'hidden_size': 70, 'batch_size': 140, 'learning_rate': 0.01700807362523141}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 3.9917252242565153, valid_loss : 4.490899721781413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([96, 1])) that is different to the input size (torch.Size([96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 5.827471167952926, valid_loss : 6.337278366088867\n",
      "fold: 0, epoch: 1,                       train_loss : 4.265559108168991, valid_loss : 5.01127274831136\n",
      "fold: 0, epoch: 2,                       train_loss : 4.04067607279177, valid_loss : 5.026791254679362\n",
      "fold: 0, epoch: 3,                       train_loss : 4.036167824709857, valid_loss : 5.049718697865804\n",
      "fold: 0, epoch: 4,                       train_loss : 4.058504484317921, valid_loss : 5.03974707921346\n",
      "fold: 0, epoch: 5,                       train_loss : 4.0395266126703335, valid_loss : 5.0599416097005205\n",
      "fold: 0, epoch: 6,                       train_loss : 4.038251682564065, valid_loss : 5.040758450826009\n",
      "fold: 0, epoch: 7,                       train_loss : 4.026339689890544, valid_loss : 5.018607934315999\n",
      "fold: 0, epoch: 8,                       train_loss : 4.040440788975468, valid_loss : 5.084660689036052\n",
      "fold: 0, epoch: 9,                       train_loss : 4.029838641484578, valid_loss : 5.050979296366374\n",
      "fold: 0, epoch: 10,                       train_loss : 4.033663617240058, valid_loss : 5.0377875963846845\n",
      "fold: 0, epoch: 11,                       train_loss : 4.045100132624309, valid_loss : 5.027335166931152\n",
      "fold: 0, epoch: 12,                       train_loss : 4.034639888339573, valid_loss : 5.0814095338185625\n",
      "fold: 1, epoch: 0,                       train_loss : 4.113390807752256, valid_loss : 4.343530257542928\n",
      "fold: 2, epoch: 0,                       train_loss : 4.151361253526476, valid_loss : 3.9639522234598794\n",
      "fold: 3, epoch: 0,                       train_loss : 4.148699168805723, valid_loss : 4.086783250172933\n",
      "fold: 4, epoch: 0,                       train_loss : 4.197037608535202, valid_loss : 3.6708361307779946\n",
      "fold: 5, epoch: 0,                       train_loss : 4.114083793428209, valid_loss : 4.271840254465739\n",
      "fold: 6, epoch: 0,                       train_loss : 4.175619902434172, valid_loss : 3.7413464387257895\n",
      "fold: 7, epoch: 0,                       train_loss : 4.12982279283029, valid_loss : 4.34917140007019\n",
      "fold: 8, epoch: 0,                       train_loss : 4.157198888284189, valid_loss : 4.006285667419434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 14:59:59,614]\u001b[0m Trial 21 finished with value: 4.133625761667887 and parameters: {'num_layers': 6, 'hidden_size': 30, 'batch_size': 100, 'learning_rate': 0.007523915525614224}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.158342591038457, valid_loss : 3.8912392457326255\n",
      "fold: 0, epoch: 0,                       train_loss : 5.343813848495484, valid_loss : 3.4767536322275796\n",
      "fold: 0, epoch: 1,                       train_loss : 4.13019460439682, valid_loss : 3.3867055575052896\n",
      "fold: 0, epoch: 2,                       train_loss : 4.313607299327851, valid_loss : 4.296658515930176\n",
      "fold: 0, epoch: 3,                       train_loss : 4.446690368652344, valid_loss : 3.7906086444854736\n",
      "fold: 0, epoch: 4,                       train_loss : 4.047008752822876, valid_loss : 3.971195697784424\n",
      "fold: 0, epoch: 5,                       train_loss : 4.068623423576355, valid_loss : 3.5949015617370605\n",
      "fold: 0, epoch: 6,                       train_loss : 4.058481168746948, valid_loss : 4.299551725387573\n",
      "fold: 0, epoch: 7,                       train_loss : 4.219463860988617, valid_loss : 3.494665781656901\n",
      "fold: 0, epoch: 8,                       train_loss : 4.114884066581726, valid_loss : 3.6212217013041177\n",
      "fold: 0, epoch: 9,                       train_loss : 4.100094532966613, valid_loss : 4.037471612294515\n",
      "fold: 0, epoch: 10,                       train_loss : 4.496076714992523, valid_loss : 3.426748355229696\n",
      "fold: 0, epoch: 11,                       train_loss : 4.357266116142273, valid_loss : 4.481571992238362\n",
      "fold: 0, epoch: 12,                       train_loss : 4.169723010063171, valid_loss : 3.5040746529897056\n",
      "fold: 1, epoch: 0,                       train_loss : 4.125836336612702, valid_loss : 3.876984119415283\n",
      "fold: 2, epoch: 0,                       train_loss : 4.132148313522339, valid_loss : 3.5348868370056152\n",
      "fold: 3, epoch: 0,                       train_loss : 4.013357484340668, valid_loss : 4.387924830118815\n",
      "fold: 4, epoch: 0,                       train_loss : 4.2289794206619264, valid_loss : 4.366525967915853\n",
      "fold: 5, epoch: 0,                       train_loss : 4.2128631234169, valid_loss : 4.118014653523763\n",
      "fold: 6, epoch: 0,                       train_loss : 4.049103689193726, valid_loss : 3.4765477975209556\n",
      "fold: 7, epoch: 0,                       train_loss : 3.9987453401088713, valid_loss : 3.89083202679952\n",
      "fold: 8, epoch: 0,                       train_loss : 4.027617788314819, valid_loss : 4.491471767425537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:00:18,783]\u001b[0m Trial 22 finished with value: 3.9514484564463297 and parameters: {'num_layers': 6, 'hidden_size': 110, 'batch_size': 140, 'learning_rate': 0.008218067230093641}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.104990255832672, valid_loss : 3.984591007232666\n",
      "fold: 0, epoch: 0,                       train_loss : 5.560587751865387, valid_loss : 5.7593770027160645\n",
      "fold: 0, epoch: 1,                       train_loss : 5.281119787693024, valid_loss : 5.441653569539388\n",
      "fold: 0, epoch: 2,                       train_loss : 5.028734695911408, valid_loss : 5.274013678232829\n",
      "fold: 0, epoch: 3,                       train_loss : 4.568436026573181, valid_loss : 4.028757254282634\n",
      "fold: 0, epoch: 4,                       train_loss : 4.306622898578643, valid_loss : 3.924262205759684\n",
      "fold: 0, epoch: 5,                       train_loss : 4.1225192785263065, valid_loss : 4.002224445343018\n",
      "fold: 0, epoch: 6,                       train_loss : 4.0274247288703915, valid_loss : 4.170618534088135\n",
      "fold: 0, epoch: 7,                       train_loss : 4.156186151504516, valid_loss : 4.925093015034993\n",
      "fold: 0, epoch: 8,                       train_loss : 4.082406735420227, valid_loss : 4.541143814722697\n",
      "fold: 0, epoch: 9,                       train_loss : 4.059886610507965, valid_loss : 4.478909254074097\n",
      "fold: 0, epoch: 10,                       train_loss : 4.013139939308166, valid_loss : 4.304344018300374\n",
      "fold: 0, epoch: 11,                       train_loss : 4.329834771156311, valid_loss : 4.240779002507527\n",
      "fold: 0, epoch: 12,                       train_loss : 3.9667711824178697, valid_loss : 4.107422510782878\n",
      "fold: 0, epoch: 13,                       train_loss : 4.0433092474937435, valid_loss : 3.9163151582082114\n",
      "fold: 0, epoch: 14,                       train_loss : 4.064797115325928, valid_loss : 4.255810181299846\n",
      "fold: 0, epoch: 15,                       train_loss : 4.052484238147736, valid_loss : 3.632469892501831\n",
      "fold: 0, epoch: 16,                       train_loss : 4.069301378726959, valid_loss : 3.7885855038960776\n",
      "fold: 0, epoch: 17,                       train_loss : 4.089280796051026, valid_loss : 3.9855782985687256\n",
      "fold: 1, epoch: 0,                       train_loss : 4.076199102401733, valid_loss : 4.327329874038696\n",
      "fold: 2, epoch: 0,                       train_loss : 4.214792478084564, valid_loss : 3.5684940814971924\n",
      "fold: 3, epoch: 0,                       train_loss : 3.997832238674164, valid_loss : 4.073466777801514\n",
      "fold: 4, epoch: 0,                       train_loss : 4.034771203994751, valid_loss : 4.078521172205607\n",
      "fold: 5, epoch: 0,                       train_loss : 4.0349061489105225, valid_loss : 4.543057044347127\n",
      "fold: 6, epoch: 0,                       train_loss : 4.19955267906189, valid_loss : 5.086596965789795\n",
      "fold: 7, epoch: 0,                       train_loss : 4.056711876392365, valid_loss : 4.2010806401570635\n",
      "fold: 8, epoch: 0,                       train_loss : 4.135519564151764, valid_loss : 3.7087113857269287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:00:43,574]\u001b[0m Trial 23 finished with value: 4.110090653101603 and parameters: {'num_layers': 5, 'hidden_size': 120, 'batch_size': 140, 'learning_rate': 0.0036930149020399194}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.369512057304382, valid_loss : 3.881178696950277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([110, 1])) that is different to the input size (torch.Size([110])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([76, 1])) that is different to the input size (torch.Size([76])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 6.059125843048096, valid_loss : 5.673204739888509\n",
      "fold: 0, epoch: 1,                       train_loss : 5.454259595870972, valid_loss : 5.23329226175944\n",
      "fold: 0, epoch: 2,                       train_loss : 5.019518566131592, valid_loss : 4.754302501678467\n",
      "fold: 0, epoch: 3,                       train_loss : 4.697118968963623, valid_loss : 4.389866590499878\n",
      "fold: 0, epoch: 4,                       train_loss : 4.488433723449707, valid_loss : 4.231240749359131\n",
      "fold: 0, epoch: 5,                       train_loss : 4.390246067047119, valid_loss : 4.153476238250732\n",
      "fold: 0, epoch: 6,                       train_loss : 4.257295999526978, valid_loss : 4.046753406524658\n",
      "fold: 0, epoch: 7,                       train_loss : 4.220192317962646, valid_loss : 4.108936786651611\n",
      "fold: 0, epoch: 8,                       train_loss : 4.2074908351898195, valid_loss : 4.095686197280884\n",
      "fold: 0, epoch: 9,                       train_loss : 4.1519163131713865, valid_loss : 4.039804458618164\n",
      "fold: 0, epoch: 10,                       train_loss : 4.174313764572144, valid_loss : 4.021403710047404\n",
      "fold: 0, epoch: 11,                       train_loss : 4.159195537567139, valid_loss : 3.916009505589803\n",
      "fold: 0, epoch: 12,                       train_loss : 4.148269958496094, valid_loss : 3.9861594835917153\n",
      "fold: 0, epoch: 13,                       train_loss : 4.113216409683227, valid_loss : 3.9784634113311768\n",
      "fold: 0, epoch: 14,                       train_loss : 4.1228421020507815, valid_loss : 4.030030330022176\n",
      "fold: 0, epoch: 15,                       train_loss : 4.0942186260223385, valid_loss : 4.041476488113403\n",
      "fold: 0, epoch: 16,                       train_loss : 4.107013969421387, valid_loss : 4.0669788519541425\n",
      "fold: 0, epoch: 17,                       train_loss : 4.230088977813721, valid_loss : 4.113141218821208\n",
      "fold: 0, epoch: 18,                       train_loss : 4.205623722076416, valid_loss : 3.977586507797241\n",
      "fold: 0, epoch: 19,                       train_loss : 4.205587663650513, valid_loss : 3.969815651575724\n",
      "fold: 0, epoch: 20,                       train_loss : 4.1682898044586185, valid_loss : 4.0439988772074384\n",
      "fold: 1, epoch: 0,                       train_loss : 4.063165206909179, valid_loss : 4.571204503377278\n",
      "fold: 2, epoch: 0,                       train_loss : 4.185624847412109, valid_loss : 3.8494680722554526\n",
      "fold: 3, epoch: 0,                       train_loss : 4.109423236846924, valid_loss : 4.034274498621623\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1592849922180175, valid_loss : 4.128578742345174\n",
      "fold: 5, epoch: 0,                       train_loss : 4.176351194381714, valid_loss : 4.182854731877645\n",
      "fold: 6, epoch: 0,                       train_loss : 4.184995756149292, valid_loss : 3.8508570988972983\n",
      "fold: 7, epoch: 0,                       train_loss : 4.099920558929443, valid_loss : 4.750556627909343\n",
      "fold: 8, epoch: 0,                       train_loss : 4.111480159759521, valid_loss : 4.243770678838094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:01:12,257]\u001b[0m Trial 24 finished with value: 4.126268943150838 and parameters: {'num_layers': 6, 'hidden_size': 100, 'batch_size': 110, 'learning_rate': 0.022993214987211255}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.200942268371582, valid_loss : 3.7351149717966714\n",
      "fold: 0, epoch: 0,                       train_loss : 5.853388892279731, valid_loss : 6.02308464050293\n",
      "fold: 0, epoch: 1,                       train_loss : 5.318873206774394, valid_loss : 5.266355514526367\n",
      "fold: 0, epoch: 2,                       train_loss : 4.51854141553243, valid_loss : 4.400106430053711\n",
      "fold: 0, epoch: 3,                       train_loss : 4.148000015152825, valid_loss : 4.2771852016448975\n",
      "fold: 0, epoch: 4,                       train_loss : 4.128472725550334, valid_loss : 4.28258204460144\n",
      "fold: 0, epoch: 5,                       train_loss : 4.12398346265157, valid_loss : 4.294838547706604\n",
      "fold: 0, epoch: 6,                       train_loss : 4.121396250194973, valid_loss : 4.282494068145752\n",
      "fold: 0, epoch: 7,                       train_loss : 4.112273004319933, valid_loss : 4.289147138595581\n",
      "fold: 0, epoch: 8,                       train_loss : 4.111147973272535, valid_loss : 4.282426118850708\n",
      "fold: 0, epoch: 9,                       train_loss : 4.130237883991665, valid_loss : 4.293340444564819\n",
      "fold: 0, epoch: 10,                       train_loss : 4.109265102280511, valid_loss : 4.277832627296448\n",
      "fold: 0, epoch: 11,                       train_loss : 4.125360502137078, valid_loss : 4.286268949508667\n",
      "fold: 0, epoch: 12,                       train_loss : 4.121943248642816, valid_loss : 4.2830970287323\n",
      "fold: 0, epoch: 13,                       train_loss : 4.12684182325999, valid_loss : 4.295358657836914\n",
      "fold: 0, epoch: 14,                       train_loss : 4.109520342614916, valid_loss : 4.280977249145508\n",
      "fold: 1, epoch: 0,                       train_loss : 4.09283443291982, valid_loss : 4.551593542098999\n",
      "fold: 2, epoch: 0,                       train_loss : 4.157289001676771, valid_loss : 3.9758328199386597\n",
      "fold: 3, epoch: 0,                       train_loss : 4.132714483473036, valid_loss : 4.168446660041809\n",
      "fold: 4, epoch: 0,                       train_loss : 4.160829967922634, valid_loss : 3.902266025543213\n",
      "fold: 5, epoch: 0,                       train_loss : 4.076846546596951, valid_loss : 4.572484016418457\n",
      "fold: 6, epoch: 0,                       train_loss : 4.103764613469441, valid_loss : 4.299955248832703\n",
      "fold: 7, epoch: 0,                       train_loss : 4.175805436240302, valid_loss : 3.7043519020080566\n",
      "fold: 8, epoch: 0,                       train_loss : 4.15846684243944, valid_loss : 3.9403260946273804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:01:30,393]\u001b[0m Trial 25 finished with value: 4.134613823890686 and parameters: {'num_layers': 5, 'hidden_size': 110, 'batch_size': 150, 'learning_rate': 0.009054241705189441}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.145379145940145, valid_loss : 3.9536967277526855\n",
      "fold: 0, epoch: 0,                       train_loss : 5.701038897037506, valid_loss : 5.7911155223846436\n",
      "fold: 0, epoch: 1,                       train_loss : 5.688473343849182, valid_loss : 5.735534191131592\n",
      "fold: 0, epoch: 2,                       train_loss : 5.6368958950042725, valid_loss : 5.647802114486694\n",
      "fold: 0, epoch: 3,                       train_loss : 5.6159756779670715, valid_loss : 5.682306289672852\n",
      "fold: 0, epoch: 4,                       train_loss : 5.57268899679184, valid_loss : 5.469182252883911\n",
      "fold: 0, epoch: 5,                       train_loss : 5.559220016002655, valid_loss : 5.578798770904541\n",
      "fold: 0, epoch: 6,                       train_loss : 5.506644129753113, valid_loss : 5.55925989151001\n",
      "fold: 0, epoch: 7,                       train_loss : 5.44845250248909, valid_loss : 5.558517217636108\n",
      "fold: 0, epoch: 8,                       train_loss : 5.4301009476184845, valid_loss : 5.476696014404297\n",
      "fold: 0, epoch: 9,                       train_loss : 5.404253929853439, valid_loss : 5.313544273376465\n",
      "fold: 0, epoch: 10,                       train_loss : 5.365976095199585, valid_loss : 5.361456871032715\n",
      "fold: 0, epoch: 11,                       train_loss : 5.302746057510376, valid_loss : 5.36314845085144\n",
      "fold: 0, epoch: 12,                       train_loss : 5.296921491622925, valid_loss : 5.320173025131226\n",
      "fold: 0, epoch: 13,                       train_loss : 5.271929323673248, valid_loss : 5.308873176574707\n",
      "fold: 0, epoch: 14,                       train_loss : 5.231351152062416, valid_loss : 5.200821161270142\n",
      "fold: 0, epoch: 15,                       train_loss : 5.191395819187164, valid_loss : 5.26458215713501\n",
      "fold: 0, epoch: 16,                       train_loss : 5.172936648130417, valid_loss : 5.149109363555908\n",
      "fold: 0, epoch: 17,                       train_loss : 5.155700713396072, valid_loss : 5.099640607833862\n",
      "fold: 0, epoch: 18,                       train_loss : 5.138848125934601, valid_loss : 5.090458631515503\n",
      "fold: 0, epoch: 19,                       train_loss : 5.10147699713707, valid_loss : 5.162842512130737\n",
      "fold: 0, epoch: 20,                       train_loss : 5.066444665193558, valid_loss : 5.083801031112671\n",
      "fold: 0, epoch: 21,                       train_loss : 5.02072212100029, valid_loss : 5.00180196762085\n",
      "fold: 0, epoch: 22,                       train_loss : 5.002078890800476, valid_loss : 5.133878469467163\n",
      "fold: 1, epoch: 0,                       train_loss : 4.995379105210304, valid_loss : 5.010308742523193\n",
      "fold: 2, epoch: 0,                       train_loss : 4.919866725802422, valid_loss : 5.107357740402222\n",
      "fold: 3, epoch: 0,                       train_loss : 4.928728342056274, valid_loss : 4.8293304443359375\n",
      "fold: 4, epoch: 0,                       train_loss : 4.955507665872574, valid_loss : 4.539936065673828\n",
      "fold: 5, epoch: 0,                       train_loss : 4.8560390174388885, valid_loss : 4.912155628204346\n",
      "fold: 6, epoch: 0,                       train_loss : 4.902957797050476, valid_loss : 4.563271760940552\n",
      "fold: 7, epoch: 0,                       train_loss : 4.841840222477913, valid_loss : 4.985478401184082\n",
      "fold: 8, epoch: 0,                       train_loss : 4.84496733546257, valid_loss : 4.483903884887695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:01:48,058]\u001b[0m Trial 26 finished with value: 4.868706274032593 and parameters: {'num_layers': 4, 'hidden_size': 80, 'batch_size': 170, 'learning_rate': 0.0023687127559592533}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.744868576526642, valid_loss : 5.253518104553223\n",
      "fold: 0, epoch: 0,                       train_loss : 5.4932210475970535, valid_loss : 5.106434011459351\n",
      "fold: 0, epoch: 1,                       train_loss : 4.494304406337249, valid_loss : 4.234142112731933\n",
      "fold: 0, epoch: 2,                       train_loss : 4.2779217438820085, valid_loss : 4.39392728805542\n",
      "fold: 0, epoch: 3,                       train_loss : 4.0901231949145975, valid_loss : 4.1905426502227785\n",
      "fold: 0, epoch: 4,                       train_loss : 4.079401034575242, valid_loss : 4.191880321502685\n",
      "fold: 0, epoch: 5,                       train_loss : 4.055342869880872, valid_loss : 4.358981895446777\n",
      "fold: 0, epoch: 6,                       train_loss : 4.174052629715357, valid_loss : 4.2537102699279785\n",
      "fold: 0, epoch: 7,                       train_loss : 4.110947407208956, valid_loss : 4.156444931030274\n",
      "fold: 0, epoch: 8,                       train_loss : 4.082757155100505, valid_loss : 4.625653696060181\n",
      "fold: 0, epoch: 9,                       train_loss : 4.0775673144902935, valid_loss : 4.360780477523804\n",
      "fold: 0, epoch: 10,                       train_loss : 4.188288199595916, valid_loss : 4.299335861206055\n",
      "fold: 0, epoch: 11,                       train_loss : 4.235936788412241, valid_loss : 4.176421070098877\n",
      "fold: 0, epoch: 12,                       train_loss : 4.058116283172216, valid_loss : 4.3034838199615475\n",
      "fold: 0, epoch: 13,                       train_loss : 4.221550531876393, valid_loss : 4.288874959945678\n",
      "fold: 0, epoch: 14,                       train_loss : 4.145152911161765, valid_loss : 4.07919225692749\n",
      "fold: 0, epoch: 15,                       train_loss : 4.077523182599973, valid_loss : 4.096692037582398\n",
      "fold: 1, epoch: 0,                       train_loss : 4.101104033298982, valid_loss : 4.855424976348877\n",
      "fold: 2, epoch: 0,                       train_loss : 4.0965148241091995, valid_loss : 4.310454511642456\n",
      "fold: 3, epoch: 0,                       train_loss : 4.291440743666429, valid_loss : 3.4937124252319336\n",
      "fold: 4, epoch: 0,                       train_loss : 4.089895382905618, valid_loss : 4.506240367889404\n",
      "fold: 5, epoch: 0,                       train_loss : 4.118267612579541, valid_loss : 3.5792054176330566\n",
      "fold: 6, epoch: 0,                       train_loss : 4.156788929914817, valid_loss : 4.746420049667359\n",
      "fold: 7, epoch: 0,                       train_loss : 4.080933301876753, valid_loss : 4.4597736358642575\n",
      "fold: 8, epoch: 0,                       train_loss : 4.089475003572611, valid_loss : 3.8887353897094727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:02:32,778]\u001b[0m Trial 27 finished with value: 4.21234049320221 and parameters: {'num_layers': 6, 'hidden_size': 130, 'batch_size': 70, 'learning_rate': 0.004977780489614476}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.132971977576231, valid_loss : 4.204245901107788\n",
      "fold: 0, epoch: 0,                       train_loss : 6.548175644874573, valid_loss : 7.564794699350993\n",
      "fold: 0, epoch: 1,                       train_loss : 6.5381081104278564, valid_loss : 6.878807067871094\n",
      "fold: 0, epoch: 2,                       train_loss : 6.320812177658081, valid_loss : 7.1497117678324384\n",
      "fold: 0, epoch: 3,                       train_loss : 6.406233644485473, valid_loss : 6.263260364532471\n",
      "fold: 0, epoch: 4,                       train_loss : 6.195597302913666, valid_loss : 6.553985595703125\n",
      "fold: 0, epoch: 5,                       train_loss : 6.106943249702454, valid_loss : 6.512697537740071\n",
      "fold: 0, epoch: 6,                       train_loss : 6.219459891319275, valid_loss : 5.506933609644572\n",
      "fold: 0, epoch: 7,                       train_loss : 6.013455271720886, valid_loss : 5.339430967966716\n",
      "fold: 0, epoch: 8,                       train_loss : 5.591202735900879, valid_loss : 5.527726332346599\n",
      "fold: 0, epoch: 9,                       train_loss : 5.258185851573944, valid_loss : 7.461140950520833\n",
      "fold: 0, epoch: 10,                       train_loss : 5.110728144645691, valid_loss : 5.5799563725789385\n",
      "fold: 0, epoch: 11,                       train_loss : 4.870569133758545, valid_loss : 5.758090019226074\n",
      "fold: 0, epoch: 12,                       train_loss : 4.522557723522186, valid_loss : 4.351245721181233\n",
      "fold: 0, epoch: 13,                       train_loss : 4.304020047187805, valid_loss : 4.617631276448567\n",
      "fold: 0, epoch: 14,                       train_loss : 4.091362047195434, valid_loss : 4.239628156026204\n",
      "fold: 0, epoch: 15,                       train_loss : 4.0566978573799135, valid_loss : 4.6335062980651855\n",
      "fold: 0, epoch: 16,                       train_loss : 4.082206153869629, valid_loss : 3.69728954633077\n",
      "fold: 0, epoch: 17,                       train_loss : 4.124321341514587, valid_loss : 4.768939971923828\n",
      "fold: 0, epoch: 18,                       train_loss : 3.9635388255119324, valid_loss : 5.1282548904418945\n",
      "fold: 1, epoch: 0,                       train_loss : 4.083464050292969, valid_loss : 3.858880122502645\n",
      "fold: 2, epoch: 0,                       train_loss : 4.0118249416351315, valid_loss : 3.7279763221740723\n",
      "fold: 3, epoch: 0,                       train_loss : 4.020258820056915, valid_loss : 3.9926609992980957\n",
      "fold: 4, epoch: 0,                       train_loss : 4.041190576553345, valid_loss : 4.11651086807251\n",
      "fold: 5, epoch: 0,                       train_loss : 4.092459428310394, valid_loss : 3.7491791248321533\n",
      "fold: 6, epoch: 0,                       train_loss : 4.2204793930053714, valid_loss : 4.778055667877197\n",
      "fold: 7, epoch: 0,                       train_loss : 4.123743450641632, valid_loss : 3.7787345250447593\n",
      "fold: 8, epoch: 0,                       train_loss : 4.1482941746711735, valid_loss : 3.668835719426473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:02:54,933]\u001b[0m Trial 28 finished with value: 3.9001558462778734 and parameters: {'num_layers': 5, 'hidden_size': 100, 'batch_size': 140, 'learning_rate': 0.0014181395165938008}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1431720495224, valid_loss : 3.6334355672200522\n",
      "fold: 0, epoch: 0,                       train_loss : 5.806222756703694, valid_loss : 5.848404884338379\n",
      "fold: 0, epoch: 1,                       train_loss : 5.739221608197248, valid_loss : 5.778586228688558\n",
      "fold: 0, epoch: 2,                       train_loss : 5.654729578230116, valid_loss : 5.707228660583496\n",
      "fold: 0, epoch: 3,                       train_loss : 5.577670998043484, valid_loss : 5.602564652760823\n",
      "fold: 0, epoch: 4,                       train_loss : 5.488358038443106, valid_loss : 5.5049638748168945\n",
      "fold: 0, epoch: 5,                       train_loss : 5.382218678792317, valid_loss : 5.368180751800537\n",
      "fold: 0, epoch: 6,                       train_loss : 5.255740324656169, valid_loss : 5.1988546053568525\n",
      "fold: 0, epoch: 7,                       train_loss : 5.067810906304254, valid_loss : 4.975659052530925\n",
      "fold: 0, epoch: 8,                       train_loss : 4.845762190995393, valid_loss : 4.72220245997111\n",
      "fold: 0, epoch: 9,                       train_loss : 4.621125680428964, valid_loss : 4.489649772644043\n",
      "fold: 0, epoch: 10,                       train_loss : 4.4031998757962825, valid_loss : 4.310623566309611\n",
      "fold: 0, epoch: 11,                       train_loss : 4.266393246474089, valid_loss : 4.195890506108602\n",
      "fold: 0, epoch: 12,                       train_loss : 4.190131072644834, valid_loss : 4.142526785532634\n",
      "fold: 0, epoch: 13,                       train_loss : 4.147414119155319, valid_loss : 4.121221701304118\n",
      "fold: 0, epoch: 14,                       train_loss : 4.130188783009847, valid_loss : 4.117369810740153\n",
      "fold: 0, epoch: 15,                       train_loss : 4.160560325339988, valid_loss : 4.115642627080281\n",
      "fold: 0, epoch: 16,                       train_loss : 4.139831437004937, valid_loss : 4.109881083170573\n",
      "fold: 0, epoch: 17,                       train_loss : 4.14924974794741, valid_loss : 4.107435305913289\n",
      "fold: 0, epoch: 18,                       train_loss : 4.143784452367712, valid_loss : 4.109206040700276\n",
      "fold: 0, epoch: 19,                       train_loss : 4.12955109278361, valid_loss : 4.115711768468221\n",
      "fold: 0, epoch: 20,                       train_loss : 4.128749202798914, valid_loss : 4.106409390767415\n",
      "fold: 0, epoch: 21,                       train_loss : 4.143859412935045, valid_loss : 4.095544179280599\n",
      "fold: 0, epoch: 22,                       train_loss : 4.131263079466643, valid_loss : 4.1185862223307295\n",
      "fold: 0, epoch: 23,                       train_loss : 4.146101986920392, valid_loss : 4.115381240844727\n",
      "fold: 0, epoch: 24,                       train_loss : 4.13712677249202, valid_loss : 4.112882137298584\n",
      "fold: 0, epoch: 25,                       train_loss : 4.140910519493951, valid_loss : 4.110620657602946\n",
      "fold: 0, epoch: 26,                       train_loss : 4.124823888142903, valid_loss : 4.1031257311503095\n",
      "fold: 0, epoch: 27,                       train_loss : 4.142706217589201, valid_loss : 4.096814155578613\n",
      "fold: 0, epoch: 28,                       train_loss : 4.139538014376605, valid_loss : 4.1175127029418945\n",
      "fold: 0, epoch: 29,                       train_loss : 4.156187101646706, valid_loss : 4.1157340208689375\n",
      "fold: 0, epoch: 30,                       train_loss : 4.150617740772389, valid_loss : 4.10300079981486\n",
      "fold: 1, epoch: 0,                       train_loss : 4.12198543548584, valid_loss : 4.2679963906606035\n",
      "fold: 2, epoch: 0,                       train_loss : 4.114464609711258, valid_loss : 4.311055501302083\n",
      "fold: 3, epoch: 0,                       train_loss : 4.165498777672097, valid_loss : 4.0422046184539795\n",
      "fold: 4, epoch: 0,                       train_loss : 4.141509550589102, valid_loss : 3.9732751846313477\n",
      "fold: 5, epoch: 0,                       train_loss : 4.134573583249693, valid_loss : 4.095720926920573\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1773539295902955, valid_loss : 3.963346799214681\n",
      "fold: 7, epoch: 0,                       train_loss : 4.098576254314846, valid_loss : 4.498522122701009\n",
      "fold: 8, epoch: 0,                       train_loss : 4.120577282375759, valid_loss : 4.287956953048706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:03:39,339]\u001b[0m Trial 29 finished with value: 4.132401196161906 and parameters: {'num_layers': 6, 'hidden_size': 110, 'batch_size': 100, 'learning_rate': 0.0010451810135942005}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.163159449895223, valid_loss : 3.788389285405477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([180, 1])) that is different to the input size (torch.Size([180])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([144, 1])) that is different to the input size (torch.Size([144])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([116, 1])) that is different to the input size (torch.Size([116])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 5.878257338205973, valid_loss : 5.261976957321167\n",
      "fold: 0, epoch: 1,                       train_loss : 5.760542106628418, valid_loss : 5.29820704460144\n",
      "fold: 0, epoch: 2,                       train_loss : 5.631383164723714, valid_loss : 5.18787407875061\n",
      "fold: 0, epoch: 3,                       train_loss : 5.442862288157145, valid_loss : 4.830242395401001\n",
      "fold: 0, epoch: 4,                       train_loss : 5.098858388264974, valid_loss : 4.347821831703186\n",
      "fold: 0, epoch: 5,                       train_loss : 4.480812406539917, valid_loss : 3.9152865409851074\n",
      "fold: 0, epoch: 6,                       train_loss : 4.189570522308349, valid_loss : 3.883673906326294\n",
      "fold: 0, epoch: 7,                       train_loss : 4.162471373875936, valid_loss : 3.9444334506988525\n",
      "fold: 0, epoch: 8,                       train_loss : 4.160848124821981, valid_loss : 3.986687660217285\n",
      "fold: 0, epoch: 9,                       train_loss : 4.154030799865723, valid_loss : 3.8634228706359863\n",
      "fold: 0, epoch: 10,                       train_loss : 4.154815069834391, valid_loss : 3.913844347000122\n",
      "fold: 0, epoch: 11,                       train_loss : 4.1690105438232425, valid_loss : 3.8744455575942993\n",
      "fold: 0, epoch: 12,                       train_loss : 4.158974615732829, valid_loss : 3.8578699827194214\n",
      "fold: 0, epoch: 13,                       train_loss : 4.171513589223226, valid_loss : 3.835685610771179\n",
      "fold: 0, epoch: 14,                       train_loss : 4.159415086110433, valid_loss : 3.921464443206787\n",
      "fold: 0, epoch: 15,                       train_loss : 4.165109268824259, valid_loss : 3.838064432144165\n",
      "fold: 0, epoch: 16,                       train_loss : 4.158450778325399, valid_loss : 3.970961332321167\n",
      "fold: 0, epoch: 17,                       train_loss : 4.15251251856486, valid_loss : 3.832131505012512\n",
      "fold: 0, epoch: 18,                       train_loss : 4.161638673146566, valid_loss : 3.8938223123550415\n",
      "fold: 0, epoch: 19,                       train_loss : 4.165305058161418, valid_loss : 3.911628246307373\n",
      "fold: 0, epoch: 20,                       train_loss : 4.149205621083578, valid_loss : 3.8441309928894043\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1404066721598305, valid_loss : 4.1620941162109375\n",
      "fold: 2, epoch: 0,                       train_loss : 4.135259071985881, valid_loss : 4.232499003410339\n",
      "fold: 3, epoch: 0,                       train_loss : 4.180710633595784, valid_loss : 3.6812950372695923\n",
      "fold: 4, epoch: 0,                       train_loss : 4.131792259216309, valid_loss : 4.253942966461182\n",
      "fold: 5, epoch: 0,                       train_loss : 4.1712383270263675, valid_loss : 3.8184844255447388\n",
      "fold: 6, epoch: 0,                       train_loss : 4.156635348002116, valid_loss : 3.8768646717071533\n",
      "fold: 7, epoch: 0,                       train_loss : 4.143176301320394, valid_loss : 4.024595379829407\n",
      "fold: 8, epoch: 0,                       train_loss : 4.055119482676188, valid_loss : 4.86519455909729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:03:54,413]\u001b[0m Trial 30 finished with value: 4.090767347812653 and parameters: {'num_layers': 6, 'hidden_size': 70, 'batch_size': 180, 'learning_rate': 0.0014842789374656337}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.12590339978536, valid_loss : 4.160571813583374\n",
      "fold: 0, epoch: 0,                       train_loss : 6.027102828025818, valid_loss : 6.650683561960856\n",
      "fold: 0, epoch: 1,                       train_loss : 5.181404423713684, valid_loss : 5.823626677195231\n",
      "fold: 0, epoch: 2,                       train_loss : 4.248134875297547, valid_loss : 3.954517046610514\n",
      "fold: 0, epoch: 3,                       train_loss : 4.322549438476562, valid_loss : 4.06709082921346\n",
      "fold: 0, epoch: 4,                       train_loss : 3.968581235408783, valid_loss : 3.7703891595204673\n",
      "fold: 0, epoch: 5,                       train_loss : 4.073469257354736, valid_loss : 4.792400201161702\n",
      "fold: 0, epoch: 6,                       train_loss : 3.9707183718681334, valid_loss : 4.100786288579305\n",
      "fold: 0, epoch: 7,                       train_loss : 3.959502837061882, valid_loss : 4.320510069529216\n",
      "fold: 0, epoch: 8,                       train_loss : 4.069952213764191, valid_loss : 3.8156753381093345\n",
      "fold: 0, epoch: 9,                       train_loss : 3.997483468055725, valid_loss : 4.426804383595784\n",
      "fold: 0, epoch: 10,                       train_loss : 4.004907929897309, valid_loss : 5.31333605448405\n",
      "fold: 0, epoch: 11,                       train_loss : 3.9968610882759092, valid_loss : 4.535855134328206\n",
      "fold: 0, epoch: 12,                       train_loss : 4.068161916732788, valid_loss : 4.099867661794026\n",
      "fold: 0, epoch: 13,                       train_loss : 4.021166253089905, valid_loss : 4.078989585240682\n",
      "fold: 0, epoch: 14,                       train_loss : 4.0020667791366575, valid_loss : 4.155318260192871\n",
      "fold: 1, epoch: 0,                       train_loss : 3.9516159534454345, valid_loss : 4.809971332550049\n",
      "fold: 2, epoch: 0,                       train_loss : 4.4774717569351195, valid_loss : 4.237562735875447\n",
      "fold: 3, epoch: 0,                       train_loss : 4.010671854019165, valid_loss : 3.737513860066732\n",
      "fold: 4, epoch: 0,                       train_loss : 4.039764678478241, valid_loss : 4.5173860390981035\n",
      "fold: 5, epoch: 0,                       train_loss : 4.004768109321594, valid_loss : 4.104244073232015\n",
      "fold: 6, epoch: 0,                       train_loss : 4.082017707824707, valid_loss : 4.579306443532308\n",
      "fold: 7, epoch: 0,                       train_loss : 4.277926445007324, valid_loss : 3.92318065961202\n",
      "fold: 8, epoch: 0,                       train_loss : 4.134661030769348, valid_loss : 3.3136932055155435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:04:11,511]\u001b[0m Trial 31 finished with value: 4.262720155715941 and parameters: {'num_layers': 5, 'hidden_size': 90, 'batch_size': 140, 'learning_rate': 0.007663159769770831}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.3108337163925174, valid_loss : 5.633954048156738\n",
      "fold: 0, epoch: 0,                       train_loss : 6.401253654843285, valid_loss : 6.363691171010335\n",
      "fold: 0, epoch: 1,                       train_loss : 6.072198981330509, valid_loss : 6.223245779673259\n",
      "fold: 0, epoch: 2,                       train_loss : 5.089847996121361, valid_loss : 4.261497735977173\n",
      "fold: 0, epoch: 3,                       train_loss : 4.1739498774210615, valid_loss : 4.13090984026591\n",
      "fold: 0, epoch: 4,                       train_loss : 4.130268993831816, valid_loss : 4.307227452596028\n",
      "fold: 0, epoch: 5,                       train_loss : 4.127903484162831, valid_loss : 4.029892047246297\n",
      "fold: 0, epoch: 6,                       train_loss : 4.144445237659273, valid_loss : 4.54602066675822\n",
      "fold: 0, epoch: 7,                       train_loss : 4.120251962116787, valid_loss : 4.53770899772644\n",
      "fold: 0, epoch: 8,                       train_loss : 4.097195477712722, valid_loss : 4.285782814025879\n",
      "fold: 0, epoch: 9,                       train_loss : 4.119894311541603, valid_loss : 4.623290618260701\n",
      "fold: 0, epoch: 10,                       train_loss : 4.136457000459943, valid_loss : 4.509581247965495\n",
      "fold: 0, epoch: 11,                       train_loss : 4.101416553769793, valid_loss : 4.283891042073567\n",
      "fold: 0, epoch: 12,                       train_loss : 4.0903471651531405, valid_loss : 4.467245578765869\n",
      "fold: 0, epoch: 13,                       train_loss : 4.147828578948975, valid_loss : 4.3786384264628095\n",
      "fold: 0, epoch: 14,                       train_loss : 4.1219549633207775, valid_loss : 4.184517065684001\n",
      "fold: 0, epoch: 15,                       train_loss : 4.101212978363037, valid_loss : 4.482770681381226\n",
      "fold: 1, epoch: 0,                       train_loss : 4.102709531784058, valid_loss : 4.585692087809245\n",
      "fold: 2, epoch: 0,                       train_loss : 4.1619917665209085, valid_loss : 3.9000500043233237\n",
      "fold: 3, epoch: 0,                       train_loss : 4.159110602878389, valid_loss : 3.7022291819254556\n",
      "fold: 4, epoch: 0,                       train_loss : 4.162814446857998, valid_loss : 3.852349281311035\n",
      "fold: 5, epoch: 0,                       train_loss : 4.08302887280782, valid_loss : 4.728570381800334\n",
      "fold: 6, epoch: 0,                       train_loss : 4.167760406221662, valid_loss : 4.432075023651123\n",
      "fold: 7, epoch: 0,                       train_loss : 4.114082132066999, valid_loss : 4.123454491297404\n",
      "fold: 8, epoch: 0,                       train_loss : 4.1223300865718295, valid_loss : 4.19566011428833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:04:34,259]\u001b[0m Trial 32 finished with value: 4.141565489768982 and parameters: {'num_layers': 5, 'hidden_size': 110, 'batch_size': 130, 'learning_rate': 0.002799227426657678}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1464817978086925, valid_loss : 3.865682284037272\n",
      "fold: 0, epoch: 0,                       train_loss : 5.641620953877767, valid_loss : 6.3089118003845215\n",
      "fold: 0, epoch: 1,                       train_loss : 5.522193087471856, valid_loss : 6.177204608917236\n",
      "fold: 0, epoch: 2,                       train_loss : 5.3920623726314965, valid_loss : 6.012401342391968\n",
      "fold: 0, epoch: 3,                       train_loss : 5.226990540822347, valid_loss : 5.825374126434326\n",
      "fold: 0, epoch: 4,                       train_loss : 4.982859187655979, valid_loss : 5.522826910018921\n",
      "fold: 0, epoch: 5,                       train_loss : 4.5880921019448175, valid_loss : 5.120462417602539\n",
      "fold: 0, epoch: 6,                       train_loss : 4.144653254085117, valid_loss : 4.827606678009033\n",
      "fold: 0, epoch: 7,                       train_loss : 4.067370004124111, valid_loss : 4.830438613891602\n",
      "fold: 0, epoch: 8,                       train_loss : 4.0582490762074785, valid_loss : 4.830630779266357\n",
      "fold: 0, epoch: 9,                       train_loss : 4.055620696809557, valid_loss : 4.825072526931763\n",
      "fold: 0, epoch: 10,                       train_loss : 4.062512079874675, valid_loss : 4.831111192703247\n",
      "fold: 0, epoch: 11,                       train_loss : 4.054460008939107, valid_loss : 4.829914331436157\n",
      "fold: 0, epoch: 12,                       train_loss : 4.048566434118483, valid_loss : 4.819430351257324\n",
      "fold: 0, epoch: 13,                       train_loss : 4.054527521133423, valid_loss : 4.841647744178772\n",
      "fold: 0, epoch: 14,                       train_loss : 4.057325707541572, valid_loss : 4.830074787139893\n",
      "fold: 0, epoch: 15,                       train_loss : 4.051853550804986, valid_loss : 4.823306322097778\n",
      "fold: 0, epoch: 16,                       train_loss : 4.0677962568071155, valid_loss : 4.822166681289673\n",
      "fold: 0, epoch: 17,                       train_loss : 4.061340729395549, valid_loss : 4.832191467285156\n",
      "fold: 0, epoch: 18,                       train_loss : 4.0624766614702015, valid_loss : 4.8240647315979\n",
      "fold: 0, epoch: 19,                       train_loss : 4.0714262459013195, valid_loss : 4.826632022857666\n",
      "fold: 1, epoch: 0,                       train_loss : 4.179127481248644, valid_loss : 3.7869378328323364\n",
      "fold: 2, epoch: 0,                       train_loss : 4.120502101050483, valid_loss : 4.2208662033081055\n",
      "fold: 3, epoch: 0,                       train_loss : 4.188187638918559, valid_loss : 3.732514262199402\n",
      "fold: 4, epoch: 0,                       train_loss : 4.123053378529018, valid_loss : 4.178801894187927\n",
      "fold: 5, epoch: 0,                       train_loss : 4.108067750930786, valid_loss : 4.342016935348511\n",
      "fold: 6, epoch: 0,                       train_loss : 4.186327324973212, valid_loss : 3.672579050064087\n",
      "fold: 7, epoch: 0,                       train_loss : 4.087290962537129, valid_loss : 4.600669860839844\n",
      "fold: 8, epoch: 0,                       train_loss : 4.128553456730312, valid_loss : 4.2719690799713135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:04:51,946]\u001b[0m Trial 33 finished with value: 4.139219617843628 and parameters: {'num_layers': 6, 'hidden_size': 80, 'batch_size': 150, 'learning_rate': 0.0013744135202940128}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.16792635122935, valid_loss : 3.766410708427429\n",
      "fold: 0, epoch: 0,                       train_loss : 6.408665657043457, valid_loss : 6.0951128005981445\n",
      "fold: 0, epoch: 1,                       train_loss : 5.960333683911492, valid_loss : 5.439836263656616\n",
      "fold: 0, epoch: 2,                       train_loss : 5.188375501071706, valid_loss : 4.741194486618042\n",
      "fold: 0, epoch: 3,                       train_loss : 4.3190558237188, valid_loss : 4.131239056587219\n",
      "fold: 0, epoch: 4,                       train_loss : 4.138120412826538, valid_loss : 4.083780288696289\n",
      "fold: 0, epoch: 5,                       train_loss : 4.137166065328262, valid_loss : 4.09971809387207\n",
      "fold: 0, epoch: 6,                       train_loss : 4.146966793957879, valid_loss : 4.096661329269409\n",
      "fold: 0, epoch: 7,                       train_loss : 4.127393343869378, valid_loss : 4.085975885391235\n",
      "fold: 0, epoch: 8,                       train_loss : 4.133138418197632, valid_loss : 4.075553059577942\n",
      "fold: 0, epoch: 9,                       train_loss : 4.14617133140564, valid_loss : 4.081791400909424\n",
      "fold: 0, epoch: 10,                       train_loss : 4.1359809566946595, valid_loss : 4.095492959022522\n",
      "fold: 0, epoch: 11,                       train_loss : 4.145242929458618, valid_loss : 4.080826759338379\n",
      "fold: 0, epoch: 12,                       train_loss : 4.135276738335104, valid_loss : 4.081299066543579\n",
      "fold: 0, epoch: 13,                       train_loss : 4.146912280250998, valid_loss : 4.054002642631531\n",
      "fold: 0, epoch: 14,                       train_loss : 4.139690357096055, valid_loss : 4.0324097871780396\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1560453807606415, valid_loss : 4.034170389175415\n",
      "fold: 0, epoch: 16,                       train_loss : 4.141347562565523, valid_loss : 4.113731026649475\n",
      "fold: 0, epoch: 17,                       train_loss : 4.120731732424567, valid_loss : 4.125606536865234\n",
      "fold: 0, epoch: 18,                       train_loss : 4.144845808253569, valid_loss : 4.088824033737183\n",
      "fold: 1, epoch: 0,                       train_loss : 4.207439759198357, valid_loss : 3.8352683782577515\n",
      "fold: 2, epoch: 0,                       train_loss : 4.12430227504057, valid_loss : 3.958686590194702\n",
      "fold: 3, epoch: 0,                       train_loss : 4.115789876264684, valid_loss : 4.271345853805542\n",
      "fold: 4, epoch: 0,                       train_loss : 4.184531927108765, valid_loss : 3.6321632862091064\n",
      "fold: 5, epoch: 0,                       train_loss : 4.125798379673677, valid_loss : 4.16958475112915\n",
      "fold: 6, epoch: 0,                       train_loss : 4.131174929001752, valid_loss : 4.125421166419983\n",
      "fold: 7, epoch: 0,                       train_loss : 4.074273221633014, valid_loss : 4.892004489898682\n",
      "fold: 8, epoch: 0,                       train_loss : 4.195862756055944, valid_loss : 3.6022340059280396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:05:16,297]\u001b[0m Trial 34 finished with value: 4.12888731956482 and parameters: {'num_layers': 4, 'hidden_size': 140, 'batch_size': 160, 'learning_rate': 0.00544653258899736}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.069134712219238, valid_loss : 4.769754886627197\n",
      "fold: 0, epoch: 0,                       train_loss : 6.199654865264892, valid_loss : 5.83702294031779\n",
      "fold: 0, epoch: 1,                       train_loss : 5.180854301452637, valid_loss : 4.475604057312012\n",
      "fold: 0, epoch: 2,                       train_loss : 4.149333028793335, valid_loss : 4.250542879104614\n",
      "fold: 0, epoch: 3,                       train_loss : 4.113528442382813, valid_loss : 4.233147780100505\n",
      "fold: 0, epoch: 4,                       train_loss : 4.112876491546631, valid_loss : 4.146827141443889\n",
      "fold: 0, epoch: 5,                       train_loss : 4.0899695301055905, valid_loss : 4.306012471516927\n",
      "fold: 0, epoch: 6,                       train_loss : 4.205936689376831, valid_loss : 4.30033524831136\n",
      "fold: 0, epoch: 7,                       train_loss : 4.1622114086151125, valid_loss : 4.22732933362325\n",
      "fold: 0, epoch: 8,                       train_loss : 4.111208810806274, valid_loss : 4.1695122718811035\n",
      "fold: 0, epoch: 9,                       train_loss : 4.124055700302124, valid_loss : 4.219903628031413\n",
      "fold: 0, epoch: 10,                       train_loss : 4.094310235977173, valid_loss : 4.2630055745442705\n",
      "fold: 0, epoch: 11,                       train_loss : 4.109669723510742, valid_loss : 4.252803564071655\n",
      "fold: 0, epoch: 12,                       train_loss : 4.052346968650818, valid_loss : 4.288410027821858\n",
      "fold: 0, epoch: 13,                       train_loss : 4.113462800979614, valid_loss : 4.327834447224935\n",
      "fold: 0, epoch: 14,                       train_loss : 4.122714548110962, valid_loss : 4.298505067825317\n",
      "fold: 0, epoch: 15,                       train_loss : 4.109227819442749, valid_loss : 4.3069101969401045\n",
      "fold: 1, epoch: 0,                       train_loss : 4.106540670394898, valid_loss : 3.9998653729756675\n",
      "fold: 2, epoch: 0,                       train_loss : 4.0809838008880615, valid_loss : 4.552688519159953\n",
      "fold: 3, epoch: 0,                       train_loss : 4.219264049530029, valid_loss : 4.152504285176595\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1753170204162595, valid_loss : 3.960035562515259\n",
      "fold: 5, epoch: 0,                       train_loss : 4.164083127975464, valid_loss : 4.033920129140218\n",
      "fold: 6, epoch: 0,                       train_loss : 4.113863306045532, valid_loss : 3.987879196802775\n",
      "fold: 7, epoch: 0,                       train_loss : 4.153347177505493, valid_loss : 3.723361094792684\n",
      "fold: 8, epoch: 0,                       train_loss : 4.162107048034668, valid_loss : 4.734704971313477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:05:32,694]\u001b[0m Trial 35 finished with value: 4.117542846997578 and parameters: {'num_layers': 5, 'hidden_size': 60, 'batch_size': 110, 'learning_rate': 0.011615186195404213}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.182007875442505, valid_loss : 3.8836421966552734\n",
      "fold: 0, epoch: 0,                       train_loss : 5.243053504398891, valid_loss : 4.900540987650554\n",
      "fold: 0, epoch: 1,                       train_loss : 4.808553525379726, valid_loss : 4.527745723724365\n",
      "fold: 0, epoch: 2,                       train_loss : 4.4719302994864325, valid_loss : 4.475510756174724\n",
      "fold: 0, epoch: 3,                       train_loss : 4.319218646912348, valid_loss : 3.8891995747884116\n",
      "fold: 0, epoch: 4,                       train_loss : 4.231682584399269, valid_loss : 4.25878890355428\n",
      "fold: 0, epoch: 5,                       train_loss : 4.174826871781122, valid_loss : 3.938379685084025\n",
      "fold: 0, epoch: 6,                       train_loss : 4.16948726063683, valid_loss : 3.912553866704305\n",
      "fold: 0, epoch: 7,                       train_loss : 4.159887132190523, valid_loss : 3.5469089349110923\n",
      "fold: 0, epoch: 8,                       train_loss : 4.154683453696115, valid_loss : 4.698779741923015\n",
      "fold: 0, epoch: 9,                       train_loss : 4.179276750201271, valid_loss : 4.182929913202922\n",
      "fold: 0, epoch: 10,                       train_loss : 4.151435976936703, valid_loss : 4.2955537637074785\n",
      "fold: 0, epoch: 11,                       train_loss : 4.155933777491252, valid_loss : 3.7517903645833335\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1422362554641, valid_loss : 3.9897116820017495\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1439877805255705, valid_loss : 4.368103663126628\n",
      "fold: 0, epoch: 14,                       train_loss : 4.19916972659883, valid_loss : 4.01471225420634\n",
      "fold: 0, epoch: 15,                       train_loss : 4.125056210018339, valid_loss : 3.9007084369659424\n",
      "fold: 1, epoch: 0,                       train_loss : 4.10472846031189, valid_loss : 4.174666563669841\n",
      "fold: 2, epoch: 0,                       train_loss : 4.167401234308879, valid_loss : 3.687446673711141\n",
      "fold: 3, epoch: 0,                       train_loss : 4.086969489143009, valid_loss : 4.469743410746257\n",
      "fold: 4, epoch: 0,                       train_loss : 4.12672563961574, valid_loss : 4.108330408732097\n",
      "fold: 5, epoch: 0,                       train_loss : 4.1823199817112515, valid_loss : 3.9768784840901694\n",
      "fold: 6, epoch: 0,                       train_loss : 4.159779821123395, valid_loss : 3.8623900413513184\n",
      "fold: 7, epoch: 0,                       train_loss : 4.145929370607648, valid_loss : 4.434893767038981\n",
      "fold: 8, epoch: 0,                       train_loss : 4.135430767422631, valid_loss : 4.426362832387288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:05:52,193]\u001b[0m Trial 36 finished with value: 4.073220745722454 and parameters: {'num_layers': 1, 'hidden_size': 100, 'batch_size': 130, 'learning_rate': 0.027631279842108978}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.127470799854824, valid_loss : 4.044586340586345\n",
      "fold: 0, epoch: 0,                       train_loss : 6.1406435171763105, valid_loss : 6.009386777877808\n",
      "fold: 0, epoch: 1,                       train_loss : 6.092151376936171, valid_loss : 5.956662178039551\n",
      "fold: 0, epoch: 2,                       train_loss : 6.077367464701335, valid_loss : 5.912159204483032\n",
      "fold: 0, epoch: 3,                       train_loss : 5.998496267530653, valid_loss : 5.861056566238403\n",
      "fold: 0, epoch: 4,                       train_loss : 5.9565947320726185, valid_loss : 5.808502435684204\n",
      "fold: 0, epoch: 5,                       train_loss : 5.905957566367255, valid_loss : 5.736548185348511\n",
      "fold: 0, epoch: 6,                       train_loss : 5.842852036158244, valid_loss : 5.67500114440918\n",
      "fold: 0, epoch: 7,                       train_loss : 5.768282996283637, valid_loss : 5.59788179397583\n",
      "fold: 0, epoch: 8,                       train_loss : 5.686560763253106, valid_loss : 5.5273683071136475\n",
      "fold: 0, epoch: 9,                       train_loss : 5.6227588123745385, valid_loss : 5.4211461544036865\n",
      "fold: 0, epoch: 10,                       train_loss : 5.4878794352213545, valid_loss : 5.319349527359009\n",
      "fold: 0, epoch: 11,                       train_loss : 5.381864070892334, valid_loss : 5.219001531600952\n",
      "fold: 0, epoch: 12,                       train_loss : 5.275388585196601, valid_loss : 5.101197242736816\n",
      "fold: 0, epoch: 13,                       train_loss : 5.150047805574205, valid_loss : 4.967048168182373\n",
      "fold: 0, epoch: 14,                       train_loss : 5.001231643888685, valid_loss : 4.8063225746154785\n",
      "fold: 0, epoch: 15,                       train_loss : 4.85603470272488, valid_loss : 4.640070080757141\n",
      "fold: 0, epoch: 16,                       train_loss : 4.699489858415392, valid_loss : 4.479706525802612\n",
      "fold: 0, epoch: 17,                       train_loss : 4.539525257216559, valid_loss : 4.332222938537598\n",
      "fold: 0, epoch: 18,                       train_loss : 4.426737176047431, valid_loss : 4.194464683532715\n",
      "fold: 0, epoch: 19,                       train_loss : 4.287567946645948, valid_loss : 4.098884105682373\n",
      "fold: 0, epoch: 20,                       train_loss : 4.22617150677575, valid_loss : 4.052598237991333\n",
      "fold: 0, epoch: 21,                       train_loss : 4.181427558263143, valid_loss : 4.011104464530945\n",
      "fold: 0, epoch: 22,                       train_loss : 4.166992902755737, valid_loss : 3.987534761428833\n",
      "fold: 0, epoch: 23,                       train_loss : 4.144240273369683, valid_loss : 3.9706060886383057\n",
      "fold: 0, epoch: 24,                       train_loss : 4.149321595827739, valid_loss : 3.9910744428634644\n",
      "fold: 0, epoch: 25,                       train_loss : 4.152015924453735, valid_loss : 3.982555389404297\n",
      "fold: 0, epoch: 26,                       train_loss : 4.15818096531762, valid_loss : 3.973734140396118\n",
      "fold: 0, epoch: 27,                       train_loss : 4.151979102028741, valid_loss : 3.9799749851226807\n",
      "fold: 0, epoch: 28,                       train_loss : 4.147271103329128, valid_loss : 3.980399012565613\n",
      "fold: 0, epoch: 29,                       train_loss : 4.141300373607212, valid_loss : 3.9702357053756714\n",
      "fold: 0, epoch: 30,                       train_loss : 4.15405629740821, valid_loss : 3.9849822521209717\n",
      "fold: 0, epoch: 31,                       train_loss : 4.152590288056268, valid_loss : 3.98652720451355\n",
      "fold: 0, epoch: 32,                       train_loss : 4.1515447166230945, valid_loss : 3.9855847358703613\n",
      "fold: 0, epoch: 33,                       train_loss : 4.14574392636617, valid_loss : 3.982589602470398\n",
      "fold: 0, epoch: 34,                       train_loss : 4.163827313317193, valid_loss : 3.978455424308777\n",
      "fold: 0, epoch: 35,                       train_loss : 4.152729286087884, valid_loss : 3.9813880920410156\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1204858091142444, valid_loss : 4.2037599086761475\n",
      "fold: 2, epoch: 0,                       train_loss : 4.154085132810804, valid_loss : 4.036764621734619\n",
      "fold: 3, epoch: 0,                       train_loss : 4.140377097659641, valid_loss : 4.103535771369934\n",
      "fold: 4, epoch: 0,                       train_loss : 4.067806641260783, valid_loss : 4.625103116035461\n",
      "fold: 5, epoch: 0,                       train_loss : 4.137254887157017, valid_loss : 4.046725273132324\n",
      "fold: 6, epoch: 0,                       train_loss : 4.118354108598497, valid_loss : 4.216773509979248\n",
      "fold: 7, epoch: 0,                       train_loss : 4.177937441402012, valid_loss : 3.8074848651885986\n",
      "fold: 8, epoch: 0,                       train_loss : 4.097298330730862, valid_loss : 4.357443332672119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:06:38,063]\u001b[0m Trial 37 finished with value: 4.132405698299408 and parameters: {'num_layers': 5, 'hidden_size': 160, 'batch_size': 150, 'learning_rate': 0.0006370393427096682}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1612646447287664, valid_loss : 3.956230878829956\n",
      "fold: 0, epoch: 0,                       train_loss : 6.044032796223958, valid_loss : 5.973050355911255\n",
      "fold: 0, epoch: 1,                       train_loss : 5.77543272972107, valid_loss : 5.767264008522034\n",
      "fold: 0, epoch: 2,                       train_loss : 5.48148725827535, valid_loss : 5.805444836616516\n",
      "fold: 0, epoch: 3,                       train_loss : 5.161733531951905, valid_loss : 5.021077752113342\n",
      "fold: 0, epoch: 4,                       train_loss : 4.870060427983602, valid_loss : 4.651982009410858\n",
      "fold: 0, epoch: 5,                       train_loss : 4.5876358350118, valid_loss : 4.324733376502991\n",
      "fold: 0, epoch: 6,                       train_loss : 4.381445741653442, valid_loss : 4.396281003952026\n",
      "fold: 0, epoch: 7,                       train_loss : 4.254523030916849, valid_loss : 4.309949815273285\n",
      "fold: 0, epoch: 8,                       train_loss : 4.207432532310486, valid_loss : 4.6966025829315186\n",
      "fold: 0, epoch: 9,                       train_loss : 4.1817158460617065, valid_loss : 4.336008310317993\n",
      "fold: 0, epoch: 10,                       train_loss : 4.141950329144795, valid_loss : 4.572380483150482\n",
      "fold: 0, epoch: 11,                       train_loss : 4.139164002736409, valid_loss : 3.9105011224746704\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1336989402771, valid_loss : 4.538352072238922\n",
      "fold: 0, epoch: 13,                       train_loss : 4.128308558464051, valid_loss : 4.32443767786026\n",
      "fold: 0, epoch: 14,                       train_loss : 4.132884558041891, valid_loss : 4.006267964839935\n",
      "fold: 0, epoch: 15,                       train_loss : 4.147758404413859, valid_loss : 4.170557677745819\n",
      "fold: 0, epoch: 16,                       train_loss : 4.135209933916728, valid_loss : 4.026260435581207\n",
      "fold: 0, epoch: 17,                       train_loss : 4.126856199900309, valid_loss : 3.958266019821167\n",
      "fold: 1, epoch: 0,                       train_loss : 4.170413629213969, valid_loss : 3.7317278385162354\n",
      "fold: 2, epoch: 0,                       train_loss : 4.143916932741801, valid_loss : 4.015298306941986\n",
      "fold: 3, epoch: 0,                       train_loss : 4.088718946774801, valid_loss : 4.459961295127869\n",
      "fold: 4, epoch: 0,                       train_loss : 4.116794570287069, valid_loss : 4.2894821763038635\n",
      "fold: 5, epoch: 0,                       train_loss : 4.21810941696167, valid_loss : 3.4100998044013977\n",
      "fold: 6, epoch: 0,                       train_loss : 4.179701018333435, valid_loss : 3.439736008644104\n",
      "fold: 7, epoch: 0,                       train_loss : 4.144347707430522, valid_loss : 4.567671298980713\n",
      "fold: 8, epoch: 0,                       train_loss : 4.043210220336914, valid_loss : 4.767519593238831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:06:56,751]\u001b[0m Trial 38 finished with value: 4.038670706748962 and parameters: {'num_layers': 3, 'hidden_size': 50, 'batch_size': 90, 'learning_rate': 0.004184215963251755}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1392338673273725, valid_loss : 3.794709622859955\n",
      "fold: 0, epoch: 0,                       train_loss : 6.446496516466141, valid_loss : 6.724130868911743\n",
      "fold: 0, epoch: 1,                       train_loss : 6.42451474070549, valid_loss : 6.765229225158691\n",
      "fold: 0, epoch: 2,                       train_loss : 6.373593211174011, valid_loss : 6.744283199310303\n",
      "fold: 0, epoch: 3,                       train_loss : 6.359742373228073, valid_loss : 6.696812629699707\n",
      "fold: 0, epoch: 4,                       train_loss : 6.323914438486099, valid_loss : 6.672270059585571\n",
      "fold: 0, epoch: 5,                       train_loss : 6.302187860012054, valid_loss : 6.590618848800659\n",
      "fold: 0, epoch: 6,                       train_loss : 6.254737764596939, valid_loss : 6.6067986488342285\n",
      "fold: 0, epoch: 7,                       train_loss : 6.238869398832321, valid_loss : 6.447570562362671\n",
      "fold: 0, epoch: 8,                       train_loss : 6.203437626361847, valid_loss : 6.466189861297607\n",
      "fold: 0, epoch: 9,                       train_loss : 6.171986609697342, valid_loss : 6.517596960067749\n",
      "fold: 0, epoch: 10,                       train_loss : 6.140764653682709, valid_loss : 6.4661970138549805\n",
      "fold: 0, epoch: 11,                       train_loss : 6.087712079286575, valid_loss : 6.333257436752319\n",
      "fold: 0, epoch: 12,                       train_loss : 6.0306150913238525, valid_loss : 6.347524881362915\n",
      "fold: 0, epoch: 13,                       train_loss : 6.0210311114788055, valid_loss : 6.419006824493408\n",
      "fold: 0, epoch: 14,                       train_loss : 5.9320579171180725, valid_loss : 6.30065655708313\n",
      "fold: 0, epoch: 15,                       train_loss : 5.887134462594986, valid_loss : 6.175184965133667\n",
      "fold: 0, epoch: 16,                       train_loss : 5.828257322311401, valid_loss : 6.048426151275635\n",
      "fold: 0, epoch: 17,                       train_loss : 5.7480036318302155, valid_loss : 6.035836458206177\n",
      "fold: 0, epoch: 18,                       train_loss : 5.6954600512981415, valid_loss : 6.03778076171875\n",
      "fold: 0, epoch: 19,                       train_loss : 5.619138330221176, valid_loss : 5.942774057388306\n",
      "fold: 0, epoch: 20,                       train_loss : 5.570520997047424, valid_loss : 5.840046167373657\n",
      "fold: 0, epoch: 21,                       train_loss : 5.5135819017887115, valid_loss : 5.739269256591797\n",
      "fold: 0, epoch: 22,                       train_loss : 5.4193167090415955, valid_loss : 5.702264070510864\n",
      "fold: 0, epoch: 23,                       train_loss : 5.349508315324783, valid_loss : 5.606849431991577\n",
      "fold: 0, epoch: 24,                       train_loss : 5.244799882173538, valid_loss : 5.536436319351196\n",
      "fold: 0, epoch: 25,                       train_loss : 5.146291762590408, valid_loss : 5.474416255950928\n",
      "fold: 0, epoch: 26,                       train_loss : 5.088319405913353, valid_loss : 5.347497224807739\n",
      "fold: 0, epoch: 27,                       train_loss : 5.008933335542679, valid_loss : 5.328179597854614\n",
      "fold: 0, epoch: 28,                       train_loss : 4.912606626749039, valid_loss : 5.178675889968872\n",
      "fold: 0, epoch: 29,                       train_loss : 4.8696474730968475, valid_loss : 5.137285232543945\n",
      "fold: 0, epoch: 30,                       train_loss : 4.778382048010826, valid_loss : 5.061536550521851\n",
      "fold: 0, epoch: 31,                       train_loss : 4.692292228341103, valid_loss : 4.8898606300354\n",
      "fold: 0, epoch: 32,                       train_loss : 4.6199479550123215, valid_loss : 4.910310745239258\n",
      "fold: 0, epoch: 33,                       train_loss : 4.560833439230919, valid_loss : 4.862173318862915\n",
      "fold: 0, epoch: 34,                       train_loss : 4.500374272465706, valid_loss : 4.8033692836761475\n",
      "fold: 0, epoch: 35,                       train_loss : 4.434452757239342, valid_loss : 4.597590446472168\n",
      "fold: 0, epoch: 36,                       train_loss : 4.387868970632553, valid_loss : 4.6690285205841064\n",
      "fold: 1, epoch: 0,                       train_loss : 4.401529744267464, valid_loss : 4.384722709655762\n",
      "fold: 2, epoch: 0,                       train_loss : 4.336366504430771, valid_loss : 4.497973918914795\n",
      "fold: 3, epoch: 0,                       train_loss : 4.2518559992313385, valid_loss : 4.789472579956055\n",
      "fold: 4, epoch: 0,                       train_loss : 4.3393329083919525, valid_loss : 3.9058656692504883\n",
      "fold: 5, epoch: 0,                       train_loss : 4.241917744278908, valid_loss : 4.340319395065308\n",
      "fold: 6, epoch: 0,                       train_loss : 4.239431768655777, valid_loss : 4.261845111846924\n",
      "fold: 7, epoch: 0,                       train_loss : 4.214374244213104, valid_loss : 4.153937339782715\n",
      "fold: 8, epoch: 0,                       train_loss : 4.19745409488678, valid_loss : 4.016260981559753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:07:20,821]\u001b[0m Trial 39 finished with value: 4.2776582598686215 and parameters: {'num_layers': 6, 'hidden_size': 70, 'batch_size': 170, 'learning_rate': 0.0006695591493298288}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.2337804436683655, valid_loss : 3.828594446182251\n",
      "fold: 0, epoch: 0,                       train_loss : 6.446323394775391, valid_loss : 6.102595806121826\n",
      "fold: 0, epoch: 1,                       train_loss : 6.373078795040355, valid_loss : 6.0042665004730225\n",
      "fold: 0, epoch: 2,                       train_loss : 6.267200301675236, valid_loss : 5.898847341537476\n",
      "fold: 0, epoch: 3,                       train_loss : 6.120292439180262, valid_loss : 5.585451364517212\n",
      "fold: 0, epoch: 4,                       train_loss : 5.741223054773667, valid_loss : 5.170598030090332\n",
      "fold: 0, epoch: 5,                       train_loss : 5.207132087034338, valid_loss : 4.53812575340271\n",
      "fold: 0, epoch: 6,                       train_loss : 4.5792896887835335, valid_loss : 3.981023907661438\n",
      "fold: 0, epoch: 7,                       train_loss : 4.207921939737656, valid_loss : 3.831288456916809\n",
      "fold: 0, epoch: 8,                       train_loss : 4.177472871892593, valid_loss : 3.821677088737488\n",
      "fold: 0, epoch: 9,                       train_loss : 4.178421230877147, valid_loss : 3.829561710357666\n",
      "fold: 0, epoch: 10,                       train_loss : 4.172778101528392, valid_loss : 3.7764865159988403\n",
      "fold: 0, epoch: 11,                       train_loss : 4.175777309081134, valid_loss : 3.7752901315689087\n",
      "fold: 0, epoch: 12,                       train_loss : 4.164869056028478, valid_loss : 3.774309992790222\n",
      "fold: 0, epoch: 13,                       train_loss : 4.182573150185978, valid_loss : 3.8034162521362305\n",
      "fold: 0, epoch: 14,                       train_loss : 4.167323350906372, valid_loss : 3.8549365997314453\n",
      "fold: 0, epoch: 15,                       train_loss : 4.167958708370433, valid_loss : 3.795406937599182\n",
      "fold: 0, epoch: 16,                       train_loss : 4.153193165274227, valid_loss : 3.8419915437698364\n",
      "fold: 0, epoch: 17,                       train_loss : 4.160618782043457, valid_loss : 3.8408504724502563\n",
      "fold: 0, epoch: 18,                       train_loss : 4.1767478690427895, valid_loss : 3.815335988998413\n",
      "fold: 0, epoch: 19,                       train_loss : 4.180663221022662, valid_loss : 3.814940094947815\n",
      "fold: 0, epoch: 20,                       train_loss : 4.160351514816284, valid_loss : 3.788793206214905\n",
      "fold: 0, epoch: 21,                       train_loss : 4.191160454469569, valid_loss : 3.8273966312408447\n",
      "fold: 0, epoch: 22,                       train_loss : 4.165488495546229, valid_loss : 3.8037803173065186\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1052533878999595, valid_loss : 4.361988306045532\n",
      "fold: 2, epoch: 0,                       train_loss : 4.132100904689116, valid_loss : 4.207133769989014\n",
      "fold: 3, epoch: 0,                       train_loss : 4.139117731767542, valid_loss : 4.091457486152649\n",
      "fold: 4, epoch: 0,                       train_loss : 4.036971232470344, valid_loss : 4.873831272125244\n",
      "fold: 5, epoch: 0,                       train_loss : 4.171292361091165, valid_loss : 3.702720880508423\n",
      "fold: 6, epoch: 0,                       train_loss : 4.17962134585661, valid_loss : 3.809114933013916\n",
      "fold: 7, epoch: 0,                       train_loss : 4.10636835939744, valid_loss : 4.509496212005615\n",
      "fold: 8, epoch: 0,                       train_loss : 4.185759754741893, valid_loss : 3.852811098098755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:07:48,054]\u001b[0m Trial 40 finished with value: 4.129370093345642 and parameters: {'num_layers': 4, 'hidden_size': 140, 'batch_size': 160, 'learning_rate': 0.0022324975965339394}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1283491779776185, valid_loss : 4.110836982727051\n",
      "fold: 0, epoch: 0,                       train_loss : 5.813055447169712, valid_loss : 4.753191232681274\n",
      "fold: 0, epoch: 1,                       train_loss : 4.579722938083467, valid_loss : 4.694673617680867\n",
      "fold: 0, epoch: 2,                       train_loss : 4.170379366193499, valid_loss : 3.7670764128367105\n",
      "fold: 0, epoch: 3,                       train_loss : 4.157754886718023, valid_loss : 4.26563040415446\n",
      "fold: 0, epoch: 4,                       train_loss : 4.141213167281378, valid_loss : 4.625222047170003\n",
      "fold: 0, epoch: 5,                       train_loss : 4.1243539197104315, valid_loss : 3.6359780629475913\n",
      "fold: 0, epoch: 6,                       train_loss : 4.123547508603051, valid_loss : 3.678950548171997\n",
      "fold: 0, epoch: 7,                       train_loss : 4.131092923028128, valid_loss : 3.9156812826792398\n",
      "fold: 0, epoch: 8,                       train_loss : 4.151681230181739, valid_loss : 3.9353296756744385\n",
      "fold: 0, epoch: 9,                       train_loss : 4.14549826440357, valid_loss : 4.0655568440755205\n",
      "fold: 0, epoch: 10,                       train_loss : 4.127923817861648, valid_loss : 3.997010866800944\n",
      "fold: 0, epoch: 11,                       train_loss : 4.142841429937453, valid_loss : 4.713048140207927\n",
      "fold: 0, epoch: 12,                       train_loss : 4.112429902667091, valid_loss : 4.1407398382822675\n",
      "fold: 0, epoch: 13,                       train_loss : 4.146375588008335, valid_loss : 4.453086773554484\n",
      "fold: 0, epoch: 14,                       train_loss : 4.180514392398653, valid_loss : 4.331928571065267\n",
      "fold: 1, epoch: 0,                       train_loss : 4.201633816673642, valid_loss : 3.82728640238444\n",
      "fold: 2, epoch: 0,                       train_loss : 4.130961894989014, valid_loss : 4.136012713114421\n",
      "fold: 3, epoch: 0,                       train_loss : 4.114508356366839, valid_loss : 4.29510776201884\n",
      "fold: 4, epoch: 0,                       train_loss : 4.145814600444975, valid_loss : 4.060344854990642\n",
      "fold: 5, epoch: 0,                       train_loss : 4.115303788866315, valid_loss : 4.458230336507161\n",
      "fold: 6, epoch: 0,                       train_loss : 4.129166500908988, valid_loss : 4.5579887231191\n",
      "fold: 7, epoch: 0,                       train_loss : 4.196047919137137, valid_loss : 3.4706780115763345\n",
      "fold: 8, epoch: 0,                       train_loss : 4.1407354445684526, valid_loss : 3.9299580256144204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:07:58,615]\u001b[0m Trial 41 finished with value: 4.02245458761851 and parameters: {'num_layers': 6, 'hidden_size': 40, 'batch_size': 130, 'learning_rate': 0.007424072984020207}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.142725808279855, valid_loss : 3.85296098391215\n",
      "fold: 0, epoch: 0,                       train_loss : 5.901685428619385, valid_loss : 4.4463426272074384\n",
      "fold: 0, epoch: 1,                       train_loss : 4.302263832092285, valid_loss : 3.9771032333374023\n",
      "fold: 0, epoch: 2,                       train_loss : 4.1452445220947265, valid_loss : 3.9103055000305176\n",
      "fold: 0, epoch: 3,                       train_loss : 4.146696910858155, valid_loss : 3.9307032426198325\n",
      "fold: 0, epoch: 4,                       train_loss : 4.136189489364624, valid_loss : 3.928938945134481\n",
      "fold: 0, epoch: 5,                       train_loss : 4.177661399841309, valid_loss : 3.9032480716705322\n",
      "fold: 0, epoch: 6,                       train_loss : 4.208080816268921, valid_loss : 3.9701987902323403\n",
      "fold: 0, epoch: 7,                       train_loss : 4.235365886688232, valid_loss : 3.9042464892069497\n",
      "fold: 0, epoch: 8,                       train_loss : 4.146363096237183, valid_loss : 3.9524362087249756\n",
      "fold: 0, epoch: 9,                       train_loss : 4.0861769914627075, valid_loss : 3.941593329111735\n",
      "fold: 0, epoch: 10,                       train_loss : 4.208383808135986, valid_loss : 3.9229896068573\n",
      "fold: 0, epoch: 11,                       train_loss : 4.158158254623413, valid_loss : 4.0126953125\n",
      "fold: 0, epoch: 12,                       train_loss : 4.264883832931519, valid_loss : 3.879448970158895\n",
      "fold: 0, epoch: 13,                       train_loss : 4.183004961013794, valid_loss : 3.9288198947906494\n",
      "fold: 0, epoch: 14,                       train_loss : 4.126416873931885, valid_loss : 3.9221299489339194\n",
      "fold: 0, epoch: 15,                       train_loss : 4.149291400909424, valid_loss : 3.9922191301981607\n",
      "fold: 1, epoch: 0,                       train_loss : 4.170026969909668, valid_loss : 4.197768449783325\n",
      "fold: 2, epoch: 0,                       train_loss : 4.144707775115966, valid_loss : 3.9840215047200522\n",
      "fold: 3, epoch: 0,                       train_loss : 4.148816804885865, valid_loss : 4.788179794947307\n",
      "fold: 4, epoch: 0,                       train_loss : 4.193729724884033, valid_loss : 3.569921096165975\n",
      "fold: 5, epoch: 0,                       train_loss : 4.223744430541992, valid_loss : 3.860607465108236\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1178398609161375, valid_loss : 4.287760337193807\n",
      "fold: 7, epoch: 0,                       train_loss : 4.135175313949585, valid_loss : 4.224032878875732\n",
      "fold: 8, epoch: 0,                       train_loss : 4.149633131027222, valid_loss : 4.182734568913777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:08:12,986]\u001b[0m Trial 42 finished with value: 4.151098863283794 and parameters: {'num_layers': 6, 'hidden_size': 50, 'batch_size': 110, 'learning_rate': 0.008694345698539524}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.098623304367066, valid_loss : 4.536513566970825\n",
      "fold: 0, epoch: 0,                       train_loss : 6.317060926686162, valid_loss : 6.978535811106364\n",
      "fold: 0, epoch: 1,                       train_loss : 6.292002905970034, valid_loss : 7.010749181111653\n",
      "fold: 0, epoch: 2,                       train_loss : 6.330291312673817, valid_loss : 6.566585063934326\n",
      "fold: 0, epoch: 3,                       train_loss : 6.2889610580776045, valid_loss : 6.613882541656494\n",
      "fold: 0, epoch: 4,                       train_loss : 6.230513717817224, valid_loss : 6.86544942855835\n",
      "fold: 0, epoch: 5,                       train_loss : 6.350782062696374, valid_loss : 6.587161223093669\n",
      "fold: 0, epoch: 6,                       train_loss : 6.279768736466117, valid_loss : 6.541223526000977\n",
      "fold: 0, epoch: 7,                       train_loss : 6.205968276314113, valid_loss : 6.746312618255615\n",
      "fold: 0, epoch: 8,                       train_loss : 6.271898062332816, valid_loss : 6.596551418304443\n",
      "fold: 0, epoch: 9,                       train_loss : 6.28522371209186, valid_loss : 6.9608438809712725\n",
      "fold: 0, epoch: 10,                       train_loss : 6.182965485945992, valid_loss : 6.894791126251221\n",
      "fold: 0, epoch: 11,                       train_loss : 6.137738538824993, valid_loss : 6.602944850921631\n",
      "fold: 0, epoch: 12,                       train_loss : 6.192217308542003, valid_loss : 6.824310302734375\n",
      "fold: 0, epoch: 13,                       train_loss : 6.220610017361849, valid_loss : 6.5989006360371905\n",
      "fold: 1, epoch: 0,                       train_loss : 6.253978107286536, valid_loss : 6.322667916615804\n",
      "fold: 2, epoch: 0,                       train_loss : 6.301915085834006, valid_loss : 5.7443437576293945\n",
      "fold: 3, epoch: 0,                       train_loss : 6.243298634238865, valid_loss : 5.938509941101074\n",
      "fold: 4, epoch: 0,                       train_loss : 6.179740553316862, valid_loss : 6.178681214650472\n",
      "fold: 5, epoch: 0,                       train_loss : 6.06406195267387, valid_loss : 6.894900321960449\n",
      "fold: 6, epoch: 0,                       train_loss : 6.191786040430483, valid_loss : 6.005446116129558\n",
      "fold: 7, epoch: 0,                       train_loss : 6.171486211859661, valid_loss : 6.332067966461182\n",
      "fold: 8, epoch: 0,                       train_loss : 6.19481086730957, valid_loss : 6.247155825297038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:08:31,482]\u001b[0m Trial 43 finished with value: 6.20663776397705 and parameters: {'num_layers': 6, 'hidden_size': 90, 'batch_size': 120, 'learning_rate': 0.000434629845652702}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 6.2097146614738135, valid_loss : 5.8613810539245605\n",
      "fold: 0, epoch: 0,                       train_loss : 6.543676900863647, valid_loss : 7.146299997965495\n",
      "fold: 0, epoch: 1,                       train_loss : 6.26541109085083, valid_loss : 6.3216172854105634\n",
      "fold: 0, epoch: 2,                       train_loss : 5.6457091808319095, valid_loss : 5.669664065043132\n",
      "fold: 0, epoch: 3,                       train_loss : 5.411884522438049, valid_loss : 5.568295955657959\n",
      "fold: 0, epoch: 4,                       train_loss : 5.366246318817138, valid_loss : 4.956892331441243\n",
      "fold: 0, epoch: 5,                       train_loss : 5.165808880329132, valid_loss : 4.852541287740071\n",
      "fold: 0, epoch: 6,                       train_loss : 4.790033328533172, valid_loss : 4.742211818695068\n",
      "fold: 0, epoch: 7,                       train_loss : 4.515988087654113, valid_loss : 4.972730000813802\n",
      "fold: 0, epoch: 8,                       train_loss : 4.539363384246826, valid_loss : 5.351192633310954\n",
      "fold: 0, epoch: 9,                       train_loss : 4.294524335861206, valid_loss : 4.742649873097737\n",
      "fold: 0, epoch: 10,                       train_loss : 4.295132279396057, valid_loss : 3.9204845428466797\n",
      "fold: 0, epoch: 11,                       train_loss : 4.196098685264587, valid_loss : 4.924660682678223\n",
      "fold: 0, epoch: 12,                       train_loss : 4.092836654186248, valid_loss : 3.430987517038981\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1299227476119995, valid_loss : 4.699652036031087\n",
      "fold: 0, epoch: 14,                       train_loss : 4.348342478275299, valid_loss : 4.108056465784709\n",
      "fold: 0, epoch: 15,                       train_loss : 4.203372287750244, valid_loss : 4.597093423207601\n",
      "fold: 0, epoch: 16,                       train_loss : 4.520412540435791, valid_loss : 3.6228811740875244\n",
      "fold: 0, epoch: 17,                       train_loss : 4.1020895600318905, valid_loss : 4.218313614527385\n",
      "fold: 0, epoch: 18,                       train_loss : 4.069269037246704, valid_loss : 4.540701150894165\n",
      "fold: 0, epoch: 19,                       train_loss : 4.16784896850586, valid_loss : 3.948707103729248\n",
      "fold: 1, epoch: 0,                       train_loss : 4.068010866641998, valid_loss : 4.899602174758911\n",
      "fold: 2, epoch: 0,                       train_loss : 3.9876965403556826, valid_loss : 4.297620058059692\n",
      "fold: 3, epoch: 0,                       train_loss : 4.171245384216308, valid_loss : 4.254661401112874\n",
      "fold: 4, epoch: 0,                       train_loss : 4.119799184799194, valid_loss : 2.997363726298014\n",
      "fold: 5, epoch: 0,                       train_loss : 4.166639816761017, valid_loss : 4.511419296264648\n",
      "fold: 6, epoch: 0,                       train_loss : 3.9650283336639403, valid_loss : 4.266374905904134\n",
      "fold: 7, epoch: 0,                       train_loss : 4.38847564458847, valid_loss : 3.9055665334065757\n",
      "fold: 8, epoch: 0,                       train_loss : 3.992176580429077, valid_loss : 3.8971426486968994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:08:41,267]\u001b[0m Trial 44 finished with value: 4.100706768035888 and parameters: {'num_layers': 2, 'hidden_size': 30, 'batch_size': 140, 'learning_rate': 0.01648008855765259}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.175754904747009, valid_loss : 4.546329418818156\n",
      "fold: 0, epoch: 0,                       train_loss : 6.4203054791405085, valid_loss : 6.118179798126221\n",
      "fold: 0, epoch: 1,                       train_loss : 6.308820134117489, valid_loss : 6.3505880037943525\n",
      "fold: 0, epoch: 2,                       train_loss : 6.239267508188884, valid_loss : 6.109256744384766\n",
      "fold: 0, epoch: 3,                       train_loss : 6.036230382465181, valid_loss : 5.998409430185954\n",
      "fold: 0, epoch: 4,                       train_loss : 5.879745710463751, valid_loss : 5.499693393707275\n",
      "fold: 0, epoch: 5,                       train_loss : 5.362963381267729, valid_loss : 5.037999629974365\n",
      "fold: 0, epoch: 6,                       train_loss : 4.435924132664998, valid_loss : 3.980696360270182\n",
      "fold: 0, epoch: 7,                       train_loss : 4.099903787885394, valid_loss : 4.494131088256836\n",
      "fold: 0, epoch: 8,                       train_loss : 4.135913769404094, valid_loss : 3.84704852104187\n",
      "fold: 0, epoch: 9,                       train_loss : 4.1216175102052235, valid_loss : 4.42866309483846\n",
      "fold: 0, epoch: 10,                       train_loss : 4.117213771456764, valid_loss : 4.128966569900513\n",
      "fold: 0, epoch: 11,                       train_loss : 4.127052840732393, valid_loss : 4.475657780965169\n",
      "fold: 0, epoch: 12,                       train_loss : 4.118471406754994, valid_loss : 4.665967067082723\n",
      "fold: 0, epoch: 13,                       train_loss : 4.116331361588978, valid_loss : 4.318619092305501\n",
      "fold: 0, epoch: 14,                       train_loss : 4.110809223992484, valid_loss : 3.8562753200531006\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1318039780571345, valid_loss : 4.564837137858073\n",
      "fold: 0, epoch: 16,                       train_loss : 4.101619357154483, valid_loss : 3.9618815581003823\n",
      "fold: 0, epoch: 17,                       train_loss : 4.137950919923329, valid_loss : 4.022323846817017\n",
      "fold: 1, epoch: 0,                       train_loss : 4.143754084904988, valid_loss : 4.433104912439982\n",
      "fold: 2, epoch: 0,                       train_loss : 4.197287377857027, valid_loss : 3.7416934172312417\n",
      "fold: 3, epoch: 0,                       train_loss : 4.12813857623509, valid_loss : 4.261547565460205\n",
      "fold: 4, epoch: 0,                       train_loss : 4.131856327965146, valid_loss : 3.9785735607147217\n",
      "fold: 5, epoch: 0,                       train_loss : 4.127111945833478, valid_loss : 4.049828211466472\n",
      "fold: 6, epoch: 0,                       train_loss : 4.139052754356747, valid_loss : 3.9016334215799966\n",
      "fold: 7, epoch: 0,                       train_loss : 4.1707921255202525, valid_loss : 4.204264005025228\n",
      "fold: 8, epoch: 0,                       train_loss : 4.127764247712635, valid_loss : 4.197595755259196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:09:08,374]\u001b[0m Trial 45 finished with value: 4.0534116665522255 and parameters: {'num_layers': 5, 'hidden_size': 130, 'batch_size': 130, 'learning_rate': 0.0016646881988376843}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.109080768766857, valid_loss : 3.9188272953033447\n",
      "fold: 0, epoch: 0,                       train_loss : 5.894987358766444, valid_loss : 5.322920560836792\n",
      "fold: 0, epoch: 1,                       train_loss : 5.753479761235854, valid_loss : 5.135997772216797\n",
      "fold: 0, epoch: 2,                       train_loss : 5.551388740539551, valid_loss : 4.9626171588897705\n",
      "fold: 0, epoch: 3,                       train_loss : 5.360275380751666, valid_loss : 4.793227434158325\n",
      "fold: 0, epoch: 4,                       train_loss : 5.108158756704891, valid_loss : 4.5695273876190186\n",
      "fold: 0, epoch: 5,                       train_loss : 4.860029501073501, valid_loss : 4.3827773332595825\n",
      "fold: 0, epoch: 6,                       train_loss : 4.6041059914757225, valid_loss : 4.130439639091492\n",
      "fold: 0, epoch: 7,                       train_loss : 4.446245011161356, valid_loss : 4.049422264099121\n",
      "fold: 0, epoch: 8,                       train_loss : 4.336103537503411, valid_loss : 3.9510380029678345\n",
      "fold: 0, epoch: 9,                       train_loss : 4.228580376681159, valid_loss : 3.9081403017044067\n",
      "fold: 0, epoch: 10,                       train_loss : 4.182872617945952, valid_loss : 3.929309368133545\n",
      "fold: 0, epoch: 11,                       train_loss : 4.17154915192548, valid_loss : 3.89273464679718\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1682506168589875, valid_loss : 3.90239155292511\n",
      "fold: 0, epoch: 13,                       train_loss : 4.145550910164328, valid_loss : 3.8819483518600464\n",
      "fold: 0, epoch: 14,                       train_loss : 4.161673503763535, valid_loss : 3.93209445476532\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1654864900252395, valid_loss : 3.9228549003601074\n",
      "fold: 0, epoch: 16,                       train_loss : 4.15085311496959, valid_loss : 3.9080443382263184\n",
      "fold: 0, epoch: 17,                       train_loss : 4.153574887443991, valid_loss : 3.9369568824768066\n",
      "fold: 0, epoch: 18,                       train_loss : 4.143958049661973, valid_loss : 3.9528032541275024\n",
      "fold: 0, epoch: 19,                       train_loss : 4.150001722223618, valid_loss : 3.938636064529419\n",
      "fold: 0, epoch: 20,                       train_loss : 4.161722225301406, valid_loss : 3.886743903160095\n",
      "fold: 0, epoch: 21,                       train_loss : 4.148899218615363, valid_loss : 3.973283290863037\n",
      "fold: 0, epoch: 22,                       train_loss : 4.134073299520156, valid_loss : 3.924814820289612\n",
      "fold: 1, epoch: 0,                       train_loss : 4.141307480194989, valid_loss : 4.081409931182861\n",
      "fold: 2, epoch: 0,                       train_loss : 4.109574430129108, valid_loss : 4.4118053913116455\n",
      "fold: 3, epoch: 0,                       train_loss : 4.139863378861371, valid_loss : 4.13218879699707\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1721168546115655, valid_loss : 3.915787100791931\n",
      "fold: 5, epoch: 0,                       train_loss : 4.118191312341129, valid_loss : 4.092522025108337\n",
      "fold: 6, epoch: 0,                       train_loss : 4.175166382509119, valid_loss : 3.856698989868164\n",
      "fold: 7, epoch: 0,                       train_loss : 4.084819611381082, valid_loss : 4.5456764698028564\n",
      "fold: 8, epoch: 0,                       train_loss : 4.067505822462194, valid_loss : 4.55384635925293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:09:29,640]\u001b[0m Trial 46 finished with value: 4.125573074817657 and parameters: {'num_layers': 5, 'hidden_size': 100, 'batch_size': 160, 'learning_rate': 0.004571471079791675}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.172322834239287, valid_loss : 3.7838473320007324\n",
      "fold: 0, epoch: 0,                       train_loss : 5.340913689654807, valid_loss : 5.289633433024089\n",
      "fold: 0, epoch: 1,                       train_loss : 4.237385936405348, valid_loss : 4.326839049657186\n",
      "fold: 0, epoch: 2,                       train_loss : 4.151304545609848, valid_loss : 4.782151540120442\n",
      "fold: 0, epoch: 3,                       train_loss : 4.054274144379989, valid_loss : 4.693190097808838\n",
      "fold: 0, epoch: 4,                       train_loss : 4.060759378516155, valid_loss : 4.412966728210449\n",
      "fold: 0, epoch: 5,                       train_loss : 4.0898815445278, valid_loss : 4.500314394632976\n",
      "fold: 0, epoch: 6,                       train_loss : 4.104646475418754, valid_loss : 4.397860924402873\n",
      "fold: 0, epoch: 7,                       train_loss : 4.125639200210571, valid_loss : 4.461110909779866\n",
      "fold: 0, epoch: 8,                       train_loss : 4.065970721452133, valid_loss : 4.4454911549886065\n",
      "fold: 0, epoch: 9,                       train_loss : 4.084919234980708, valid_loss : 4.412647565205892\n",
      "fold: 0, epoch: 10,                       train_loss : 4.099460798761119, valid_loss : 4.6236998240153\n",
      "fold: 0, epoch: 11,                       train_loss : 4.145400814388109, valid_loss : 4.605287392934163\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1064962511477265, valid_loss : 4.558791319529216\n",
      "fold: 1, epoch: 0,                       train_loss : 4.071690476459006, valid_loss : 4.759836673736572\n",
      "fold: 2, epoch: 0,                       train_loss : 4.13903316207554, valid_loss : 3.921739101409912\n",
      "fold: 3, epoch: 0,                       train_loss : 4.126658937205439, valid_loss : 3.827909787495931\n",
      "fold: 4, epoch: 0,                       train_loss : 4.15044671556224, valid_loss : 4.15118130048116\n",
      "fold: 5, epoch: 0,                       train_loss : 4.255137650862984, valid_loss : 3.6477259000142417\n",
      "fold: 6, epoch: 0,                       train_loss : 4.235989425493323, valid_loss : 4.01864767074585\n",
      "fold: 7, epoch: 0,                       train_loss : 4.105392290198284, valid_loss : 3.856435855229696\n",
      "fold: 8, epoch: 0,                       train_loss : 4.0649954339732295, valid_loss : 5.106676419576009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:09:43,118]\u001b[0m Trial 47 finished with value: 4.10159744421641 and parameters: {'num_layers': 6, 'hidden_size': 60, 'batch_size': 120, 'learning_rate': 0.005891795696001912}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1622567384139355, valid_loss : 3.3989826838175454\n",
      "fold: 0, epoch: 0,                       train_loss : 5.784501409530639, valid_loss : 6.135965506235759\n",
      "fold: 0, epoch: 1,                       train_loss : 5.940072846412659, valid_loss : 6.0226461092631025\n",
      "fold: 0, epoch: 2,                       train_loss : 6.0164310216903685, valid_loss : 5.5838623046875\n",
      "fold: 0, epoch: 3,                       train_loss : 6.0975443601608275, valid_loss : 6.069331010182698\n",
      "fold: 0, epoch: 4,                       train_loss : 5.75739688873291, valid_loss : 6.216406027475993\n",
      "fold: 0, epoch: 5,                       train_loss : 5.769725728034973, valid_loss : 6.86723518371582\n",
      "fold: 0, epoch: 6,                       train_loss : 5.89555516242981, valid_loss : 5.2150217692057295\n",
      "fold: 0, epoch: 7,                       train_loss : 6.235362482070923, valid_loss : 6.12475601832072\n",
      "fold: 0, epoch: 8,                       train_loss : 5.77362027168274, valid_loss : 5.520244280497233\n",
      "fold: 0, epoch: 9,                       train_loss : 5.654357314109802, valid_loss : 5.677175521850586\n",
      "fold: 0, epoch: 10,                       train_loss : 5.50783405303955, valid_loss : 7.252308368682861\n",
      "fold: 0, epoch: 11,                       train_loss : 6.460225319862365, valid_loss : 6.728461901346843\n",
      "fold: 0, epoch: 12,                       train_loss : 5.665715122222901, valid_loss : 5.767073790232341\n",
      "fold: 0, epoch: 13,                       train_loss : 5.562204873561859, valid_loss : 5.771999518076579\n",
      "fold: 0, epoch: 14,                       train_loss : 5.740118241310119, valid_loss : 6.345284779866536\n",
      "fold: 1, epoch: 0,                       train_loss : 5.806777787208557, valid_loss : 5.32008695602417\n",
      "fold: 2, epoch: 0,                       train_loss : 5.858009386062622, valid_loss : 6.665644804636638\n",
      "fold: 3, epoch: 0,                       train_loss : 5.7782601594924925, valid_loss : 5.288402875264485\n",
      "fold: 4, epoch: 0,                       train_loss : 5.912446618080139, valid_loss : 5.8638332684834795\n",
      "fold: 5, epoch: 0,                       train_loss : 5.484408235549926, valid_loss : 5.747465133666992\n",
      "fold: 6, epoch: 0,                       train_loss : 5.779764938354492, valid_loss : 4.658964951833089\n",
      "fold: 7, epoch: 0,                       train_loss : 5.919307684898376, valid_loss : 5.484123229980469\n",
      "fold: 8, epoch: 0,                       train_loss : 5.557350444793701, valid_loss : 5.075735092163086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:09:59,849]\u001b[0m Trial 48 finished with value: 5.441260282198588 and parameters: {'num_layers': 5, 'hidden_size': 80, 'batch_size': 140, 'learning_rate': 0.00017149964834154197}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 5.7415186882019045, valid_loss : 5.093324740727742\n",
      "fold: 0, epoch: 0,                       train_loss : 6.41840041478475, valid_loss : 6.246090650558472\n",
      "fold: 0, epoch: 1,                       train_loss : 5.75674737294515, valid_loss : 5.415217399597168\n",
      "fold: 0, epoch: 2,                       train_loss : 4.627522913614909, valid_loss : 4.134737014770508\n",
      "fold: 0, epoch: 3,                       train_loss : 4.193255043029785, valid_loss : 4.027228116989136\n",
      "fold: 0, epoch: 4,                       train_loss : 4.150051434834798, valid_loss : 4.005492687225342\n",
      "fold: 0, epoch: 5,                       train_loss : 4.133785279591878, valid_loss : 4.043980836868286\n",
      "fold: 0, epoch: 6,                       train_loss : 4.134189542134603, valid_loss : 4.165571451187134\n",
      "fold: 0, epoch: 7,                       train_loss : 4.134540526072184, valid_loss : 4.077766418457031\n",
      "fold: 0, epoch: 8,                       train_loss : 4.137851969401042, valid_loss : 4.067705154418945\n",
      "fold: 0, epoch: 9,                       train_loss : 4.137928406397502, valid_loss : 4.148728251457214\n",
      "fold: 0, epoch: 10,                       train_loss : 4.147846158345541, valid_loss : 4.032829999923706\n",
      "fold: 0, epoch: 11,                       train_loss : 4.143484846750895, valid_loss : 4.181850790977478\n",
      "fold: 0, epoch: 12,                       train_loss : 4.132122532526652, valid_loss : 4.242714881896973\n",
      "fold: 0, epoch: 13,                       train_loss : 4.13482042948405, valid_loss : 4.122214317321777\n",
      "fold: 0, epoch: 14,                       train_loss : 4.150537570317586, valid_loss : 4.01366913318634\n",
      "fold: 0, epoch: 15,                       train_loss : 4.138158353169759, valid_loss : 4.181312441825867\n",
      "fold: 1, epoch: 0,                       train_loss : 4.142737849553426, valid_loss : 4.295792579650879\n",
      "fold: 2, epoch: 0,                       train_loss : 4.132611974080404, valid_loss : 4.351843595504761\n",
      "fold: 3, epoch: 0,                       train_loss : 4.133054494857788, valid_loss : 4.047871947288513\n",
      "fold: 4, epoch: 0,                       train_loss : 4.05425059000651, valid_loss : 4.8264687061309814\n",
      "fold: 5, epoch: 0,                       train_loss : 4.149825032552084, valid_loss : 4.008897423744202\n",
      "fold: 6, epoch: 0,                       train_loss : 4.187179724375407, valid_loss : 3.8018617630004883\n",
      "fold: 7, epoch: 0,                       train_loss : 4.162693945566813, valid_loss : 3.8822896480560303\n",
      "fold: 8, epoch: 0,                       train_loss : 4.10220988591512, valid_loss : 4.3135902881622314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:10:17,458]\u001b[0m Trial 49 finished with value: 4.133662211894989 and parameters: {'num_layers': 3, 'hidden_size': 120, 'batch_size': 180, 'learning_rate': 0.010842403543460782}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.178252919514974, valid_loss : 3.8025134801864624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([50, 1])) that is different to the input size (torch.Size([50])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([14, 1])) that is different to the input size (torch.Size([14])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([46, 1])) that is different to the input size (torch.Size([46])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 6.768131609316225, valid_loss : 7.0211403369903564\n",
      "fold: 0, epoch: 1,                       train_loss : 6.516338745752971, valid_loss : 6.802258332570394\n",
      "fold: 0, epoch: 2,                       train_loss : 6.291434756031743, valid_loss : 6.5544655323028564\n",
      "fold: 0, epoch: 3,                       train_loss : 6.055378220699452, valid_loss : 6.370506366093953\n",
      "fold: 0, epoch: 4,                       train_loss : 5.869542717933655, valid_loss : 6.163540760676066\n",
      "fold: 0, epoch: 5,                       train_loss : 5.6653684068609165, valid_loss : 5.966302235921224\n",
      "fold: 0, epoch: 6,                       train_loss : 5.543834041666101, valid_loss : 5.812442620595296\n",
      "fold: 0, epoch: 7,                       train_loss : 5.336691564983791, valid_loss : 5.6599141756693525\n",
      "fold: 0, epoch: 8,                       train_loss : 5.225284223203306, valid_loss : 5.5495626131693525\n",
      "fold: 0, epoch: 9,                       train_loss : 5.066226561864217, valid_loss : 5.405620336532593\n",
      "fold: 0, epoch: 10,                       train_loss : 4.966869142320421, valid_loss : 5.3054993947347\n",
      "fold: 0, epoch: 11,                       train_loss : 4.829136980904473, valid_loss : 5.189358631769816\n",
      "fold: 0, epoch: 12,                       train_loss : 4.76725215823562, valid_loss : 5.126434365908305\n",
      "fold: 0, epoch: 13,                       train_loss : 4.680480144642018, valid_loss : 5.0601338148117065\n",
      "fold: 0, epoch: 14,                       train_loss : 4.604145986062509, valid_loss : 4.973051905632019\n",
      "fold: 0, epoch: 15,                       train_loss : 4.556997789276971, valid_loss : 4.9059016307195025\n",
      "fold: 0, epoch: 16,                       train_loss : 4.480225103872794, valid_loss : 4.8433146476745605\n",
      "fold: 0, epoch: 17,                       train_loss : 4.391996357176039, valid_loss : 4.805351614952087\n",
      "fold: 0, epoch: 18,                       train_loss : 4.371769551877622, valid_loss : 4.754786849021912\n",
      "fold: 0, epoch: 19,                       train_loss : 4.307314294355887, valid_loss : 4.735501488049825\n",
      "fold: 0, epoch: 20,                       train_loss : 4.318354641949689, valid_loss : 4.7094190915425616\n",
      "fold: 0, epoch: 21,                       train_loss : 4.250235040982564, valid_loss : 4.672508239746094\n",
      "fold: 0, epoch: 22,                       train_loss : 4.270095123185052, valid_loss : 4.635311285654704\n",
      "fold: 0, epoch: 23,                       train_loss : 4.240556677182515, valid_loss : 4.618617455164592\n",
      "fold: 0, epoch: 24,                       train_loss : 4.193035708533393, valid_loss : 4.598358829816182\n",
      "fold: 0, epoch: 25,                       train_loss : 4.157561235957676, valid_loss : 4.586869557698567\n",
      "fold: 0, epoch: 26,                       train_loss : 4.17096741994222, valid_loss : 4.553882956504822\n",
      "fold: 0, epoch: 27,                       train_loss : 4.13334596157074, valid_loss : 4.539815783500671\n",
      "fold: 0, epoch: 28,                       train_loss : 4.13570941598327, valid_loss : 4.540951251983643\n",
      "fold: 0, epoch: 29,                       train_loss : 4.161091685295105, valid_loss : 4.543565114339192\n",
      "fold: 0, epoch: 30,                       train_loss : 4.109609029911183, valid_loss : 4.514452775319417\n",
      "fold: 0, epoch: 31,                       train_loss : 4.113142799448084, valid_loss : 4.53278915087382\n",
      "fold: 0, epoch: 32,                       train_loss : 4.14074675683622, valid_loss : 4.494389136632283\n",
      "fold: 0, epoch: 33,                       train_loss : 4.1468118649941905, valid_loss : 4.505173166592916\n",
      "fold: 0, epoch: 34,                       train_loss : 4.094970597161187, valid_loss : 4.502294023831685\n",
      "fold: 0, epoch: 35,                       train_loss : 4.082708636919658, valid_loss : 4.47453773021698\n",
      "fold: 0, epoch: 36,                       train_loss : 4.070128323855223, valid_loss : 4.479345321655273\n",
      "fold: 0, epoch: 37,                       train_loss : 4.088867350860879, valid_loss : 4.482707103093465\n",
      "fold: 0, epoch: 38,                       train_loss : 4.127111200933103, valid_loss : 4.481027960777283\n",
      "fold: 0, epoch: 39,                       train_loss : 4.152624249458313, valid_loss : 4.460183461507161\n",
      "fold: 0, epoch: 40,                       train_loss : 4.129878719647725, valid_loss : 4.478090484937032\n",
      "fold: 0, epoch: 41,                       train_loss : 4.139803405161257, valid_loss : 4.485030849774678\n",
      "fold: 0, epoch: 42,                       train_loss : 4.085383940626074, valid_loss : 4.441340605417888\n",
      "fold: 0, epoch: 43,                       train_loss : 4.088852626306039, valid_loss : 4.4659803708394366\n",
      "fold: 1, epoch: 0,                       train_loss : 4.034739110204908, valid_loss : 4.800931096076965\n",
      "fold: 2, epoch: 0,                       train_loss : 4.133609643688908, valid_loss : 4.087352832158406\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1885863410101996, valid_loss : 3.7903740406036377\n",
      "fold: 4, epoch: 0,                       train_loss : 4.156734387079875, valid_loss : 4.171598394711812\n",
      "fold: 5, epoch: 0,                       train_loss : 4.110052903493245, valid_loss : 4.185106197992961\n",
      "fold: 6, epoch: 0,                       train_loss : 4.151116781764561, valid_loss : 4.196356693903605\n",
      "fold: 7, epoch: 0,                       train_loss : 4.177205147566618, valid_loss : 3.9244149923324585\n",
      "fold: 8, epoch: 0,                       train_loss : 4.155500849088033, valid_loss : 4.03564715385437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:11:38,271]\u001b[0m Trial 50 finished with value: 4.133081229527791 and parameters: {'num_layers': 1, 'hidden_size': 70, 'batch_size': 50, 'learning_rate': 0.003431674480317276}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.167788810200161, valid_loss : 3.6976902882258096\n",
      "fold: 0, epoch: 0,                       train_loss : 5.993621599106562, valid_loss : 6.142784436543782\n",
      "fold: 0, epoch: 1,                       train_loss : 5.73983097076416, valid_loss : 5.19215202331543\n",
      "fold: 0, epoch: 2,                       train_loss : 4.314626602899461, valid_loss : 4.168797254562378\n",
      "fold: 0, epoch: 3,                       train_loss : 4.142371995108468, valid_loss : 4.480213483174642\n",
      "fold: 0, epoch: 4,                       train_loss : 4.116835230872745, valid_loss : 3.9045073986053467\n",
      "fold: 0, epoch: 5,                       train_loss : 4.174031859352475, valid_loss : 4.33048947652181\n",
      "fold: 0, epoch: 6,                       train_loss : 4.118885517120361, valid_loss : 4.057024002075195\n",
      "fold: 0, epoch: 7,                       train_loss : 4.123315515972319, valid_loss : 4.473517020543416\n",
      "fold: 0, epoch: 8,                       train_loss : 4.113710664567494, valid_loss : 4.544776201248169\n",
      "fold: 0, epoch: 9,                       train_loss : 4.128268503007435, valid_loss : 3.9859414100646973\n",
      "fold: 0, epoch: 10,                       train_loss : 4.109148604529245, valid_loss : 4.4367298285166425\n",
      "fold: 0, epoch: 11,                       train_loss : 4.139967100960868, valid_loss : 4.268496990203857\n",
      "fold: 0, epoch: 12,                       train_loss : 4.11968013218471, valid_loss : 4.218281428019206\n",
      "fold: 0, epoch: 13,                       train_loss : 4.145239035288493, valid_loss : 4.58645494778951\n",
      "fold: 0, epoch: 14,                       train_loss : 4.110732169378371, valid_loss : 3.8311945597330728\n",
      "fold: 0, epoch: 15,                       train_loss : 4.125019266491845, valid_loss : 4.310323874155681\n",
      "fold: 1, epoch: 0,                       train_loss : 4.219154516855876, valid_loss : 3.246186892191569\n",
      "fold: 2, epoch: 0,                       train_loss : 4.10980004356021, valid_loss : 4.664127508799235\n",
      "fold: 3, epoch: 0,                       train_loss : 4.172665187290737, valid_loss : 3.6726718743642173\n",
      "fold: 4, epoch: 0,                       train_loss : 4.037464743568783, valid_loss : 4.928531805674235\n",
      "fold: 5, epoch: 0,                       train_loss : 4.196580932253883, valid_loss : 4.126289129257202\n",
      "fold: 6, epoch: 0,                       train_loss : 4.076589879535494, valid_loss : 4.690660317738851\n",
      "fold: 7, epoch: 0,                       train_loss : 4.110677753176008, valid_loss : 4.5527544021606445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:11:41,939]\u001b[0m Trial 51 finished with value: 4.117232680320739 and parameters: {'num_layers': 6, 'hidden_size': 10, 'batch_size': 130, 'learning_rate': 0.006825582557516806}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 8, epoch: 0,                       train_loss : 4.176945709046864, valid_loss : 3.7025605837504068\n",
      "fold: 9, epoch: 0,                       train_loss : 4.186671711149669, valid_loss : 3.757349729537964\n",
      "fold: 0, epoch: 0,                       train_loss : 5.3150219387478295, valid_loss : 4.488956928253174\n",
      "fold: 0, epoch: 1,                       train_loss : 4.161867472860548, valid_loss : 4.4012696743011475\n",
      "fold: 0, epoch: 2,                       train_loss : 4.102328207757738, valid_loss : 4.396606922149658\n",
      "fold: 0, epoch: 3,                       train_loss : 4.106926626629299, valid_loss : 4.407273054122925\n",
      "fold: 0, epoch: 4,                       train_loss : 4.119183394643995, valid_loss : 4.395328521728516\n",
      "fold: 0, epoch: 5,                       train_loss : 4.106190641721089, valid_loss : 4.409829139709473\n",
      "fold: 0, epoch: 6,                       train_loss : 4.113967140515645, valid_loss : 4.410115718841553\n",
      "fold: 0, epoch: 7,                       train_loss : 4.121552149454753, valid_loss : 4.39777398109436\n",
      "fold: 0, epoch: 8,                       train_loss : 4.103350069787767, valid_loss : 4.4070494174957275\n",
      "fold: 0, epoch: 9,                       train_loss : 4.108778582678901, valid_loss : 4.4001686573028564\n",
      "fold: 0, epoch: 10,                       train_loss : 4.10959533850352, valid_loss : 4.411821603775024\n",
      "fold: 0, epoch: 11,                       train_loss : 4.106093883514404, valid_loss : 4.413087368011475\n",
      "fold: 0, epoch: 12,                       train_loss : 4.103365063667297, valid_loss : 4.4059507846832275\n",
      "fold: 0, epoch: 13,                       train_loss : 4.104746407932705, valid_loss : 4.4185950756073\n",
      "fold: 0, epoch: 14,                       train_loss : 4.117433137363857, valid_loss : 4.401507377624512\n",
      "fold: 1, epoch: 0,                       train_loss : 4.116128298971388, valid_loss : 4.497831583023071\n",
      "fold: 2, epoch: 0,                       train_loss : 4.156095915370518, valid_loss : 4.013400077819824\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1260567506154375, valid_loss : 4.123133540153503\n",
      "fold: 4, epoch: 0,                       train_loss : 4.191007084316677, valid_loss : 3.6439446210861206\n",
      "fold: 5, epoch: 0,                       train_loss : 4.179074194696215, valid_loss : 3.7285760641098022\n",
      "fold: 6, epoch: 0,                       train_loss : 4.10378442870246, valid_loss : 4.464684009552002\n",
      "fold: 7, epoch: 0,                       train_loss : 4.082677761713664, valid_loss : 4.682652711868286\n",
      "fold: 8, epoch: 0,                       train_loss : 4.177518076366848, valid_loss : 3.910983920097351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:11:50,735]\u001b[0m Trial 52 finished with value: 4.1392406821250916 and parameters: {'num_layers': 6, 'hidden_size': 40, 'batch_size': 150, 'learning_rate': 0.013947554113335476}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.176508704821269, valid_loss : 3.931871771812439\n",
      "fold: 0, epoch: 0,                       train_loss : 5.8583179764125655, valid_loss : 5.419216156005859\n",
      "fold: 0, epoch: 1,                       train_loss : 4.620957063591999, valid_loss : 4.324692328770955\n",
      "fold: 0, epoch: 2,                       train_loss : 4.123758637386819, valid_loss : 4.039814551671346\n",
      "fold: 0, epoch: 3,                       train_loss : 4.091738224029541, valid_loss : 4.225803931554158\n",
      "fold: 0, epoch: 4,                       train_loss : 4.087395502173382, valid_loss : 4.0852711995442705\n",
      "fold: 0, epoch: 5,                       train_loss : 4.142879133639128, valid_loss : 4.3169169425964355\n",
      "fold: 0, epoch: 6,                       train_loss : 4.167776398036791, valid_loss : 4.178989092508952\n",
      "fold: 0, epoch: 7,                       train_loss : 4.167283586833788, valid_loss : 4.262747923533122\n",
      "fold: 0, epoch: 8,                       train_loss : 4.168213844299316, valid_loss : 4.399231513341268\n",
      "fold: 0, epoch: 9,                       train_loss : 4.128416133963543, valid_loss : 4.191350142161052\n",
      "fold: 0, epoch: 10,                       train_loss : 4.124390011248381, valid_loss : 4.255219221115112\n",
      "fold: 0, epoch: 11,                       train_loss : 4.101210314294566, valid_loss : 4.151985088984172\n",
      "fold: 0, epoch: 12,                       train_loss : 4.099899457848591, valid_loss : 4.0951034228007\n",
      "fold: 0, epoch: 13,                       train_loss : 4.100549957026606, valid_loss : 4.107497453689575\n",
      "fold: 1, epoch: 0,                       train_loss : 4.197742047517196, valid_loss : 3.9019577503204346\n",
      "fold: 2, epoch: 0,                       train_loss : 4.148879248162975, valid_loss : 3.7513094743092856\n",
      "fold: 3, epoch: 0,                       train_loss : 4.173199570697287, valid_loss : 4.289828459421794\n",
      "fold: 4, epoch: 0,                       train_loss : 4.18318452005801, valid_loss : 4.1088634332021075\n",
      "fold: 5, epoch: 0,                       train_loss : 4.097898472910342, valid_loss : 4.301382303237915\n",
      "fold: 6, epoch: 0,                       train_loss : 4.0820512771606445, valid_loss : 4.2894078095753985\n",
      "fold: 7, epoch: 0,                       train_loss : 4.109019020329351, valid_loss : 4.524145126342773\n",
      "fold: 8, epoch: 0,                       train_loss : 4.103423564330392, valid_loss : 4.4657643636067705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:11:56,760]\u001b[0m Trial 53 finished with value: 4.185862350463867 and parameters: {'num_layers': 6, 'hidden_size': 20, 'batch_size': 120, 'learning_rate': 0.009449356106665604}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.152201559232629, valid_loss : 4.186150232950847\n",
      "fold: 0, epoch: 0,                       train_loss : 5.814877152442932, valid_loss : 5.784980773925781\n",
      "fold: 0, epoch: 1,                       train_loss : 5.064854979515076, valid_loss : 4.617507855097453\n",
      "fold: 0, epoch: 2,                       train_loss : 4.686419606208801, valid_loss : 3.9011425177256265\n",
      "fold: 0, epoch: 3,                       train_loss : 4.017394399642944, valid_loss : 4.10845406850179\n",
      "fold: 0, epoch: 4,                       train_loss : 4.0689866781234745, valid_loss : 3.587524096171061\n",
      "fold: 0, epoch: 5,                       train_loss : 4.16090487241745, valid_loss : 3.963871479034424\n",
      "fold: 0, epoch: 6,                       train_loss : 4.097697734832764, valid_loss : 3.815277179082235\n",
      "fold: 0, epoch: 7,                       train_loss : 4.120139455795288, valid_loss : 4.01283065478007\n",
      "fold: 0, epoch: 8,                       train_loss : 4.030938225984573, valid_loss : 3.7717734972635903\n",
      "fold: 0, epoch: 9,                       train_loss : 4.386141765117645, valid_loss : 3.9346420764923096\n",
      "fold: 0, epoch: 10,                       train_loss : 4.328775560855865, valid_loss : 3.747296174367269\n",
      "fold: 0, epoch: 11,                       train_loss : 4.076924645900727, valid_loss : 3.6925083796183267\n",
      "fold: 0, epoch: 12,                       train_loss : 4.6160874485969545, valid_loss : 3.8062657515207925\n",
      "fold: 0, epoch: 13,                       train_loss : 4.283627569675446, valid_loss : 4.227344671885173\n",
      "fold: 0, epoch: 14,                       train_loss : 4.0508506298065186, valid_loss : 3.4904844760894775\n",
      "fold: 0, epoch: 15,                       train_loss : 4.128827440738678, valid_loss : 4.426421721776326\n",
      "fold: 1, epoch: 0,                       train_loss : 4.279374301433563, valid_loss : 4.137563784917195\n",
      "fold: 2, epoch: 0,                       train_loss : 4.090976524353027, valid_loss : 3.846293290456136\n",
      "fold: 3, epoch: 0,                       train_loss : 4.2439881563186646, valid_loss : 3.6876724561055503\n",
      "fold: 4, epoch: 0,                       train_loss : 4.032212960720062, valid_loss : 3.9536454677581787\n",
      "fold: 5, epoch: 0,                       train_loss : 4.113600182533264, valid_loss : 3.768046776453654\n",
      "fold: 6, epoch: 0,                       train_loss : 4.25206184387207, valid_loss : 3.9053380489349365\n",
      "fold: 7, epoch: 0,                       train_loss : 4.094717609882355, valid_loss : 4.055896520614624\n",
      "fold: 8, epoch: 0,                       train_loss : 4.28700885772705, valid_loss : 3.59157665570577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:12:07,295]\u001b[0m Trial 54 finished with value: 3.9557739019393923 and parameters: {'num_layers': 6, 'hidden_size': 40, 'batch_size': 140, 'learning_rate': 0.006936771149309475}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 3.949311524629593, valid_loss : 5.121221542358398\n",
      "fold: 0, epoch: 0,                       train_loss : 5.754856053520651, valid_loss : 5.259516954421997\n",
      "fold: 0, epoch: 1,                       train_loss : 5.37009084925932, valid_loss : 4.820742845535278\n",
      "fold: 0, epoch: 2,                       train_loss : 4.567064804189346, valid_loss : 3.9361788034439087\n",
      "fold: 0, epoch: 3,                       train_loss : 4.199149580562816, valid_loss : 3.9177701473236084\n",
      "fold: 0, epoch: 4,                       train_loss : 4.165984322043026, valid_loss : 3.962718367576599\n",
      "fold: 0, epoch: 5,                       train_loss : 4.138620011946735, valid_loss : 3.949899435043335\n",
      "fold: 0, epoch: 6,                       train_loss : 4.143337796716129, valid_loss : 3.957181453704834\n",
      "fold: 0, epoch: 7,                       train_loss : 4.162461140576531, valid_loss : 3.980826258659363\n",
      "fold: 0, epoch: 8,                       train_loss : 4.192965942270615, valid_loss : 3.999429941177368\n",
      "fold: 0, epoch: 9,                       train_loss : 4.1363504634184, valid_loss : 3.955919623374939\n",
      "fold: 0, epoch: 10,                       train_loss : 4.147206643048455, valid_loss : 3.974114179611206\n",
      "fold: 0, epoch: 11,                       train_loss : 4.143831140854779, valid_loss : 3.9378771781921387\n",
      "fold: 0, epoch: 12,                       train_loss : 4.145935759824865, valid_loss : 3.959496855735779\n",
      "fold: 0, epoch: 13,                       train_loss : 4.157570193795597, valid_loss : 3.976457953453064\n",
      "fold: 0, epoch: 14,                       train_loss : 4.1413146187277405, valid_loss : 3.9455909729003906\n",
      "fold: 1, epoch: 0,                       train_loss : 4.130724906921387, valid_loss : 4.142685651779175\n",
      "fold: 2, epoch: 0,                       train_loss : 4.156720932792215, valid_loss : 4.207956671714783\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1272292137146, valid_loss : 4.401955604553223\n",
      "fold: 4, epoch: 0,                       train_loss : 4.093962024239933, valid_loss : 4.594841003417969\n",
      "fold: 5, epoch: 0,                       train_loss : 4.183230470208561, valid_loss : 3.7167614698410034\n",
      "fold: 6, epoch: 0,                       train_loss : 4.131137651555679, valid_loss : 4.149901509284973\n",
      "fold: 7, epoch: 0,                       train_loss : 4.1801902967340805, valid_loss : 3.861284613609314\n",
      "fold: 8, epoch: 0,                       train_loss : 4.128532002953922, valid_loss : 4.083815217018127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:12:14,017]\u001b[0m Trial 55 finished with value: 4.143204176425934 and parameters: {'num_layers': 5, 'hidden_size': 30, 'batch_size': 160, 'learning_rate': 0.006305481107063624}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1061287487254425, valid_loss : 4.355069875717163\n",
      "fold: 0, epoch: 0,                       train_loss : 6.121070551872253, valid_loss : 5.278691212336223\n",
      "fold: 0, epoch: 1,                       train_loss : 6.080381226539612, valid_loss : 5.198804060618083\n",
      "fold: 0, epoch: 2,                       train_loss : 5.658076810836792, valid_loss : 4.744314511617024\n",
      "fold: 0, epoch: 3,                       train_loss : 5.366734051704407, valid_loss : 4.2134190400441485\n",
      "fold: 0, epoch: 4,                       train_loss : 4.687904214859008, valid_loss : 4.411136627197266\n",
      "fold: 0, epoch: 5,                       train_loss : 4.136106121540069, valid_loss : 3.9757814407348633\n",
      "fold: 0, epoch: 6,                       train_loss : 3.9968334913253782, valid_loss : 4.220372915267944\n",
      "fold: 0, epoch: 7,                       train_loss : 4.067283809185028, valid_loss : 3.550568421681722\n",
      "fold: 0, epoch: 8,                       train_loss : 4.144915270805359, valid_loss : 4.315133174260457\n",
      "fold: 0, epoch: 9,                       train_loss : 4.160718607902527, valid_loss : 3.3040624459584556\n",
      "fold: 0, epoch: 10,                       train_loss : 4.269442534446716, valid_loss : 3.679480234781901\n",
      "fold: 0, epoch: 11,                       train_loss : 4.0635249495506285, valid_loss : 3.7256698608398438\n",
      "fold: 0, epoch: 12,                       train_loss : 4.228412020206451, valid_loss : 3.6457738081614175\n",
      "fold: 0, epoch: 13,                       train_loss : 4.045188057422638, valid_loss : 4.5104663372039795\n",
      "fold: 0, epoch: 14,                       train_loss : 4.057151353359222, valid_loss : 5.006787300109863\n",
      "fold: 0, epoch: 15,                       train_loss : 4.083687734603882, valid_loss : 3.8370107809702554\n",
      "fold: 0, epoch: 16,                       train_loss : 4.491477382183075, valid_loss : 3.5706450939178467\n",
      "fold: 0, epoch: 17,                       train_loss : 4.340809631347656, valid_loss : 3.813781976699829\n",
      "fold: 1, epoch: 0,                       train_loss : 4.142440986633301, valid_loss : 4.6536485354105634\n",
      "fold: 2, epoch: 0,                       train_loss : 4.042987716197968, valid_loss : 3.621448596318563\n",
      "fold: 3, epoch: 0,                       train_loss : 4.068042063713074, valid_loss : 3.777310053507487\n",
      "fold: 4, epoch: 0,                       train_loss : 4.167486262321472, valid_loss : 3.71941868464152\n",
      "fold: 5, epoch: 0,                       train_loss : 4.056617134809494, valid_loss : 4.139290014902751\n",
      "fold: 6, epoch: 0,                       train_loss : 4.225455117225647, valid_loss : 4.429824670155843\n",
      "fold: 7, epoch: 0,                       train_loss : 4.009569656848908, valid_loss : 3.560002168019613\n",
      "fold: 8, epoch: 0,                       train_loss : 4.079259610176086, valid_loss : 3.8185298442840576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:12:33,212]\u001b[0m Trial 56 finished with value: 3.886004400253296 and parameters: {'num_layers': 6, 'hidden_size': 90, 'batch_size': 140, 'learning_rate': 0.002425624812413071}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 3.9846743136644363, valid_loss : 3.8365089893341064\n",
      "fold: 0, epoch: 0,                       train_loss : 6.131242847442627, valid_loss : 5.464860757191976\n",
      "fold: 0, epoch: 1,                       train_loss : 6.138660621643067, valid_loss : 5.558271567026774\n",
      "fold: 0, epoch: 2,                       train_loss : 5.6733660221099855, valid_loss : 5.747478485107422\n",
      "fold: 0, epoch: 3,                       train_loss : 5.476215410232544, valid_loss : 5.129800955454509\n",
      "fold: 0, epoch: 4,                       train_loss : 5.347974443435669, valid_loss : 4.648184935251872\n",
      "fold: 0, epoch: 5,                       train_loss : 4.821409845352173, valid_loss : 4.142934004465739\n",
      "fold: 0, epoch: 6,                       train_loss : 4.091577243804932, valid_loss : 3.917637268702189\n",
      "fold: 0, epoch: 7,                       train_loss : 4.199386179447174, valid_loss : 3.8579318523406982\n",
      "fold: 0, epoch: 8,                       train_loss : 4.024926090240479, valid_loss : 3.843212922414144\n",
      "fold: 0, epoch: 9,                       train_loss : 4.530102920532227, valid_loss : 3.69850492477417\n",
      "fold: 0, epoch: 10,                       train_loss : 4.081211173534394, valid_loss : 3.4342593351999917\n",
      "fold: 0, epoch: 11,                       train_loss : 4.249142789840699, valid_loss : 4.4044069449106855\n",
      "fold: 0, epoch: 12,                       train_loss : 4.118291759490967, valid_loss : 4.324962298075358\n",
      "fold: 0, epoch: 13,                       train_loss : 4.233698058128357, valid_loss : 4.272815863291423\n",
      "fold: 0, epoch: 14,                       train_loss : 4.091389465332031, valid_loss : 3.266409476598104\n",
      "fold: 0, epoch: 15,                       train_loss : 4.489558613300323, valid_loss : 4.270414352416992\n",
      "fold: 0, epoch: 16,                       train_loss : 4.024050188064575, valid_loss : 3.4639387130737305\n",
      "fold: 0, epoch: 17,                       train_loss : 4.179585063457489, valid_loss : 3.806892156600952\n",
      "fold: 0, epoch: 18,                       train_loss : 4.066916060447693, valid_loss : 3.7799628575642905\n",
      "fold: 0, epoch: 19,                       train_loss : 4.047316825389862, valid_loss : 4.224302371342977\n",
      "fold: 0, epoch: 20,                       train_loss : 4.197004985809326, valid_loss : 3.651549736658732\n",
      "fold: 1, epoch: 0,                       train_loss : 4.0161790490150455, valid_loss : 4.444555759429932\n",
      "fold: 2, epoch: 0,                       train_loss : 4.2057912945747375, valid_loss : 4.3585911591847735\n",
      "fold: 3, epoch: 0,                       train_loss : 3.9627057671546937, valid_loss : 4.795827706654866\n",
      "fold: 4, epoch: 0,                       train_loss : 4.061677777767182, valid_loss : 4.439625104268392\n",
      "fold: 5, epoch: 0,                       train_loss : 4.263451671600341, valid_loss : 3.7188007831573486\n",
      "fold: 6, epoch: 0,                       train_loss : 4.369380056858063, valid_loss : 4.48937185605367\n",
      "fold: 7, epoch: 0,                       train_loss : 3.9991410434246064, valid_loss : 3.8550347487131753\n",
      "fold: 8, epoch: 0,                       train_loss : 4.144096708297729, valid_loss : 4.4551239013671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:12:54,483]\u001b[0m Trial 57 finished with value: 4.177759909629821 and parameters: {'num_layers': 5, 'hidden_size': 90, 'batch_size': 140, 'learning_rate': 0.0026853869358005127}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.111497962474823, valid_loss : 3.954258600870768\n",
      "fold: 0, epoch: 0,                       train_loss : 6.3155599784851075, valid_loss : 5.7128729820251465\n",
      "fold: 0, epoch: 1,                       train_loss : 6.151892814636231, valid_loss : 5.505355358123779\n",
      "fold: 0, epoch: 2,                       train_loss : 6.1026978683471675, valid_loss : 5.459193388621013\n",
      "fold: 0, epoch: 3,                       train_loss : 6.029998893737793, valid_loss : 5.274247805277507\n",
      "fold: 0, epoch: 4,                       train_loss : 5.769626064300537, valid_loss : 5.1447601318359375\n",
      "fold: 0, epoch: 5,                       train_loss : 5.569426727294922, valid_loss : 4.956890106201172\n",
      "fold: 0, epoch: 6,                       train_loss : 5.3402527236938475, valid_loss : 4.5172225634257\n",
      "fold: 0, epoch: 7,                       train_loss : 4.895178661346436, valid_loss : 4.161935965220134\n",
      "fold: 0, epoch: 8,                       train_loss : 4.561954040527343, valid_loss : 3.919374704360962\n",
      "fold: 0, epoch: 9,                       train_loss : 4.344998540878296, valid_loss : 3.806021531422933\n",
      "fold: 0, epoch: 10,                       train_loss : 4.226955375671387, valid_loss : 3.6953349908192954\n",
      "fold: 0, epoch: 11,                       train_loss : 4.238881187438965, valid_loss : 3.666657288869222\n",
      "fold: 0, epoch: 12,                       train_loss : 4.147628202438354, valid_loss : 3.7428935368855796\n",
      "fold: 0, epoch: 13,                       train_loss : 4.172057590484619, valid_loss : 3.7348288695017495\n",
      "fold: 0, epoch: 14,                       train_loss : 4.161390800476074, valid_loss : 3.7939182122548423\n",
      "fold: 0, epoch: 15,                       train_loss : 4.231615180969238, valid_loss : 3.773399909337362\n",
      "fold: 0, epoch: 16,                       train_loss : 4.176256589889526, valid_loss : 3.713507095972697\n",
      "fold: 0, epoch: 17,                       train_loss : 4.161615705490112, valid_loss : 3.6257429917653403\n",
      "fold: 0, epoch: 18,                       train_loss : 4.147230234146118, valid_loss : 3.725386381149292\n",
      "fold: 0, epoch: 19,                       train_loss : 4.15143590927124, valid_loss : 3.6597955226898193\n",
      "fold: 0, epoch: 20,                       train_loss : 4.184084806442261, valid_loss : 3.626535256703695\n",
      "fold: 0, epoch: 21,                       train_loss : 4.147404870986938, valid_loss : 3.7186456521352134\n",
      "fold: 0, epoch: 22,                       train_loss : 4.193403530120849, valid_loss : 3.647652546564738\n",
      "fold: 0, epoch: 23,                       train_loss : 4.162857513427735, valid_loss : 3.6171185970306396\n",
      "fold: 0, epoch: 24,                       train_loss : 4.2318915843963625, valid_loss : 3.6593779722849527\n",
      "fold: 1, epoch: 0,                       train_loss : 4.063964300155639, valid_loss : 4.236688057581584\n",
      "fold: 2, epoch: 0,                       train_loss : 4.031624813079834, valid_loss : 4.40101687113444\n",
      "fold: 3, epoch: 0,                       train_loss : 4.127414894104004, valid_loss : 3.999781290690104\n",
      "fold: 4, epoch: 0,                       train_loss : 4.086994190216064, valid_loss : 4.348050753275554\n",
      "fold: 5, epoch: 0,                       train_loss : 4.1037328338623045, valid_loss : 4.012955745061238\n",
      "fold: 6, epoch: 0,                       train_loss : 4.147777585983277, valid_loss : 4.149269342422485\n",
      "fold: 7, epoch: 0,                       train_loss : 4.191486263275147, valid_loss : 3.8821003437042236\n",
      "fold: 8, epoch: 0,                       train_loss : 4.108619194030762, valid_loss : 3.9691555500030518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:13:29,554]\u001b[0m Trial 58 finished with value: 4.070694200197855 and parameters: {'num_layers': 6, 'hidden_size': 110, 'batch_size': 110, 'learning_rate': 0.0011078555503958624}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.109637498855591, valid_loss : 4.090805451075236\n",
      "fold: 0, epoch: 0,                       train_loss : 6.013592746522692, valid_loss : 6.2970969676971436\n",
      "fold: 0, epoch: 1,                       train_loss : 5.841173039542304, valid_loss : 6.156381607055664\n",
      "fold: 0, epoch: 2,                       train_loss : 5.7224264939626055, valid_loss : 6.022151231765747\n",
      "fold: 0, epoch: 3,                       train_loss : 5.565398613611857, valid_loss : 5.83558464050293\n",
      "fold: 0, epoch: 4,                       train_loss : 5.383239216274685, valid_loss : 5.61135196685791\n",
      "fold: 0, epoch: 5,                       train_loss : 5.1331413586934405, valid_loss : 5.276094675064087\n",
      "fold: 0, epoch: 6,                       train_loss : 4.7737787697050305, valid_loss : 4.856113433837891\n",
      "fold: 0, epoch: 7,                       train_loss : 4.377030372619629, valid_loss : 4.342965602874756\n",
      "fold: 0, epoch: 8,                       train_loss : 4.15366776784261, valid_loss : 4.141106128692627\n",
      "fold: 0, epoch: 9,                       train_loss : 4.140341109699673, valid_loss : 4.136503458023071\n",
      "fold: 0, epoch: 10,                       train_loss : 4.138114386134678, valid_loss : 4.1454503536224365\n",
      "fold: 0, epoch: 11,                       train_loss : 4.140481803152296, valid_loss : 4.144985318183899\n",
      "fold: 0, epoch: 12,                       train_loss : 4.133736040857103, valid_loss : 4.146534204483032\n",
      "fold: 0, epoch: 13,                       train_loss : 4.130359027120802, valid_loss : 4.148162603378296\n",
      "fold: 0, epoch: 14,                       train_loss : 4.133393062485589, valid_loss : 4.148924827575684\n",
      "fold: 0, epoch: 15,                       train_loss : 4.131306025716993, valid_loss : 4.1547088623046875\n",
      "fold: 0, epoch: 16,                       train_loss : 4.13292400042216, valid_loss : 4.152166485786438\n",
      "fold: 0, epoch: 17,                       train_loss : 4.144580019844903, valid_loss : 4.155096650123596\n",
      "fold: 0, epoch: 18,                       train_loss : 4.1237311363220215, valid_loss : 4.152588248252869\n",
      "fold: 0, epoch: 19,                       train_loss : 4.136130743556553, valid_loss : 4.159348845481873\n",
      "fold: 0, epoch: 20,                       train_loss : 4.13943170176612, valid_loss : 4.148962020874023\n",
      "fold: 1, epoch: 0,                       train_loss : 4.135194089677599, valid_loss : 4.188197612762451\n",
      "fold: 2, epoch: 0,                       train_loss : 4.13690169652303, valid_loss : 4.07235062122345\n",
      "fold: 3, epoch: 0,                       train_loss : 4.129619929525587, valid_loss : 4.1779868602752686\n",
      "fold: 4, epoch: 0,                       train_loss : 4.090555482440525, valid_loss : 4.569606304168701\n",
      "fold: 5, epoch: 0,                       train_loss : 4.090611126687792, valid_loss : 4.523550510406494\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1825885905159845, valid_loss : 3.659769654273987\n",
      "fold: 7, epoch: 0,                       train_loss : 4.164842989709642, valid_loss : 3.8132705688476562\n",
      "fold: 8, epoch: 0,                       train_loss : 4.13236145178477, valid_loss : 4.166932225227356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:13:50,484]\u001b[0m Trial 59 finished with value: 4.134909570217133 and parameters: {'num_layers': 4, 'hidden_size': 100, 'batch_size': 150, 'learning_rate': 0.0020857271691561373}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.142771270540026, valid_loss : 4.040927886962891\n",
      "fold: 0, epoch: 0,                       train_loss : 6.463742574055989, valid_loss : 5.981424570083618\n",
      "fold: 0, epoch: 1,                       train_loss : 6.3785913467407225, valid_loss : 5.7837605476379395\n",
      "fold: 0, epoch: 2,                       train_loss : 6.304910691579183, valid_loss : 5.722201347351074\n",
      "fold: 0, epoch: 3,                       train_loss : 6.1618322690327965, valid_loss : 5.4202964305877686\n",
      "fold: 0, epoch: 4,                       train_loss : 5.457618379592896, valid_loss : 4.263593912124634\n",
      "fold: 0, epoch: 5,                       train_loss : 4.295416959126791, valid_loss : 3.9006922245025635\n",
      "fold: 0, epoch: 6,                       train_loss : 4.200199524561564, valid_loss : 3.9262694120407104\n",
      "fold: 0, epoch: 7,                       train_loss : 4.162698745727539, valid_loss : 3.8198044300079346\n",
      "fold: 0, epoch: 8,                       train_loss : 4.167836777369181, valid_loss : 3.8160808086395264\n",
      "fold: 0, epoch: 9,                       train_loss : 4.160887861251831, valid_loss : 3.8327090740203857\n",
      "fold: 0, epoch: 10,                       train_loss : 4.168943707148234, valid_loss : 3.9245840311050415\n",
      "fold: 0, epoch: 11,                       train_loss : 4.157679049173991, valid_loss : 3.829445719718933\n",
      "fold: 0, epoch: 12,                       train_loss : 4.159162187576294, valid_loss : 3.8541886806488037\n",
      "fold: 0, epoch: 13,                       train_loss : 4.171396271387736, valid_loss : 3.882526159286499\n",
      "fold: 0, epoch: 14,                       train_loss : 4.180042314529419, valid_loss : 3.8554744720458984\n",
      "fold: 0, epoch: 15,                       train_loss : 4.167799154917399, valid_loss : 3.8802374601364136\n",
      "fold: 0, epoch: 16,                       train_loss : 4.16897759437561, valid_loss : 3.856900930404663\n",
      "fold: 0, epoch: 17,                       train_loss : 4.16015396118164, valid_loss : 3.8306291103363037\n",
      "fold: 0, epoch: 18,                       train_loss : 4.173561716079712, valid_loss : 3.9138282537460327\n",
      "fold: 1, epoch: 0,                       train_loss : 4.134272448221842, valid_loss : 4.06070351600647\n",
      "fold: 2, epoch: 0,                       train_loss : 4.160281403859456, valid_loss : 3.83265483379364\n",
      "fold: 3, epoch: 0,                       train_loss : 4.149910672505697, valid_loss : 4.0290000438690186\n",
      "fold: 4, epoch: 0,                       train_loss : 4.17481951713562, valid_loss : 3.787839651107788\n",
      "fold: 5, epoch: 0,                       train_loss : 4.135790506998698, valid_loss : 4.095054030418396\n",
      "fold: 6, epoch: 0,                       train_loss : 4.144923448562622, valid_loss : 4.06580913066864\n",
      "fold: 7, epoch: 0,                       train_loss : 4.142521556218465, valid_loss : 4.106228351593018\n",
      "fold: 8, epoch: 0,                       train_loss : 4.000114568074545, valid_loss : 5.349504709243774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:14:05,119]\u001b[0m Trial 60 finished with value: 4.1199583292007445 and parameters: {'num_layers': 6, 'hidden_size': 80, 'batch_size': 180, 'learning_rate': 0.0037294570360003796}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.148815504709879, valid_loss : 4.056708216667175\n",
      "fold: 0, epoch: 0,                       train_loss : 5.370472121238708, valid_loss : 4.35880184173584\n",
      "fold: 0, epoch: 1,                       train_loss : 4.584346961975098, valid_loss : 4.0368969440460205\n",
      "fold: 0, epoch: 2,                       train_loss : 4.627665030956268, valid_loss : 5.28608767191569\n",
      "fold: 0, epoch: 3,                       train_loss : 4.484843635559082, valid_loss : 4.671842257181804\n",
      "fold: 0, epoch: 4,                       train_loss : 4.062127101421356, valid_loss : 4.477990468343099\n",
      "fold: 0, epoch: 5,                       train_loss : 4.214852809906006, valid_loss : 3.8328173955281577\n",
      "fold: 0, epoch: 6,                       train_loss : 4.0674967765808105, valid_loss : 4.742854356765747\n",
      "fold: 0, epoch: 7,                       train_loss : 4.00623105764389, valid_loss : 4.469365517298381\n",
      "fold: 0, epoch: 8,                       train_loss : 4.461667692661285, valid_loss : 3.9900554021199546\n",
      "fold: 0, epoch: 9,                       train_loss : 4.011913812160492, valid_loss : 4.658460299173991\n",
      "fold: 0, epoch: 10,                       train_loss : 4.006866216659546, valid_loss : 4.11796768506368\n",
      "fold: 0, epoch: 11,                       train_loss : 4.177661776542664, valid_loss : 3.9266421794891357\n",
      "fold: 0, epoch: 12,                       train_loss : 4.362709474563599, valid_loss : 3.784335454305013\n",
      "fold: 0, epoch: 13,                       train_loss : 4.026106512546539, valid_loss : 3.889252503712972\n",
      "fold: 0, epoch: 14,                       train_loss : 4.017878216505051, valid_loss : 5.157124121983846\n",
      "fold: 1, epoch: 0,                       train_loss : 4.253359174728393, valid_loss : 4.441563685735066\n",
      "fold: 2, epoch: 0,                       train_loss : 4.470717239379883, valid_loss : 4.237939675649007\n",
      "fold: 3, epoch: 0,                       train_loss : 4.071939706802368, valid_loss : 4.0070390701293945\n",
      "fold: 4, epoch: 0,                       train_loss : 3.9554464340209963, valid_loss : 3.7624743779500327\n",
      "fold: 5, epoch: 0,                       train_loss : 4.088567066192627, valid_loss : 3.743894656499227\n",
      "fold: 6, epoch: 0,                       train_loss : 4.146673917770386, valid_loss : 4.372693141301473\n",
      "fold: 7, epoch: 0,                       train_loss : 4.144039762020111, valid_loss : 4.109018723169963\n",
      "fold: 8, epoch: 0,                       train_loss : 4.136308896541595, valid_loss : 3.7680474122365317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:14:17,977]\u001b[0m Trial 61 finished with value: 3.9690690676371263 and parameters: {'num_layers': 6, 'hidden_size': 60, 'batch_size': 140, 'learning_rate': 0.004740427261389268}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.161257183551788, valid_loss : 3.4636844793955484\n",
      "fold: 0, epoch: 0,                       train_loss : 6.606139779090881, valid_loss : 6.374806086222331\n",
      "fold: 0, epoch: 1,                       train_loss : 6.361066889762879, valid_loss : 6.065089384714763\n",
      "fold: 0, epoch: 2,                       train_loss : 6.383749079704285, valid_loss : 5.4657816886901855\n",
      "fold: 0, epoch: 3,                       train_loss : 6.271610355377197, valid_loss : 5.849557717641194\n",
      "fold: 0, epoch: 4,                       train_loss : 5.994717335700988, valid_loss : 5.695144494374593\n",
      "fold: 0, epoch: 5,                       train_loss : 5.84337089061737, valid_loss : 5.891867160797119\n",
      "fold: 0, epoch: 6,                       train_loss : 5.695936179161071, valid_loss : 4.661773840586345\n",
      "fold: 0, epoch: 7,                       train_loss : 5.8614500761032104, valid_loss : 4.644635438919067\n",
      "fold: 0, epoch: 8,                       train_loss : 4.98997973203659, valid_loss : 3.5058768590291343\n",
      "fold: 0, epoch: 9,                       train_loss : 4.049681794643402, valid_loss : 3.6183694998423257\n",
      "fold: 0, epoch: 10,                       train_loss : 4.147887289524078, valid_loss : 3.491891622543335\n",
      "fold: 0, epoch: 11,                       train_loss : 4.077656722068786, valid_loss : 4.423406521479289\n",
      "fold: 0, epoch: 12,                       train_loss : 4.068179559707642, valid_loss : 3.3170947233835855\n",
      "fold: 0, epoch: 13,                       train_loss : 4.208489918708802, valid_loss : 3.94927978515625\n",
      "fold: 0, epoch: 14,                       train_loss : 4.077929902076721, valid_loss : 3.499115467071533\n",
      "fold: 0, epoch: 15,                       train_loss : 4.107860708236695, valid_loss : 4.06543231010437\n",
      "fold: 0, epoch: 16,                       train_loss : 4.033156710863113, valid_loss : 3.886465867360433\n",
      "fold: 0, epoch: 17,                       train_loss : 4.074226880073548, valid_loss : 4.550486882527669\n",
      "fold: 0, epoch: 18,                       train_loss : 4.056956315040589, valid_loss : 4.078464190165202\n",
      "fold: 1, epoch: 0,                       train_loss : 4.062499868869781, valid_loss : 3.94676407178243\n",
      "fold: 2, epoch: 0,                       train_loss : 4.313179516792298, valid_loss : 4.585775216420491\n",
      "fold: 3, epoch: 0,                       train_loss : 4.047733664512634, valid_loss : 3.0965072313944497\n",
      "fold: 4, epoch: 0,                       train_loss : 4.062036919593811, valid_loss : 3.96358855565389\n",
      "fold: 5, epoch: 0,                       train_loss : 4.1262531042098995, valid_loss : 4.965152263641357\n",
      "fold: 6, epoch: 0,                       train_loss : 3.995330685377121, valid_loss : 4.292193651199341\n",
      "fold: 7, epoch: 0,                       train_loss : 4.045060002803803, valid_loss : 4.136351267496745\n",
      "fold: 8, epoch: 0,                       train_loss : 4.052334845066071, valid_loss : 4.944238980611165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:14:32,718]\u001b[0m Trial 62 finished with value: 4.10605464776357 and parameters: {'num_layers': 6, 'hidden_size': 60, 'batch_size': 140, 'learning_rate': 0.004589244975366484}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.312808990478516, valid_loss : 3.812880516052246\n",
      "fold: 0, epoch: 0,                       train_loss : 5.988736046685113, valid_loss : 6.046765565872192\n",
      "fold: 0, epoch: 1,                       train_loss : 5.787128024631077, valid_loss : 5.8753509521484375\n",
      "fold: 0, epoch: 2,                       train_loss : 5.571530236138238, valid_loss : 5.569560766220093\n",
      "fold: 0, epoch: 3,                       train_loss : 5.121852583355373, valid_loss : 4.882300853729248\n",
      "fold: 0, epoch: 4,                       train_loss : 4.290113859706455, valid_loss : 4.359134912490845\n",
      "fold: 0, epoch: 5,                       train_loss : 4.125759813520643, valid_loss : 4.323458194732666\n",
      "fold: 0, epoch: 6,                       train_loss : 4.117544889450073, valid_loss : 4.335323810577393\n",
      "fold: 0, epoch: 7,                       train_loss : 4.109208994441563, valid_loss : 4.337332487106323\n",
      "fold: 0, epoch: 8,                       train_loss : 4.105578846401638, valid_loss : 4.333964109420776\n",
      "fold: 0, epoch: 9,                       train_loss : 4.1106190416547985, valid_loss : 4.338000774383545\n",
      "fold: 0, epoch: 10,                       train_loss : 4.1290899647606745, valid_loss : 4.328389763832092\n",
      "fold: 0, epoch: 11,                       train_loss : 4.1130326588948565, valid_loss : 4.329390287399292\n",
      "fold: 0, epoch: 12,                       train_loss : 4.112448069784376, valid_loss : 4.330979347229004\n",
      "fold: 0, epoch: 13,                       train_loss : 4.112582445144653, valid_loss : 4.336853504180908\n",
      "fold: 0, epoch: 14,                       train_loss : 4.106205516391331, valid_loss : 4.325176239013672\n",
      "fold: 0, epoch: 15,                       train_loss : 4.118499411476983, valid_loss : 4.331472158432007\n",
      "fold: 0, epoch: 16,                       train_loss : 4.109199431207445, valid_loss : 4.335096597671509\n",
      "fold: 1, epoch: 0,                       train_loss : 4.2112482521269055, valid_loss : 3.659501314163208\n",
      "fold: 2, epoch: 0,                       train_loss : 4.202100820011562, valid_loss : 3.5851718187332153\n",
      "fold: 3, epoch: 0,                       train_loss : 4.146484812100728, valid_loss : 3.9656771421432495\n",
      "fold: 4, epoch: 0,                       train_loss : 4.126658744282192, valid_loss : 4.31950044631958\n",
      "fold: 5, epoch: 0,                       train_loss : 4.1260640223821, valid_loss : 4.263963937759399\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1538412306043835, valid_loss : 3.9030312299728394\n",
      "fold: 7, epoch: 0,                       train_loss : 4.127876824802822, valid_loss : 4.271108150482178\n",
      "fold: 8, epoch: 0,                       train_loss : 4.098613818486531, valid_loss : 4.653133392333984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:14:48,987]\u001b[0m Trial 63 finished with value: 4.1356027007102965 and parameters: {'num_layers': 6, 'hidden_size': 90, 'batch_size': 150, 'learning_rate': 0.0029428919021320925}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.097071131070455, valid_loss : 4.4114813804626465\n",
      "fold: 0, epoch: 0,                       train_loss : 6.491947310311454, valid_loss : 5.598615487416585\n",
      "fold: 0, epoch: 1,                       train_loss : 6.318776448567708, valid_loss : 5.412228902180989\n",
      "fold: 0, epoch: 2,                       train_loss : 6.127107733771915, valid_loss : 5.27740494410197\n",
      "fold: 0, epoch: 3,                       train_loss : 5.802692663101923, valid_loss : 4.627230405807495\n",
      "fold: 0, epoch: 4,                       train_loss : 5.373438698904855, valid_loss : 4.478774388631185\n",
      "fold: 0, epoch: 5,                       train_loss : 4.881300812675839, valid_loss : 3.553164482116699\n",
      "fold: 0, epoch: 6,                       train_loss : 4.404982487360637, valid_loss : 3.3711767196655273\n",
      "fold: 0, epoch: 7,                       train_loss : 4.203425203050886, valid_loss : 3.325591484705607\n",
      "fold: 0, epoch: 8,                       train_loss : 4.211897316433134, valid_loss : 3.528583606084188\n",
      "fold: 0, epoch: 9,                       train_loss : 4.224589926855905, valid_loss : 3.5634330113728843\n",
      "fold: 0, epoch: 10,                       train_loss : 4.218538863318307, valid_loss : 3.366174300511678\n",
      "fold: 0, epoch: 11,                       train_loss : 4.213431119918823, valid_loss : 3.3606980641682944\n",
      "fold: 0, epoch: 12,                       train_loss : 4.188693546113514, valid_loss : 3.341031551361084\n",
      "fold: 0, epoch: 13,                       train_loss : 4.18536224819365, valid_loss : 3.5930135250091553\n",
      "fold: 0, epoch: 14,                       train_loss : 4.190459932599749, valid_loss : 3.5997130076090493\n",
      "fold: 0, epoch: 15,                       train_loss : 4.174789122172764, valid_loss : 3.3539768854777017\n",
      "fold: 0, epoch: 16,                       train_loss : 4.2046299661908835, valid_loss : 3.331742286682129\n",
      "fold: 0, epoch: 17,                       train_loss : 4.216314474741618, valid_loss : 3.6339100201924643\n",
      "fold: 0, epoch: 18,                       train_loss : 4.195124013083322, valid_loss : 3.2996092637379966\n",
      "fold: 0, epoch: 19,                       train_loss : 4.201911869503203, valid_loss : 3.4471359252929688\n",
      "fold: 1, epoch: 0,                       train_loss : 4.123985438119798, valid_loss : 4.766366958618164\n",
      "fold: 2, epoch: 0,                       train_loss : 4.113551503136044, valid_loss : 3.978125810623169\n",
      "fold: 3, epoch: 0,                       train_loss : 4.133791230973744, valid_loss : 3.691946585973104\n",
      "fold: 4, epoch: 0,                       train_loss : 4.154823484874907, valid_loss : 3.7198646068573\n",
      "fold: 5, epoch: 0,                       train_loss : 4.115531853267124, valid_loss : 4.193188349405925\n",
      "fold: 6, epoch: 0,                       train_loss : 4.119729484830584, valid_loss : 4.172628005345662\n",
      "fold: 7, epoch: 0,                       train_loss : 4.195298501423427, valid_loss : 3.377180576324463\n",
      "fold: 8, epoch: 0,                       train_loss : 4.015519993645804, valid_loss : 5.719127019246419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:15:07,090]\u001b[0m Trial 64 finished with value: 4.080906097094218 and parameters: {'num_layers': 5, 'hidden_size': 70, 'batch_size': 130, 'learning_rate': 0.0017231557991683097}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.105693839845204, valid_loss : 3.891023794809977\n",
      "fold: 0, epoch: 0,                       train_loss : 5.779917885275448, valid_loss : 5.701426982879639\n",
      "fold: 0, epoch: 1,                       train_loss : 5.728381213019876, valid_loss : 5.517238616943359\n",
      "fold: 0, epoch: 2,                       train_loss : 5.6612058246836945, valid_loss : 5.459720134735107\n",
      "fold: 0, epoch: 3,                       train_loss : 5.55498883303474, valid_loss : 5.425065994262695\n",
      "fold: 0, epoch: 4,                       train_loss : 5.474411683924058, valid_loss : 5.338908672332764\n",
      "fold: 0, epoch: 5,                       train_loss : 5.387633940752814, valid_loss : 5.26964807510376\n",
      "fold: 0, epoch: 6,                       train_loss : 5.254120742573457, valid_loss : 5.1237053871154785\n",
      "fold: 0, epoch: 7,                       train_loss : 5.103019980823293, valid_loss : 4.889920234680176\n",
      "fold: 0, epoch: 8,                       train_loss : 4.915941532920389, valid_loss : 4.657102823257446\n",
      "fold: 0, epoch: 9,                       train_loss : 4.647917481029735, valid_loss : 4.318110108375549\n",
      "fold: 0, epoch: 10,                       train_loss : 4.355145566603717, valid_loss : 3.8783063888549805\n",
      "fold: 0, epoch: 11,                       train_loss : 4.1750423627741196, valid_loss : 3.868948459625244\n",
      "fold: 0, epoch: 12,                       train_loss : 4.165192043080049, valid_loss : 3.8488067388534546\n",
      "fold: 0, epoch: 13,                       train_loss : 4.165747923009536, valid_loss : 3.8618547916412354\n",
      "fold: 0, epoch: 14,                       train_loss : 4.166622203939101, valid_loss : 3.8220051527023315\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1816425183240105, valid_loss : 3.8281625509262085\n",
      "fold: 0, epoch: 16,                       train_loss : 4.166397880105412, valid_loss : 3.8488807678222656\n",
      "fold: 0, epoch: 17,                       train_loss : 4.158123647465425, valid_loss : 3.8451695442199707\n",
      "fold: 0, epoch: 18,                       train_loss : 4.15993595123291, valid_loss : 3.832489252090454\n",
      "fold: 0, epoch: 19,                       train_loss : 4.186478109920726, valid_loss : 3.840267300605774\n",
      "fold: 0, epoch: 20,                       train_loss : 4.168807562659769, valid_loss : 3.826034903526306\n",
      "fold: 0, epoch: 21,                       train_loss : 4.152974787880392, valid_loss : 3.8312058448791504\n",
      "fold: 0, epoch: 22,                       train_loss : 4.1557375122519105, valid_loss : 3.8177850246429443\n",
      "fold: 0, epoch: 23,                       train_loss : 4.185294445823221, valid_loss : 3.8512282371520996\n",
      "fold: 0, epoch: 24,                       train_loss : 4.179613800609813, valid_loss : 3.8287817239761353\n",
      "fold: 0, epoch: 25,                       train_loss : 4.1632320319905, valid_loss : 3.830168843269348\n",
      "fold: 1, epoch: 0,                       train_loss : 4.151260109508739, valid_loss : 4.304274559020996\n",
      "fold: 2, epoch: 0,                       train_loss : 4.108090050080243, valid_loss : 4.3138086795806885\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1750854604384475, valid_loss : 3.6606298685073853\n",
      "fold: 4, epoch: 0,                       train_loss : 4.175116272533641, valid_loss : 3.6903488636016846\n",
      "fold: 5, epoch: 0,                       train_loss : 4.108721522723927, valid_loss : 4.387913465499878\n",
      "fold: 6, epoch: 0,                       train_loss : 4.137082029791439, valid_loss : 4.08508837223053\n",
      "fold: 7, epoch: 0,                       train_loss : 4.100974686005536, valid_loss : 4.359848618507385\n",
      "fold: 8, epoch: 0,                       train_loss : 4.097822371651144, valid_loss : 4.363036632537842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:15:19,072]\u001b[0m Trial 65 finished with value: 4.1368237137794495 and parameters: {'num_layers': 6, 'hidden_size': 40, 'batch_size': 160, 'learning_rate': 0.0012746475755117843}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.123946891111486, valid_loss : 4.385503053665161\n",
      "fold: 0, epoch: 0,                       train_loss : 6.339635586738586, valid_loss : 6.165623664855957\n",
      "fold: 0, epoch: 1,                       train_loss : 5.882877218723297, valid_loss : 5.351666450500488\n",
      "fold: 0, epoch: 2,                       train_loss : 5.964755868911743, valid_loss : 5.452332496643066\n",
      "fold: 0, epoch: 3,                       train_loss : 5.980508160591126, valid_loss : 5.377087116241455\n",
      "fold: 0, epoch: 4,                       train_loss : 5.891302299499512, valid_loss : 5.181052525838216\n",
      "fold: 0, epoch: 5,                       train_loss : 5.769868016242981, valid_loss : 5.399219830830892\n",
      "fold: 0, epoch: 6,                       train_loss : 6.3227674722671505, valid_loss : 5.308689912160237\n",
      "fold: 0, epoch: 7,                       train_loss : 5.724612474441528, valid_loss : 5.302756309509277\n",
      "fold: 0, epoch: 8,                       train_loss : 5.795543384552002, valid_loss : 5.1698533693949384\n",
      "fold: 0, epoch: 9,                       train_loss : 5.713677477836609, valid_loss : 4.819239139556885\n",
      "fold: 0, epoch: 10,                       train_loss : 5.563143944740295, valid_loss : 4.862128098805745\n",
      "fold: 0, epoch: 11,                       train_loss : 5.553971314430237, valid_loss : 5.366078694661458\n",
      "fold: 0, epoch: 12,                       train_loss : 5.577911305427551, valid_loss : 4.526418685913086\n",
      "fold: 0, epoch: 13,                       train_loss : 5.239648151397705, valid_loss : 4.738470395406087\n",
      "fold: 0, epoch: 14,                       train_loss : 5.173504161834717, valid_loss : 5.788694540659587\n",
      "fold: 0, epoch: 15,                       train_loss : 5.743178081512451, valid_loss : 4.379660765329997\n",
      "fold: 0, epoch: 16,                       train_loss : 5.076361334323883, valid_loss : 5.06802495320638\n",
      "fold: 0, epoch: 17,                       train_loss : 4.9565253257751465, valid_loss : 5.163718064626058\n",
      "fold: 1, epoch: 0,                       train_loss : 4.887607979774475, valid_loss : 4.769867579142253\n",
      "fold: 2, epoch: 0,                       train_loss : 5.5808279633522035, valid_loss : 4.755604982376099\n",
      "fold: 3, epoch: 0,                       train_loss : 4.796592140197754, valid_loss : 5.080435276031494\n",
      "fold: 4, epoch: 0,                       train_loss : 4.516300928592682, valid_loss : 4.019257148106893\n",
      "fold: 5, epoch: 0,                       train_loss : 4.47803655564785, valid_loss : 3.6241230169932046\n",
      "fold: 6, epoch: 0,                       train_loss : 4.299534630775452, valid_loss : 4.786920229593913\n",
      "fold: 7, epoch: 0,                       train_loss : 4.320407974720001, valid_loss : 4.389324188232422\n",
      "fold: 8, epoch: 0,                       train_loss : 4.256310117244721, valid_loss : 4.217621644337972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:15:42,206]\u001b[0m Trial 66 finished with value: 4.387358419100444 and parameters: {'num_layers': 5, 'hidden_size': 110, 'batch_size': 140, 'learning_rate': 0.0008314553176198806}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.389041709899902, valid_loss : 3.850769360860189\n",
      "fold: 0, epoch: 0,                       train_loss : 5.896115005016327, valid_loss : 6.087803840637207\n",
      "fold: 0, epoch: 1,                       train_loss : 5.752266108989716, valid_loss : 6.080259799957275\n",
      "fold: 0, epoch: 2,                       train_loss : 5.6952404379844666, valid_loss : 5.824928522109985\n",
      "fold: 0, epoch: 3,                       train_loss : 5.618900567293167, valid_loss : 5.834550619125366\n",
      "fold: 0, epoch: 4,                       train_loss : 5.537953704595566, valid_loss : 5.853764533996582\n",
      "fold: 0, epoch: 5,                       train_loss : 5.497046798467636, valid_loss : 5.727427244186401\n",
      "fold: 0, epoch: 6,                       train_loss : 5.423430472612381, valid_loss : 5.634812355041504\n",
      "fold: 0, epoch: 7,                       train_loss : 5.355616599321365, valid_loss : 5.629029273986816\n",
      "fold: 0, epoch: 8,                       train_loss : 5.319103956222534, valid_loss : 5.604015827178955\n",
      "fold: 0, epoch: 9,                       train_loss : 5.257994174957275, valid_loss : 5.602178335189819\n",
      "fold: 0, epoch: 10,                       train_loss : 5.205997854471207, valid_loss : 5.456795930862427\n",
      "fold: 0, epoch: 11,                       train_loss : 5.146053105592728, valid_loss : 5.526396036148071\n",
      "fold: 0, epoch: 12,                       train_loss : 5.11455237865448, valid_loss : 5.422716379165649\n",
      "fold: 0, epoch: 13,                       train_loss : 5.036403566598892, valid_loss : 5.276190757751465\n",
      "fold: 0, epoch: 14,                       train_loss : 5.008201628923416, valid_loss : 5.314802885055542\n",
      "fold: 0, epoch: 15,                       train_loss : 4.955736607313156, valid_loss : 5.265090227127075\n",
      "fold: 0, epoch: 16,                       train_loss : 4.935235291719437, valid_loss : 5.313589096069336\n",
      "fold: 0, epoch: 17,                       train_loss : 4.868433803319931, valid_loss : 5.229200601577759\n",
      "fold: 0, epoch: 18,                       train_loss : 4.82522714138031, valid_loss : 5.163808822631836\n",
      "fold: 0, epoch: 19,                       train_loss : 4.796892523765564, valid_loss : 5.115047216415405\n",
      "fold: 0, epoch: 20,                       train_loss : 4.777361333370209, valid_loss : 5.110773324966431\n",
      "fold: 0, epoch: 21,                       train_loss : 4.709239438176155, valid_loss : 5.124465227127075\n",
      "fold: 0, epoch: 22,                       train_loss : 4.682196035981178, valid_loss : 5.0696070194244385\n",
      "fold: 0, epoch: 23,                       train_loss : 4.658572182059288, valid_loss : 4.918083190917969\n",
      "fold: 0, epoch: 24,                       train_loss : 4.633996769785881, valid_loss : 5.014577865600586\n",
      "fold: 0, epoch: 25,                       train_loss : 4.595387279987335, valid_loss : 5.042365312576294\n",
      "fold: 0, epoch: 26,                       train_loss : 4.587857261300087, valid_loss : 4.863192081451416\n",
      "fold: 0, epoch: 27,                       train_loss : 4.524252757430077, valid_loss : 4.843358278274536\n",
      "fold: 0, epoch: 28,                       train_loss : 4.528810754418373, valid_loss : 4.986409902572632\n",
      "fold: 0, epoch: 29,                       train_loss : 4.48344874382019, valid_loss : 4.798617839813232\n",
      "fold: 0, epoch: 30,                       train_loss : 4.482764691114426, valid_loss : 4.87886905670166\n",
      "fold: 0, epoch: 31,                       train_loss : 4.445636555552483, valid_loss : 4.828450441360474\n",
      "fold: 1, epoch: 0,                       train_loss : 4.521345853805542, valid_loss : 4.006034970283508\n",
      "fold: 2, epoch: 0,                       train_loss : 4.444553881883621, valid_loss : 4.462722301483154\n",
      "fold: 3, epoch: 0,                       train_loss : 4.410746589303017, valid_loss : 4.551721096038818\n",
      "fold: 4, epoch: 0,                       train_loss : 4.35173773765564, valid_loss : 4.946884870529175\n",
      "fold: 5, epoch: 0,                       train_loss : 4.358664572238922, valid_loss : 4.861661195755005\n",
      "fold: 6, epoch: 0,                       train_loss : 4.4411656111478806, valid_loss : 3.8148008584976196\n",
      "fold: 7, epoch: 0,                       train_loss : 4.361986115574837, valid_loss : 4.505131483078003\n",
      "fold: 8, epoch: 0,                       train_loss : 4.382129728794098, valid_loss : 4.104055404663086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:16:04,626]\u001b[0m Trial 67 finished with value: 4.4185384750366214 and parameters: {'num_layers': 6, 'hidden_size': 80, 'batch_size': 170, 'learning_rate': 0.004168492481352118}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.360421776771545, valid_loss : 4.133754730224609\n",
      "fold: 0, epoch: 0,                       train_loss : 6.514366481615149, valid_loss : 6.6484731038411455\n",
      "fold: 0, epoch: 1,                       train_loss : 6.256731199181599, valid_loss : 6.453297138214111\n",
      "fold: 0, epoch: 2,                       train_loss : 6.134272450986116, valid_loss : 6.3078867594401045\n",
      "fold: 0, epoch: 3,                       train_loss : 5.799799836200217, valid_loss : 5.529601573944092\n",
      "fold: 0, epoch: 4,                       train_loss : 5.373750002487846, valid_loss : 5.14550240834554\n",
      "fold: 0, epoch: 5,                       train_loss : 4.922868583513343, valid_loss : 4.896704196929932\n",
      "fold: 0, epoch: 6,                       train_loss : 4.591891630836155, valid_loss : 4.483405828475952\n",
      "fold: 0, epoch: 7,                       train_loss : 4.394701740016108, valid_loss : 4.520706415176392\n",
      "fold: 0, epoch: 8,                       train_loss : 4.235222578048706, valid_loss : 4.483354489008586\n",
      "fold: 0, epoch: 9,                       train_loss : 4.126001420228378, valid_loss : 4.389639059702556\n",
      "fold: 0, epoch: 10,                       train_loss : 4.144975392714791, valid_loss : 4.704704920450847\n",
      "fold: 0, epoch: 11,                       train_loss : 4.084158887033877, valid_loss : 4.35789426167806\n",
      "fold: 0, epoch: 12,                       train_loss : 4.13580350253893, valid_loss : 4.042853991190593\n",
      "fold: 0, epoch: 13,                       train_loss : 4.089272975921631, valid_loss : 4.128289222717285\n",
      "fold: 0, epoch: 14,                       train_loss : 4.224853619285252, valid_loss : 4.3409037590026855\n",
      "fold: 0, epoch: 15,                       train_loss : 4.073099395503169, valid_loss : 4.544856786727905\n",
      "fold: 0, epoch: 16,                       train_loss : 4.095695060232411, valid_loss : 4.124242703119914\n",
      "fold: 0, epoch: 17,                       train_loss : 4.092000671055006, valid_loss : 4.315742254257202\n",
      "fold: 0, epoch: 18,                       train_loss : 4.126523318498031, valid_loss : 4.247838656107585\n",
      "fold: 0, epoch: 19,                       train_loss : 4.144423080527264, valid_loss : 4.091667016347249\n",
      "fold: 0, epoch: 20,                       train_loss : 4.1310971094214395, valid_loss : 4.27603022257487\n",
      "fold: 0, epoch: 21,                       train_loss : 4.103916862736577, valid_loss : 4.307759761810303\n",
      "fold: 1, epoch: 0,                       train_loss : 4.136553899101589, valid_loss : 4.437113046646118\n",
      "fold: 2, epoch: 0,                       train_loss : 4.156602849131045, valid_loss : 3.7157651583353677\n",
      "fold: 3, epoch: 0,                       train_loss : 4.11194254004437, valid_loss : 4.086271286010742\n",
      "fold: 4, epoch: 0,                       train_loss : 4.10960520868716, valid_loss : 4.148913065592448\n",
      "fold: 5, epoch: 0,                       train_loss : 4.072221641955168, valid_loss : 4.830264727274577\n",
      "fold: 6, epoch: 0,                       train_loss : 4.153161898903225, valid_loss : 4.079971631368001\n",
      "fold: 7, epoch: 0,                       train_loss : 4.186624972716622, valid_loss : 4.181756655375163\n",
      "fold: 8, epoch: 0,                       train_loss : 4.157667875289917, valid_loss : 3.725561539332072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:16:38,054]\u001b[0m Trial 68 finished with value: 4.124841936429342 and parameters: {'num_layers': 5, 'hidden_size': 130, 'batch_size': 120, 'learning_rate': 0.003283930354271181}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.184042940969053, valid_loss : 3.999948263168335\n",
      "fold: 0, epoch: 0,                       train_loss : 6.196432554721833, valid_loss : 5.405990123748779\n",
      "fold: 0, epoch: 1,                       train_loss : 6.247065758705139, valid_loss : 4.147029399871826\n",
      "fold: 0, epoch: 2,                       train_loss : 4.209575951099396, valid_loss : 3.9386202494303384\n",
      "fold: 0, epoch: 3,                       train_loss : 4.3643858432769775, valid_loss : 3.7688653469085693\n",
      "fold: 0, epoch: 4,                       train_loss : 4.348215985298157, valid_loss : 4.1934802532196045\n",
      "fold: 0, epoch: 5,                       train_loss : 4.598539805412292, valid_loss : 3.441685914993286\n",
      "fold: 0, epoch: 6,                       train_loss : 4.635099732875824, valid_loss : 3.6973842779795327\n",
      "fold: 0, epoch: 7,                       train_loss : 4.263436186313629, valid_loss : 3.303927183151245\n",
      "fold: 0, epoch: 8,                       train_loss : 4.14495142698288, valid_loss : 3.886131683985392\n",
      "fold: 0, epoch: 9,                       train_loss : 4.133249914646148, valid_loss : 3.5167988936106362\n",
      "fold: 0, epoch: 10,                       train_loss : 4.523742699623108, valid_loss : 3.8263980547587075\n",
      "fold: 0, epoch: 11,                       train_loss : 4.115503644943237, valid_loss : 3.8428701559702554\n",
      "fold: 0, epoch: 12,                       train_loss : 4.050848269462586, valid_loss : 3.668248176574707\n",
      "fold: 0, epoch: 13,                       train_loss : 4.050005698204041, valid_loss : 3.431091864903768\n",
      "fold: 0, epoch: 14,                       train_loss : 4.10313572883606, valid_loss : 4.134045839309692\n",
      "fold: 0, epoch: 15,                       train_loss : 4.130212581157684, valid_loss : 3.9537301858266196\n",
      "fold: 0, epoch: 16,                       train_loss : 4.035269701480866, valid_loss : 3.7415761152903237\n",
      "fold: 1, epoch: 0,                       train_loss : 4.064058542251587, valid_loss : 3.779235521952311\n",
      "fold: 2, epoch: 0,                       train_loss : 4.108037734031678, valid_loss : 3.792486588160197\n",
      "fold: 3, epoch: 0,                       train_loss : 4.006318151950836, valid_loss : 4.861058235168457\n",
      "fold: 4, epoch: 0,                       train_loss : 4.17486605644226, valid_loss : 4.303190549214681\n",
      "fold: 5, epoch: 0,                       train_loss : 3.945002329349518, valid_loss : 5.394426663716634\n",
      "fold: 6, epoch: 0,                       train_loss : 4.052835094928741, valid_loss : 4.775364478429158\n",
      "fold: 7, epoch: 0,                       train_loss : 4.053611302375794, valid_loss : 4.829872767130534\n",
      "fold: 8, epoch: 0,                       train_loss : 4.176792085170746, valid_loss : 4.695611794789632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:16:56,234]\u001b[0m Trial 69 finished with value: 4.344615165392558 and parameters: {'num_layers': 6, 'hidden_size': 90, 'batch_size': 140, 'learning_rate': 0.005106450816749494}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.052930843830109, valid_loss : 3.710977872212728\n",
      "fold: 0, epoch: 0,                       train_loss : 5.913404941558838, valid_loss : 5.06780481338501\n",
      "fold: 0, epoch: 1,                       train_loss : 4.93498170375824, valid_loss : 4.091077446937561\n",
      "fold: 0, epoch: 2,                       train_loss : 4.202400830056932, valid_loss : 4.084155440330505\n",
      "fold: 0, epoch: 3,                       train_loss : 4.159220735232036, valid_loss : 3.96990966796875\n",
      "fold: 0, epoch: 4,                       train_loss : 4.159830954339769, valid_loss : 3.973333239555359\n",
      "fold: 0, epoch: 5,                       train_loss : 4.1470681296454535, valid_loss : 3.9877500534057617\n",
      "fold: 0, epoch: 6,                       train_loss : 4.158674478530884, valid_loss : 3.9731911420822144\n",
      "fold: 0, epoch: 7,                       train_loss : 4.1525015168719825, valid_loss : 3.978373408317566\n",
      "fold: 0, epoch: 8,                       train_loss : 4.151220083236694, valid_loss : 3.965568780899048\n",
      "fold: 0, epoch: 9,                       train_loss : 4.164159403906928, valid_loss : 3.974380373954773\n",
      "fold: 0, epoch: 10,                       train_loss : 4.157286233372158, valid_loss : 3.971803903579712\n",
      "fold: 0, epoch: 11,                       train_loss : 4.14908324347602, valid_loss : 3.978533148765564\n",
      "fold: 0, epoch: 12,                       train_loss : 4.155268563164605, valid_loss : 3.974441647529602\n",
      "fold: 0, epoch: 13,                       train_loss : 4.145856022834778, valid_loss : 3.9836153984069824\n",
      "fold: 0, epoch: 14,                       train_loss : 4.147387862205505, valid_loss : 3.977416157722473\n",
      "fold: 0, epoch: 15,                       train_loss : 4.154563824335734, valid_loss : 3.9824471473693848\n",
      "fold: 1, epoch: 0,                       train_loss : 4.116997970475091, valid_loss : 4.338948488235474\n",
      "fold: 2, epoch: 0,                       train_loss : 4.1197091870837745, valid_loss : 4.272453308105469\n",
      "fold: 3, epoch: 0,                       train_loss : 4.145505468050639, valid_loss : 4.027642011642456\n",
      "fold: 4, epoch: 0,                       train_loss : 4.173237668143378, valid_loss : 3.7190589904785156\n",
      "fold: 5, epoch: 0,                       train_loss : 4.135696079995897, valid_loss : 4.057747840881348\n",
      "fold: 6, epoch: 0,                       train_loss : 4.170283794403076, valid_loss : 3.780172109603882\n",
      "fold: 7, epoch: 0,                       train_loss : 4.11654527982076, valid_loss : 4.311640739440918\n",
      "fold: 8, epoch: 0,                       train_loss : 4.137345618671841, valid_loss : 4.1547887325286865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:17:16,345]\u001b[0m Trial 70 finished with value: 4.134378409385681 and parameters: {'num_layers': 5, 'hidden_size': 120, 'batch_size': 150, 'learning_rate': 0.008968774539247996}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.077199247148302, valid_loss : 4.715763092041016\n",
      "fold: 0, epoch: 0,                       train_loss : 5.728015400114513, valid_loss : 5.315998077392578\n",
      "fold: 0, epoch: 1,                       train_loss : 4.331977015449887, valid_loss : 4.4225231011708575\n",
      "fold: 0, epoch: 2,                       train_loss : 4.141361486344111, valid_loss : 4.025920391082764\n",
      "fold: 0, epoch: 3,                       train_loss : 4.141330571401687, valid_loss : 4.031942049662272\n",
      "fold: 0, epoch: 4,                       train_loss : 4.143179802667527, valid_loss : 4.785876115163167\n",
      "fold: 0, epoch: 5,                       train_loss : 4.159149964650472, valid_loss : 4.201397736867269\n",
      "fold: 0, epoch: 6,                       train_loss : 4.120324543544224, valid_loss : 4.316354592641194\n",
      "fold: 0, epoch: 7,                       train_loss : 4.124175060363043, valid_loss : 4.311084588368733\n",
      "fold: 0, epoch: 8,                       train_loss : 4.113892634709676, valid_loss : 4.150217771530151\n",
      "fold: 0, epoch: 9,                       train_loss : 4.131641183580671, valid_loss : 4.144233147303264\n",
      "fold: 0, epoch: 10,                       train_loss : 4.155618406477428, valid_loss : 4.091128667195638\n",
      "fold: 0, epoch: 11,                       train_loss : 4.123997745059786, valid_loss : 4.034191131591797\n",
      "fold: 0, epoch: 12,                       train_loss : 4.132742893128168, valid_loss : 3.8517181873321533\n",
      "fold: 0, epoch: 13,                       train_loss : 4.115900130498977, valid_loss : 4.195018450419108\n",
      "fold: 0, epoch: 14,                       train_loss : 4.130528438658941, valid_loss : 4.527389446894328\n",
      "fold: 1, epoch: 0,                       train_loss : 4.13801121711731, valid_loss : 4.031735420227051\n",
      "fold: 2, epoch: 0,                       train_loss : 4.131426436560495, valid_loss : 4.683580080668132\n",
      "fold: 3, epoch: 0,                       train_loss : 4.09754356883821, valid_loss : 4.234556833902995\n",
      "fold: 4, epoch: 0,                       train_loss : 4.152651809510731, valid_loss : 4.062662124633789\n",
      "fold: 5, epoch: 0,                       train_loss : 4.166380257833572, valid_loss : 3.856346845626831\n",
      "fold: 6, epoch: 0,                       train_loss : 4.163638557706561, valid_loss : 3.5641345183054605\n",
      "fold: 7, epoch: 0,                       train_loss : 4.14482999983288, valid_loss : 4.251838763554891\n",
      "fold: 8, epoch: 0,                       train_loss : 4.138939074107578, valid_loss : 4.722485224405925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:17:29,728]\u001b[0m Trial 71 finished with value: 4.098830898602804 and parameters: {'num_layers': 6, 'hidden_size': 60, 'batch_size': 130, 'learning_rate': 0.012345158502248516}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.20186692192441, valid_loss : 3.729250987370809\n",
      "fold: 0, epoch: 0,                       train_loss : 5.749011198679606, valid_loss : 6.3419225215911865\n",
      "fold: 0, epoch: 1,                       train_loss : 5.308286295996772, valid_loss : 5.562480688095093\n",
      "fold: 0, epoch: 2,                       train_loss : 4.297241277164883, valid_loss : 4.651958703994751\n",
      "fold: 0, epoch: 3,                       train_loss : 4.092558304468791, valid_loss : 4.681495666503906\n",
      "fold: 0, epoch: 4,                       train_loss : 4.081027799182468, valid_loss : 4.671459197998047\n",
      "fold: 0, epoch: 5,                       train_loss : 4.079152199957106, valid_loss : 4.664410829544067\n",
      "fold: 0, epoch: 6,                       train_loss : 4.078917900721232, valid_loss : 4.675014495849609\n",
      "fold: 0, epoch: 7,                       train_loss : 4.0702586968739825, valid_loss : 4.660218238830566\n",
      "fold: 0, epoch: 8,                       train_loss : 4.0835267305374146, valid_loss : 4.680842638015747\n",
      "fold: 0, epoch: 9,                       train_loss : 4.077625340885586, valid_loss : 4.684133291244507\n",
      "fold: 0, epoch: 10,                       train_loss : 4.070125155978733, valid_loss : 4.656738042831421\n",
      "fold: 0, epoch: 11,                       train_loss : 4.084141850471497, valid_loss : 4.68926215171814\n",
      "fold: 0, epoch: 12,                       train_loss : 4.085234920183818, valid_loss : 4.68311619758606\n",
      "fold: 0, epoch: 13,                       train_loss : 4.082211825582716, valid_loss : 4.664390325546265\n",
      "fold: 1, epoch: 0,                       train_loss : 4.109955853886074, valid_loss : 4.310498476028442\n",
      "fold: 2, epoch: 0,                       train_loss : 4.151294589042664, valid_loss : 4.065106987953186\n",
      "fold: 3, epoch: 0,                       train_loss : 4.139882326126099, valid_loss : 4.12148642539978\n",
      "fold: 4, epoch: 0,                       train_loss : 4.174660682678223, valid_loss : 3.7793784141540527\n",
      "fold: 5, epoch: 0,                       train_loss : 4.161535965071784, valid_loss : 3.9486606121063232\n",
      "fold: 6, epoch: 0,                       train_loss : 4.069964183701409, valid_loss : 4.759033203125\n",
      "fold: 7, epoch: 0,                       train_loss : 4.160930924945408, valid_loss : 3.9499212503433228\n",
      "fold: 8, epoch: 0,                       train_loss : 4.135431064499749, valid_loss : 4.051222324371338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:17:39,215]\u001b[0m Trial 72 finished with value: 4.137740576267243 and parameters: {'num_layers': 6, 'hidden_size': 50, 'batch_size': 150, 'learning_rate': 0.00642770934929071}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1826050943798485, valid_loss : 3.740139365196228\n",
      "fold: 0, epoch: 0,                       train_loss : 6.319547486305237, valid_loss : 6.237320899963379\n",
      "fold: 0, epoch: 1,                       train_loss : 6.070169138908386, valid_loss : 5.998185475667317\n",
      "fold: 0, epoch: 2,                       train_loss : 5.673149752616882, valid_loss : 5.840658346811931\n",
      "fold: 0, epoch: 3,                       train_loss : 5.488446319103241, valid_loss : 4.310114622116089\n",
      "fold: 0, epoch: 4,                       train_loss : 4.39888710975647, valid_loss : 3.985780874888102\n",
      "fold: 0, epoch: 5,                       train_loss : 4.028364694118499, valid_loss : 4.254294713338216\n",
      "fold: 0, epoch: 6,                       train_loss : 4.485827374458313, valid_loss : 4.310000419616699\n",
      "fold: 0, epoch: 7,                       train_loss : 4.221774554252624, valid_loss : 3.958037773768107\n",
      "fold: 0, epoch: 8,                       train_loss : 4.063520121574402, valid_loss : 4.876033782958984\n",
      "fold: 0, epoch: 9,                       train_loss : 4.062922573089599, valid_loss : 4.343268076578776\n",
      "fold: 0, epoch: 10,                       train_loss : 4.012850677967071, valid_loss : 4.827773729960124\n",
      "fold: 0, epoch: 11,                       train_loss : 3.9587113499641418, valid_loss : 4.538961728413899\n",
      "fold: 0, epoch: 12,                       train_loss : 3.9851553678512572, valid_loss : 5.721186637878418\n",
      "fold: 0, epoch: 13,                       train_loss : 3.977905249595642, valid_loss : 4.616494655609131\n",
      "fold: 0, epoch: 14,                       train_loss : 3.968428099155426, valid_loss : 4.494895935058594\n",
      "fold: 0, epoch: 15,                       train_loss : 4.077394723892212, valid_loss : 4.605889956156413\n",
      "fold: 0, epoch: 16,                       train_loss : 3.9320999652147295, valid_loss : 4.17065691947937\n",
      "fold: 1, epoch: 0,                       train_loss : 4.035326111316681, valid_loss : 3.8695881366729736\n",
      "fold: 2, epoch: 0,                       train_loss : 4.003123724460602, valid_loss : 4.980264504750569\n",
      "fold: 3, epoch: 0,                       train_loss : 4.645474302768707, valid_loss : 4.806978225708008\n",
      "fold: 4, epoch: 0,                       train_loss : 4.01304018497467, valid_loss : 4.436323960622151\n",
      "fold: 5, epoch: 0,                       train_loss : 4.016676950454712, valid_loss : 4.526231288909912\n",
      "fold: 6, epoch: 0,                       train_loss : 4.107271206378937, valid_loss : 3.574035088221232\n",
      "fold: 7, epoch: 0,                       train_loss : 4.2977241516113285, valid_loss : 4.161049127578735\n",
      "fold: 8, epoch: 0,                       train_loss : 4.176779901981353, valid_loss : 4.1961478392283125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:17:59,816]\u001b[0m Trial 73 finished with value: 4.309132766723633 and parameters: {'num_layers': 6, 'hidden_size': 100, 'batch_size': 140, 'learning_rate': 0.0024305898295623714}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.118314850330353, valid_loss : 4.582671721776326\n",
      "fold: 0, epoch: 0,                       train_loss : 5.417128494807652, valid_loss : 4.16180682182312\n",
      "fold: 0, epoch: 1,                       train_loss : 4.186668271110172, valid_loss : 3.928619305292765\n",
      "fold: 0, epoch: 2,                       train_loss : 4.164928027561733, valid_loss : 4.626244068145752\n",
      "fold: 0, epoch: 3,                       train_loss : 4.139431011109125, valid_loss : 3.8776164054870605\n",
      "fold: 0, epoch: 4,                       train_loss : 4.14134973571414, valid_loss : 4.017538070678711\n",
      "fold: 0, epoch: 5,                       train_loss : 4.155541068031674, valid_loss : 4.026527643203735\n",
      "fold: 0, epoch: 6,                       train_loss : 4.10971542767116, valid_loss : 4.246597528457642\n",
      "fold: 0, epoch: 7,                       train_loss : 4.137829735165551, valid_loss : 4.442470232645671\n",
      "fold: 0, epoch: 8,                       train_loss : 4.117454608281453, valid_loss : 3.6595542430877686\n",
      "fold: 0, epoch: 9,                       train_loss : 4.152143694105602, valid_loss : 3.9031089146931968\n",
      "fold: 0, epoch: 10,                       train_loss : 4.136858145395915, valid_loss : 3.9750077724456787\n",
      "fold: 0, epoch: 11,                       train_loss : 4.128758067176456, valid_loss : 3.8622443675994873\n",
      "fold: 0, epoch: 12,                       train_loss : 4.127279270262945, valid_loss : 4.350027163823445\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1284018357594805, valid_loss : 5.143891414006551\n",
      "fold: 0, epoch: 14,                       train_loss : 4.127573104131789, valid_loss : 4.2713963985443115\n",
      "fold: 1, epoch: 0,                       train_loss : 4.184030362537929, valid_loss : 3.64845609664917\n",
      "fold: 2, epoch: 0,                       train_loss : 4.089726845423381, valid_loss : 5.459313948949178\n",
      "fold: 3, epoch: 0,                       train_loss : 4.072127978006999, valid_loss : 4.373552401860555\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1365640958150225, valid_loss : 4.013572533925374\n",
      "fold: 5, epoch: 0,                       train_loss : 4.142246700468517, valid_loss : 4.419329881668091\n",
      "fold: 6, epoch: 0,                       train_loss : 4.108557394572666, valid_loss : 4.70835558573405\n",
      "fold: 7, epoch: 0,                       train_loss : 4.148408129101708, valid_loss : 3.9171179135640464\n",
      "fold: 8, epoch: 0,                       train_loss : 4.163989112490699, valid_loss : 3.7929930686950684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:18:11,227]\u001b[0m Trial 74 finished with value: 4.180545337994894 and parameters: {'num_layers': 6, 'hidden_size': 50, 'batch_size': 130, 'learning_rate': 0.010018486796870826}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.158482948939006, valid_loss : 3.8132077058156333\n",
      "fold: 0, epoch: 0,                       train_loss : 5.383772345150218, valid_loss : 4.418244361877441\n",
      "fold: 0, epoch: 1,                       train_loss : 4.186073373345768, valid_loss : 4.147901177406311\n",
      "fold: 0, epoch: 2,                       train_loss : 4.177294071982889, valid_loss : 4.112485766410828\n",
      "fold: 0, epoch: 3,                       train_loss : 4.1316898149602554, valid_loss : 4.14760160446167\n",
      "fold: 0, epoch: 4,                       train_loss : 4.152935827479643, valid_loss : 4.1863603591918945\n",
      "fold: 0, epoch: 5,                       train_loss : 4.117626835318172, valid_loss : 4.203301310539246\n",
      "fold: 0, epoch: 6,                       train_loss : 4.135921856936286, valid_loss : 4.1067739725112915\n",
      "fold: 0, epoch: 7,                       train_loss : 4.147361993789673, valid_loss : 4.196470499038696\n",
      "fold: 0, epoch: 8,                       train_loss : 4.125501029631671, valid_loss : 4.124879240989685\n",
      "fold: 0, epoch: 9,                       train_loss : 4.14440850650563, valid_loss : 4.109461545944214\n",
      "fold: 0, epoch: 10,                       train_loss : 4.1536835361929505, valid_loss : 4.1127132177352905\n",
      "fold: 0, epoch: 11,                       train_loss : 4.1249591462752395, valid_loss : 4.144673705101013\n",
      "fold: 0, epoch: 12,                       train_loss : 4.124112872516408, valid_loss : 4.1437156200408936\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1409555182737465, valid_loss : 4.078909873962402\n",
      "fold: 0, epoch: 14,                       train_loss : 4.150963867411894, valid_loss : 4.116511106491089\n",
      "fold: 0, epoch: 15,                       train_loss : 4.150178502587711, valid_loss : 4.12139356136322\n",
      "fold: 1, epoch: 0,                       train_loss : 4.133360680411844, valid_loss : 4.279224634170532\n",
      "fold: 2, epoch: 0,                       train_loss : 4.14305305480957, valid_loss : 4.217937707901001\n",
      "fold: 3, epoch: 0,                       train_loss : 4.217130731133854, valid_loss : 3.6981170177459717\n",
      "fold: 4, epoch: 0,                       train_loss : 4.068233195473166, valid_loss : 4.714048147201538\n",
      "fold: 5, epoch: 0,                       train_loss : 4.170052275938146, valid_loss : 4.018184661865234\n",
      "fold: 6, epoch: 0,                       train_loss : 4.168103498571059, valid_loss : 4.040584683418274\n",
      "fold: 7, epoch: 0,                       train_loss : 4.192048647824456, valid_loss : 3.802165389060974\n",
      "fold: 8, epoch: 0,                       train_loss : 4.145368435803582, valid_loss : 3.9708064794540405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:18:24,011]\u001b[0m Trial 75 finished with value: 4.143662416934967 and parameters: {'num_layers': 4, 'hidden_size': 70, 'batch_size': 160, 'learning_rate': 0.02021231377534769}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.094910621643066, valid_loss : 4.616645574569702\n",
      "fold: 0, epoch: 0,                       train_loss : 5.523306493759155, valid_loss : 3.7374308904012046\n",
      "fold: 0, epoch: 1,                       train_loss : 4.3090572166442875, valid_loss : 3.7356266180674234\n",
      "fold: 0, epoch: 2,                       train_loss : 4.15994626045227, valid_loss : 3.7609593073527017\n",
      "fold: 0, epoch: 3,                       train_loss : 4.158277587890625, valid_loss : 3.7339640458424888\n",
      "fold: 0, epoch: 4,                       train_loss : 4.182007942199707, valid_loss : 3.7214489777882895\n",
      "fold: 0, epoch: 5,                       train_loss : 4.1960856723785405, valid_loss : 3.7646698156992593\n",
      "fold: 0, epoch: 6,                       train_loss : 4.172291221618653, valid_loss : 3.7624521255493164\n",
      "fold: 0, epoch: 7,                       train_loss : 4.193350343704224, valid_loss : 3.7392579714457193\n",
      "fold: 0, epoch: 8,                       train_loss : 4.170330772399902, valid_loss : 3.7356461683909097\n",
      "fold: 0, epoch: 9,                       train_loss : 4.171832437515259, valid_loss : 3.8331755797068277\n",
      "fold: 0, epoch: 10,                       train_loss : 4.151259126663208, valid_loss : 3.735649506251017\n",
      "fold: 0, epoch: 11,                       train_loss : 4.183388195037842, valid_loss : 3.7895820140838623\n",
      "fold: 0, epoch: 12,                       train_loss : 4.159186334609985, valid_loss : 3.8558270931243896\n",
      "fold: 0, epoch: 13,                       train_loss : 4.203729953765869, valid_loss : 3.75678817431132\n",
      "fold: 0, epoch: 14,                       train_loss : 4.238263816833496, valid_loss : 3.732490619023641\n",
      "fold: 1, epoch: 0,                       train_loss : 4.207189626693726, valid_loss : 4.0965806643168134\n",
      "fold: 2, epoch: 0,                       train_loss : 4.130877237319947, valid_loss : 4.015217224756877\n",
      "fold: 3, epoch: 0,                       train_loss : 4.131290712356567, valid_loss : 4.03867753346761\n",
      "fold: 4, epoch: 0,                       train_loss : 4.094903221130371, valid_loss : 4.455465316772461\n",
      "fold: 5, epoch: 0,                       train_loss : 4.115417261123657, valid_loss : 4.263246138890584\n",
      "fold: 6, epoch: 0,                       train_loss : 4.2078950977325436, valid_loss : 4.216219584147136\n",
      "fold: 7, epoch: 0,                       train_loss : 4.1938582801818844, valid_loss : 3.9864006837209067\n",
      "fold: 8, epoch: 0,                       train_loss : 4.113505163192749, valid_loss : 4.176571289698283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:18:45,971]\u001b[0m Trial 76 finished with value: 4.139387003580728 and parameters: {'num_layers': 5, 'hidden_size': 100, 'batch_size': 110, 'learning_rate': 0.014869241126049967}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.140413866043091, valid_loss : 4.424042622248332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([80, 1])) that is different to the input size (torch.Size([80])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                       train_loss : 5.4097862874760345, valid_loss : 4.592095851898193\n",
      "fold: 0, epoch: 1,                       train_loss : 4.212900729740367, valid_loss : 4.3508079051971436\n",
      "fold: 0, epoch: 2,                       train_loss : 4.121021095444174, valid_loss : 4.313603520393372\n",
      "fold: 0, epoch: 3,                       train_loss : 4.091958389562719, valid_loss : 4.318679392337799\n",
      "fold: 0, epoch: 4,                       train_loss : 4.198865722207462, valid_loss : 4.356860041618347\n",
      "fold: 0, epoch: 5,                       train_loss : 4.169009783688714, valid_loss : 4.3358548283576965\n",
      "fold: 0, epoch: 6,                       train_loss : 4.134342067381915, valid_loss : 4.378309667110443\n",
      "fold: 0, epoch: 7,                       train_loss : 4.121427655220032, valid_loss : 4.293108105659485\n",
      "fold: 0, epoch: 8,                       train_loss : 4.115526921608868, valid_loss : 4.350944638252258\n",
      "fold: 0, epoch: 9,                       train_loss : 4.112576603889465, valid_loss : 4.375674247741699\n",
      "fold: 0, epoch: 10,                       train_loss : 4.102226523792043, valid_loss : 4.367261528968811\n",
      "fold: 0, epoch: 11,                       train_loss : 4.151282135178061, valid_loss : 4.336008846759796\n",
      "fold: 0, epoch: 12,                       train_loss : 4.11197707232307, valid_loss : 4.44867217540741\n",
      "fold: 0, epoch: 13,                       train_loss : 4.082557005040786, valid_loss : 4.423194766044617\n",
      "fold: 0, epoch: 14,                       train_loss : 4.106434660799363, valid_loss : 4.4440144300460815\n",
      "fold: 1, epoch: 0,                       train_loss : 4.09639127815471, valid_loss : 4.3295411467552185\n",
      "fold: 2, epoch: 0,                       train_loss : 4.191888367428499, valid_loss : 3.523154377937317\n",
      "fold: 3, epoch: 0,                       train_loss : 4.128991554765141, valid_loss : 4.236982047557831\n",
      "fold: 4, epoch: 0,                       train_loss : 4.108628322096432, valid_loss : 4.3092846274375916\n",
      "fold: 5, epoch: 0,                       train_loss : 4.10637836596545, valid_loss : 4.501551806926727\n",
      "fold: 6, epoch: 0,                       train_loss : 4.239749242277706, valid_loss : 3.7561882734298706\n",
      "fold: 7, epoch: 0,                       train_loss : 4.211294026935802, valid_loss : 3.8760798573493958\n",
      "fold: 8, epoch: 0,                       train_loss : 4.123101914630217, valid_loss : 4.579824686050415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:18:54,855]\u001b[0m Trial 77 finished with value: 4.114567238092422 and parameters: {'num_layers': 6, 'hidden_size': 20, 'batch_size': 80, 'learning_rate': 0.0075883786565318755}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.142988218980677, valid_loss : 3.7399574518203735\n",
      "fold: 0, epoch: 0,                       train_loss : 4.5870791606688766, valid_loss : 4.413296733299891\n",
      "fold: 0, epoch: 1,                       train_loss : 4.1407561364691805, valid_loss : 4.394194515546163\n",
      "fold: 0, epoch: 2,                       train_loss : 4.130118309335316, valid_loss : 4.406382668018341\n",
      "fold: 0, epoch: 3,                       train_loss : 4.141577370157849, valid_loss : 4.435055494308472\n",
      "fold: 0, epoch: 4,                       train_loss : 4.117096732171734, valid_loss : 4.382968171437581\n",
      "fold: 0, epoch: 5,                       train_loss : 4.1117646220918, valid_loss : 4.4008231123288475\n",
      "fold: 0, epoch: 6,                       train_loss : 4.129805022857609, valid_loss : 4.376794521013895\n",
      "fold: 0, epoch: 7,                       train_loss : 4.110785950435681, valid_loss : 4.543723650773367\n",
      "fold: 0, epoch: 8,                       train_loss : 4.112502886561419, valid_loss : 4.419246085484823\n",
      "fold: 0, epoch: 9,                       train_loss : 4.1049172132649225, valid_loss : 4.4511042873064675\n",
      "fold: 0, epoch: 10,                       train_loss : 4.108920208077306, valid_loss : 4.4387137254079185\n",
      "fold: 0, epoch: 11,                       train_loss : 4.107281827301568, valid_loss : 4.4766067941983545\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1296833990218484, valid_loss : 4.545888272921244\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1077654924285545, valid_loss : 4.375626754760742\n",
      "fold: 0, epoch: 14,                       train_loss : 4.1061342008104935, valid_loss : 4.40093420346578\n",
      "fold: 0, epoch: 15,                       train_loss : 4.112683118059394, valid_loss : 4.446244057019552\n",
      "fold: 1, epoch: 0,                       train_loss : 4.162262404902598, valid_loss : 3.957537519931793\n",
      "fold: 2, epoch: 0,                       train_loss : 4.149452100978809, valid_loss : 4.123883565266927\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1713346287552335, valid_loss : 3.9437310616175334\n",
      "fold: 4, epoch: 0,                       train_loss : 4.120531348699934, valid_loss : 4.328911813100179\n",
      "fold: 5, epoch: 0,                       train_loss : 4.171895543287756, valid_loss : 3.87286776304245\n",
      "fold: 6, epoch: 0,                       train_loss : 4.11586287673493, valid_loss : 4.400438666343689\n",
      "fold: 7, epoch: 0,                       train_loss : 4.143779159931654, valid_loss : 4.185736429691315\n",
      "fold: 8, epoch: 0,                       train_loss : 4.198616557353445, valid_loss : 3.7098808248837787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:25:27,479]\u001b[0m Trial 78 finished with value: 4.138198919296265 and parameters: {'num_layers': 6, 'hidden_size': 190, 'batch_size': 10, 'learning_rate': 0.005899660533182934}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1057381138819435, valid_loss : 4.483374794324239\n",
      "fold: 0, epoch: 0,                       train_loss : 5.551229083019754, valid_loss : 6.245667616526286\n",
      "fold: 0, epoch: 1,                       train_loss : 5.501311861950418, valid_loss : 5.940329869588216\n",
      "fold: 0, epoch: 2,                       train_loss : 5.224299679631772, valid_loss : 5.827175617218018\n",
      "fold: 0, epoch: 3,                       train_loss : 4.883684096129044, valid_loss : 4.969367027282715\n",
      "fold: 0, epoch: 4,                       train_loss : 4.441291715787805, valid_loss : 4.844350179036458\n",
      "fold: 0, epoch: 5,                       train_loss : 4.170107478680818, valid_loss : 4.590291341145833\n",
      "fold: 0, epoch: 6,                       train_loss : 4.0516426977903945, valid_loss : 4.424158334732056\n",
      "fold: 0, epoch: 7,                       train_loss : 4.041040534558504, valid_loss : 4.683839241663615\n",
      "fold: 0, epoch: 8,                       train_loss : 4.059259114058121, valid_loss : 4.525455474853516\n",
      "fold: 0, epoch: 9,                       train_loss : 4.035818068877511, valid_loss : 4.776805241902669\n",
      "fold: 0, epoch: 10,                       train_loss : 4.035832519116609, valid_loss : 4.540471076965332\n",
      "fold: 0, epoch: 11,                       train_loss : 4.121702878371529, valid_loss : 4.672322034835815\n",
      "fold: 0, epoch: 12,                       train_loss : 4.068030170772387, valid_loss : 4.846755504608154\n",
      "fold: 0, epoch: 13,                       train_loss : 4.040904107301132, valid_loss : 4.512625058492024\n",
      "fold: 0, epoch: 14,                       train_loss : 4.044124820958013, valid_loss : 4.556631565093994\n",
      "fold: 0, epoch: 15,                       train_loss : 4.055843052656754, valid_loss : 4.584370772043864\n",
      "fold: 0, epoch: 16,                       train_loss : 4.085949483125106, valid_loss : 4.874115149180095\n",
      "fold: 0, epoch: 17,                       train_loss : 4.022268015405406, valid_loss : 4.593626181284587\n",
      "fold: 1, epoch: 0,                       train_loss : 4.096592778744905, valid_loss : 4.104615529378255\n",
      "fold: 2, epoch: 0,                       train_loss : 4.056309731110282, valid_loss : 4.30591615041097\n",
      "fold: 3, epoch: 0,                       train_loss : 4.227513323659482, valid_loss : 3.673734664916992\n",
      "fold: 4, epoch: 0,                       train_loss : 4.111984294393788, valid_loss : 3.9606735706329346\n",
      "fold: 5, epoch: 0,                       train_loss : 4.066786848980447, valid_loss : 4.20940899848938\n",
      "fold: 6, epoch: 0,                       train_loss : 4.099540326906287, valid_loss : 4.770364125569661\n",
      "fold: 7, epoch: 0,                       train_loss : 4.155056735743647, valid_loss : 4.483121395111084\n",
      "fold: 8, epoch: 0,                       train_loss : 4.186784868654997, valid_loss : 3.5848209857940674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:25:48,345]\u001b[0m Trial 79 finished with value: 4.132277472813924 and parameters: {'num_layers': 5, 'hidden_size': 80, 'batch_size': 120, 'learning_rate': 0.0018740360781225878}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.123743575552235, valid_loss : 3.8059609731038413\n",
      "fold: 0, epoch: 0,                       train_loss : 5.993292695000058, valid_loss : 5.794802983601888\n",
      "fold: 0, epoch: 1,                       train_loss : 5.691709132421584, valid_loss : 5.308218955993652\n",
      "fold: 0, epoch: 2,                       train_loss : 5.531729698181152, valid_loss : 4.965215524037679\n",
      "fold: 0, epoch: 3,                       train_loss : 5.38814115524292, valid_loss : 5.132865111033122\n",
      "fold: 0, epoch: 4,                       train_loss : 5.198701779047648, valid_loss : 5.129648526509603\n",
      "fold: 0, epoch: 5,                       train_loss : 5.085785434359596, valid_loss : 4.733725070953369\n",
      "fold: 0, epoch: 6,                       train_loss : 4.968819867996943, valid_loss : 4.342455466588338\n",
      "fold: 0, epoch: 7,                       train_loss : 4.860047544751849, valid_loss : 4.379212538401286\n",
      "fold: 0, epoch: 8,                       train_loss : 4.741553068161011, valid_loss : 4.305026213328044\n",
      "fold: 0, epoch: 9,                       train_loss : 4.68942243712289, valid_loss : 4.449824571609497\n",
      "fold: 0, epoch: 10,                       train_loss : 4.6047709328787665, valid_loss : 4.475122292836507\n",
      "fold: 0, epoch: 11,                       train_loss : 4.5251549652644565, valid_loss : 4.36953067779541\n",
      "fold: 0, epoch: 12,                       train_loss : 4.500578505652292, valid_loss : 4.236374060312907\n",
      "fold: 0, epoch: 13,                       train_loss : 4.433874538966587, valid_loss : 4.37526551882426\n",
      "fold: 0, epoch: 14,                       train_loss : 4.401279120218186, valid_loss : 3.9865015347798667\n",
      "fold: 0, epoch: 15,                       train_loss : 4.359054224831717, valid_loss : 4.010683139165242\n",
      "fold: 0, epoch: 16,                       train_loss : 4.306356032689412, valid_loss : 4.0171754360198975\n",
      "fold: 0, epoch: 17,                       train_loss : 4.313120773860386, valid_loss : 4.015375137329102\n",
      "fold: 0, epoch: 18,                       train_loss : 4.282067741666522, valid_loss : 3.795823256174723\n",
      "fold: 0, epoch: 19,                       train_loss : 4.269769316627865, valid_loss : 3.911834239959717\n",
      "fold: 1, epoch: 0,                       train_loss : 4.2544470855167935, valid_loss : 3.3917531172434487\n",
      "fold: 2, epoch: 0,                       train_loss : 4.211047036307199, valid_loss : 4.7143581708272295\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1574497904096335, valid_loss : 4.113958358764648\n",
      "fold: 4, epoch: 0,                       train_loss : 4.14768632253011, valid_loss : 5.012064139048259\n",
      "fold: 5, epoch: 0,                       train_loss : 4.2194193090711325, valid_loss : 4.070632537206014\n",
      "fold: 6, epoch: 0,                       train_loss : 4.107632648377192, valid_loss : 4.3385329246521\n",
      "fold: 7, epoch: 0,                       train_loss : 4.120785554250081, valid_loss : 4.497054735819499\n",
      "fold: 8, epoch: 0,                       train_loss : 4.1632438614254905, valid_loss : 3.8409996032714844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:26:13,905]\u001b[0m Trial 80 finished with value: 4.180231165885925 and parameters: {'num_layers': 6, 'hidden_size': 110, 'batch_size': 130, 'learning_rate': 0.008316634595731884}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.144026427041917, valid_loss : 4.027134815851848\n",
      "fold: 0, epoch: 0,                       train_loss : 5.986919403076172, valid_loss : 5.147506872812907\n",
      "fold: 0, epoch: 1,                       train_loss : 4.805539585295177, valid_loss : 3.860985199610392\n",
      "fold: 0, epoch: 2,                       train_loss : 4.187099774678548, valid_loss : 3.9786256154378257\n",
      "fold: 0, epoch: 3,                       train_loss : 4.160532588050479, valid_loss : 3.882960398991903\n",
      "fold: 0, epoch: 4,                       train_loss : 4.171213195437477, valid_loss : 3.549629290898641\n",
      "fold: 0, epoch: 5,                       train_loss : 4.160730566297259, valid_loss : 4.150307496388753\n",
      "fold: 0, epoch: 6,                       train_loss : 4.181663240705218, valid_loss : 3.7226248582204184\n",
      "fold: 0, epoch: 7,                       train_loss : 4.185805718104045, valid_loss : 3.9048475424448648\n",
      "fold: 0, epoch: 8,                       train_loss : 4.184397493089948, valid_loss : 3.634408871332804\n",
      "fold: 0, epoch: 9,                       train_loss : 4.182076806113834, valid_loss : 3.8568763732910156\n",
      "fold: 0, epoch: 10,                       train_loss : 4.182895013264248, valid_loss : 3.887317736943563\n",
      "fold: 0, epoch: 11,                       train_loss : 4.1937492574964255, valid_loss : 3.8599297205607095\n",
      "fold: 0, epoch: 12,                       train_loss : 4.19827127456665, valid_loss : 3.7663649717966714\n",
      "fold: 0, epoch: 13,                       train_loss : 4.182853664670672, valid_loss : 3.726545254389445\n",
      "fold: 1, epoch: 0,                       train_loss : 4.212721915472121, valid_loss : 3.755974849065145\n",
      "fold: 2, epoch: 0,                       train_loss : 4.143627530052548, valid_loss : 3.93531862894694\n",
      "fold: 3, epoch: 0,                       train_loss : 4.119447265352521, valid_loss : 4.376674811045329\n",
      "fold: 4, epoch: 0,                       train_loss : 4.076268968128023, valid_loss : 4.718938271204631\n",
      "fold: 5, epoch: 0,                       train_loss : 4.146518173671904, valid_loss : 3.797825892766317\n",
      "fold: 6, epoch: 0,                       train_loss : 4.07820741335551, valid_loss : 4.567535400390625\n",
      "fold: 7, epoch: 0,                       train_loss : 4.065954480852399, valid_loss : 4.526603062947591\n",
      "fold: 8, epoch: 0,                       train_loss : 4.125381401606968, valid_loss : 4.21971074740092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:26:23,787]\u001b[0m Trial 81 finished with value: 4.120515267054239 and parameters: {'num_layers': 6, 'hidden_size': 40, 'batch_size': 130, 'learning_rate': 0.0070243499134564425}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1852060953776045, valid_loss : 3.7569417158762612\n",
      "fold: 0, epoch: 0,                       train_loss : 6.024619296745017, valid_loss : 5.882177988688151\n",
      "fold: 0, epoch: 1,                       train_loss : 4.596344859511764, valid_loss : 4.406905333201091\n",
      "fold: 0, epoch: 2,                       train_loss : 4.112987332873875, valid_loss : 4.341354529062907\n",
      "fold: 0, epoch: 3,                       train_loss : 4.114928748872545, valid_loss : 4.3377760251363116\n",
      "fold: 0, epoch: 4,                       train_loss : 4.116715139812893, valid_loss : 4.34086799621582\n",
      "fold: 0, epoch: 5,                       train_loss : 4.108465380138821, valid_loss : 4.360805670420329\n",
      "fold: 0, epoch: 6,                       train_loss : 4.112158951935945, valid_loss : 4.3344340324401855\n",
      "fold: 0, epoch: 7,                       train_loss : 4.121673221941347, valid_loss : 4.349835236867269\n",
      "fold: 0, epoch: 8,                       train_loss : 4.114711019727919, valid_loss : 4.340022246042888\n",
      "fold: 0, epoch: 9,                       train_loss : 4.126123905181885, valid_loss : 4.3398105303446455\n",
      "fold: 0, epoch: 10,                       train_loss : 4.101428358643143, valid_loss : 4.339006662368774\n",
      "fold: 0, epoch: 11,                       train_loss : 4.126112637696443, valid_loss : 4.330417474110921\n",
      "fold: 0, epoch: 12,                       train_loss : 4.120158928411978, valid_loss : 4.341784954071045\n",
      "fold: 0, epoch: 13,                       train_loss : 4.109771030920523, valid_loss : 4.346069256464641\n",
      "fold: 0, epoch: 14,                       train_loss : 4.121378201025504, valid_loss : 4.34683624903361\n",
      "fold: 0, epoch: 15,                       train_loss : 4.106437188607675, valid_loss : 4.328901529312134\n",
      "fold: 0, epoch: 16,                       train_loss : 4.1148176193237305, valid_loss : 4.373486836751302\n",
      "fold: 0, epoch: 17,                       train_loss : 4.121543531064634, valid_loss : 4.3428886731465655\n",
      "fold: 1, epoch: 0,                       train_loss : 4.093762733318187, valid_loss : 4.474517345428467\n",
      "fold: 2, epoch: 0,                       train_loss : 4.075729114037973, valid_loss : 4.632065137227376\n",
      "fold: 3, epoch: 0,                       train_loss : 4.163892966729623, valid_loss : 3.8992406527201333\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1036002900865345, valid_loss : 4.334192196528117\n",
      "fold: 5, epoch: 0,                       train_loss : 4.1320719277417215, valid_loss : 4.28437066078186\n",
      "fold: 6, epoch: 0,                       train_loss : 4.213585526854904, valid_loss : 3.3715460300445557\n",
      "fold: 7, epoch: 0,                       train_loss : 4.124475302519621, valid_loss : 4.1132298310597735\n",
      "fold: 8, epoch: 0,                       train_loss : 4.132528331544664, valid_loss : 4.095285654067993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:26:38,047]\u001b[0m Trial 82 finished with value: 4.13829063574473 and parameters: {'num_layers': 6, 'hidden_size': 40, 'batch_size': 100, 'learning_rate': 0.0052703796479934215}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1574465345453335, valid_loss : 3.849557320276896\n",
      "fold: 0, epoch: 0,                       train_loss : 5.983227157592774, valid_loss : 4.812841256459554\n",
      "fold: 0, epoch: 1,                       train_loss : 5.526087057590485, valid_loss : 5.032541116078694\n",
      "fold: 0, epoch: 2,                       train_loss : 5.070353066921234, valid_loss : 4.408941666285197\n",
      "fold: 0, epoch: 3,                       train_loss : 4.129087495803833, valid_loss : 3.457204739252726\n",
      "fold: 0, epoch: 4,                       train_loss : 4.1170161128044125, valid_loss : 4.019055287043254\n",
      "fold: 0, epoch: 5,                       train_loss : 4.184487998485565, valid_loss : 3.5598040421803794\n",
      "fold: 0, epoch: 6,                       train_loss : 4.109856629371643, valid_loss : 3.4747132460276284\n",
      "fold: 0, epoch: 7,                       train_loss : 4.347540307044983, valid_loss : 3.0715713500976562\n",
      "fold: 0, epoch: 8,                       train_loss : 4.143001890182495, valid_loss : 3.3441282908121743\n",
      "fold: 0, epoch: 9,                       train_loss : 4.3160866618156435, valid_loss : 3.314420302708944\n",
      "fold: 0, epoch: 10,                       train_loss : 4.306249356269836, valid_loss : 3.031539519627889\n",
      "fold: 0, epoch: 11,                       train_loss : 4.116340553760528, valid_loss : 3.3056553999582925\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1426146030426025, valid_loss : 3.7058262825012207\n",
      "fold: 0, epoch: 13,                       train_loss : 4.360886216163635, valid_loss : 3.508319536844889\n",
      "fold: 0, epoch: 14,                       train_loss : 4.314408433437348, valid_loss : 3.9197911421457925\n",
      "fold: 0, epoch: 15,                       train_loss : 4.259848976135254, valid_loss : 3.3974925676981607\n",
      "fold: 1, epoch: 0,                       train_loss : 3.9600407123565673, valid_loss : 4.460052092870076\n",
      "fold: 2, epoch: 0,                       train_loss : 4.228374695777893, valid_loss : 4.279604911804199\n",
      "fold: 3, epoch: 0,                       train_loss : 4.22655109167099, valid_loss : 4.5139106909434\n",
      "fold: 4, epoch: 0,                       train_loss : 4.122904944419861, valid_loss : 5.0631171862284345\n",
      "fold: 5, epoch: 0,                       train_loss : 4.060248029232025, valid_loss : 3.5221146742502847\n",
      "fold: 6, epoch: 0,                       train_loss : 4.175387239456176, valid_loss : 4.061148722966512\n",
      "fold: 7, epoch: 0,                       train_loss : 4.041077208518982, valid_loss : 4.147629181543986\n",
      "fold: 8, epoch: 0,                       train_loss : 4.0777507543563845, valid_loss : 4.100321054458618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:26:51,471]\u001b[0m Trial 83 finished with value: 4.140808629989625 and parameters: {'num_layers': 6, 'hidden_size': 60, 'batch_size': 140, 'learning_rate': 0.004270995039104304}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1743255972862245, valid_loss : 4.22864826520284\n",
      "fold: 0, epoch: 0,                       train_loss : 6.072060770458645, valid_loss : 5.958089590072632\n",
      "fold: 0, epoch: 1,                       train_loss : 5.317890856001112, valid_loss : 5.049546003341675\n",
      "fold: 0, epoch: 2,                       train_loss : 4.306050883399116, valid_loss : 4.46775484085083\n",
      "fold: 0, epoch: 3,                       train_loss : 4.112987173928155, valid_loss : 4.401947736740112\n",
      "fold: 0, epoch: 4,                       train_loss : 4.102391401926677, valid_loss : 4.389773845672607\n",
      "fold: 0, epoch: 5,                       train_loss : 4.110335919592115, valid_loss : 4.390823006629944\n",
      "fold: 0, epoch: 6,                       train_loss : 4.1200729476081, valid_loss : 4.39871883392334\n",
      "fold: 0, epoch: 7,                       train_loss : 4.106093671586779, valid_loss : 4.396522283554077\n",
      "fold: 0, epoch: 8,                       train_loss : 4.111404829555088, valid_loss : 4.40022087097168\n",
      "fold: 0, epoch: 9,                       train_loss : 4.112519317203098, valid_loss : 4.4064308404922485\n",
      "fold: 0, epoch: 10,                       train_loss : 4.10882830619812, valid_loss : 4.392045021057129\n",
      "fold: 0, epoch: 11,                       train_loss : 4.1029571824603615, valid_loss : 4.401446104049683\n",
      "fold: 0, epoch: 12,                       train_loss : 4.108400344848633, valid_loss : 4.397129774093628\n",
      "fold: 0, epoch: 13,                       train_loss : 4.105240636401707, valid_loss : 4.396925926208496\n",
      "fold: 0, epoch: 14,                       train_loss : 4.103645059797499, valid_loss : 4.396873950958252\n",
      "fold: 0, epoch: 15,                       train_loss : 4.104596959220038, valid_loss : 4.392950773239136\n",
      "fold: 1, epoch: 0,                       train_loss : 4.183047188652886, valid_loss : 3.6814345121383667\n",
      "fold: 2, epoch: 0,                       train_loss : 4.174939446979099, valid_loss : 3.7794283628463745\n",
      "fold: 3, epoch: 0,                       train_loss : 4.100678337944879, valid_loss : 4.401941299438477\n",
      "fold: 4, epoch: 0,                       train_loss : 4.09512115849389, valid_loss : 4.5668511390686035\n",
      "fold: 5, epoch: 0,                       train_loss : 4.180330130789015, valid_loss : 3.6818255186080933\n",
      "fold: 6, epoch: 0,                       train_loss : 4.121316128306919, valid_loss : 4.395720720291138\n",
      "fold: 7, epoch: 0,                       train_loss : 4.08265835709042, valid_loss : 4.618444085121155\n",
      "fold: 8, epoch: 0,                       train_loss : 4.151065601242913, valid_loss : 4.007383227348328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:26:58,424]\u001b[0m Trial 84 finished with value: 4.141407752037049 and parameters: {'num_layers': 6, 'hidden_size': 30, 'batch_size': 150, 'learning_rate': 0.007903764536269271}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.153014434708489, valid_loss : 3.8912748098373413\n",
      "fold: 0, epoch: 0,                       train_loss : 5.820092905135382, valid_loss : 5.210666497548421\n",
      "fold: 0, epoch: 1,                       train_loss : 5.014560483750843, valid_loss : 4.265395402908325\n",
      "fold: 0, epoch: 2,                       train_loss : 4.159814255578177, valid_loss : 3.7931345303853354\n",
      "fold: 0, epoch: 3,                       train_loss : 4.1425809633164175, valid_loss : 3.972106138865153\n",
      "fold: 0, epoch: 4,                       train_loss : 4.165667806352888, valid_loss : 4.013565301895142\n",
      "fold: 0, epoch: 5,                       train_loss : 4.143901938483829, valid_loss : 3.796018441518148\n",
      "fold: 0, epoch: 6,                       train_loss : 4.16231217838469, valid_loss : 3.756176312764486\n",
      "fold: 0, epoch: 7,                       train_loss : 4.15171936580113, valid_loss : 4.144458929697673\n",
      "fold: 0, epoch: 8,                       train_loss : 4.1736631734030585, valid_loss : 4.082842111587524\n",
      "fold: 0, epoch: 9,                       train_loss : 4.185256424404326, valid_loss : 3.992894490559896\n",
      "fold: 0, epoch: 10,                       train_loss : 4.144873880204701, valid_loss : 3.7887304623921714\n",
      "fold: 0, epoch: 11,                       train_loss : 4.130956808725993, valid_loss : 4.246463696161906\n",
      "fold: 0, epoch: 12,                       train_loss : 4.152197326932635, valid_loss : 4.21588937441508\n",
      "fold: 0, epoch: 13,                       train_loss : 4.133669909976778, valid_loss : 4.044696648915608\n",
      "fold: 0, epoch: 14,                       train_loss : 4.130423557190668, valid_loss : 4.177106300989787\n",
      "fold: 1, epoch: 0,                       train_loss : 4.069349936076573, valid_loss : 4.426150878270467\n",
      "fold: 2, epoch: 0,                       train_loss : 4.149371101742699, valid_loss : 3.9169161319732666\n",
      "fold: 3, epoch: 0,                       train_loss : 4.053805373963856, valid_loss : 4.623818397521973\n",
      "fold: 4, epoch: 0,                       train_loss : 4.154844159171695, valid_loss : 3.8440445264180503\n",
      "fold: 5, epoch: 0,                       train_loss : 4.150315284729004, valid_loss : 4.076397339502971\n",
      "fold: 6, epoch: 0,                       train_loss : 4.156893230619884, valid_loss : 4.178550720214844\n",
      "fold: 7, epoch: 0,                       train_loss : 4.191808121544974, valid_loss : 3.8755374749501548\n",
      "fold: 8, epoch: 0,                       train_loss : 4.102711075828189, valid_loss : 4.300679286321004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:27:09,992]\u001b[0m Trial 85 finished with value: 4.059702356656393 and parameters: {'num_layers': 5, 'hidden_size': 50, 'batch_size': 130, 'learning_rate': 0.004002698752755843}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.212846369970412, valid_loss : 3.598752498626709\n",
      "fold: 0, epoch: 0,                       train_loss : 5.837181282043457, valid_loss : 5.199916362762451\n",
      "fold: 0, epoch: 1,                       train_loss : 5.171005576848984, valid_loss : 4.525504906972249\n",
      "fold: 0, epoch: 2,                       train_loss : 5.078982102870941, valid_loss : 3.9183973471323648\n",
      "fold: 0, epoch: 3,                       train_loss : 4.1159038066864015, valid_loss : 4.201863765716553\n",
      "fold: 0, epoch: 4,                       train_loss : 4.0906801462173465, valid_loss : 3.8203419049580893\n",
      "fold: 0, epoch: 5,                       train_loss : 4.009486746788025, valid_loss : 3.595667044321696\n",
      "fold: 0, epoch: 6,                       train_loss : 3.977895611524582, valid_loss : 3.6669719219207764\n",
      "fold: 0, epoch: 7,                       train_loss : 4.000605428218842, valid_loss : 3.679709037144979\n",
      "fold: 0, epoch: 8,                       train_loss : 4.116301965713501, valid_loss : 4.235033432642619\n",
      "fold: 0, epoch: 9,                       train_loss : 4.082042789459228, valid_loss : 4.386097272237142\n",
      "fold: 0, epoch: 10,                       train_loss : 4.159330189228058, valid_loss : 4.157598495483398\n",
      "fold: 0, epoch: 11,                       train_loss : 4.084051430225372, valid_loss : 4.343893369038899\n",
      "fold: 0, epoch: 12,                       train_loss : 4.10309556722641, valid_loss : 4.559470494588216\n",
      "fold: 0, epoch: 13,                       train_loss : 4.317747032642364, valid_loss : 3.866269826889038\n",
      "fold: 0, epoch: 14,                       train_loss : 4.2818138837814335, valid_loss : 4.09226655960083\n",
      "fold: 0, epoch: 15,                       train_loss : 4.0280568361282345, valid_loss : 3.754222313563029\n",
      "fold: 1, epoch: 0,                       train_loss : 4.293229866027832, valid_loss : 4.553210337956746\n",
      "fold: 2, epoch: 0,                       train_loss : 4.0075420379638675, valid_loss : 3.6074726581573486\n",
      "fold: 3, epoch: 0,                       train_loss : 3.995737671852112, valid_loss : 5.300617376963298\n",
      "fold: 4, epoch: 0,                       train_loss : 4.009934902191162, valid_loss : 4.895741144816081\n",
      "fold: 5, epoch: 0,                       train_loss : 4.107900857925415, valid_loss : 4.362380425135295\n",
      "fold: 6, epoch: 0,                       train_loss : 4.145457816123963, valid_loss : 3.05570650100708\n",
      "fold: 7, epoch: 0,                       train_loss : 4.033488869667053, valid_loss : 3.909040371576945\n",
      "fold: 8, epoch: 0,                       train_loss : 4.315176093578339, valid_loss : 3.785078843434652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:27:21,583]\u001b[0m Trial 86 finished with value: 4.0688987493515025 and parameters: {'num_layers': 2, 'hidden_size': 50, 'batch_size': 140, 'learning_rate': 0.009822933584757937}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.086032795906067, valid_loss : 3.624072790145874\n",
      "fold: 0, epoch: 0,                       train_loss : 6.305835694074631, valid_loss : 6.624709129333496\n",
      "fold: 0, epoch: 1,                       train_loss : 6.223975121974945, valid_loss : 6.535804986953735\n",
      "fold: 0, epoch: 2,                       train_loss : 6.145550191402435, valid_loss : 6.434784173965454\n",
      "fold: 0, epoch: 3,                       train_loss : 6.065587908029556, valid_loss : 6.298874616622925\n",
      "fold: 0, epoch: 4,                       train_loss : 5.94366055727005, valid_loss : 6.398299694061279\n",
      "fold: 0, epoch: 5,                       train_loss : 5.8718873262405396, valid_loss : 6.244097471237183\n",
      "fold: 0, epoch: 6,                       train_loss : 5.790708690881729, valid_loss : 6.181399822235107\n",
      "fold: 0, epoch: 7,                       train_loss : 5.719497382640839, valid_loss : 6.047837734222412\n",
      "fold: 0, epoch: 8,                       train_loss : 5.619996130466461, valid_loss : 5.96686577796936\n",
      "fold: 0, epoch: 9,                       train_loss : 5.550351411104202, valid_loss : 5.834530591964722\n",
      "fold: 0, epoch: 10,                       train_loss : 5.468532145023346, valid_loss : 5.9088428020477295\n",
      "fold: 0, epoch: 11,                       train_loss : 5.400712758302689, valid_loss : 5.798074007034302\n",
      "fold: 0, epoch: 12,                       train_loss : 5.351370394229889, valid_loss : 5.705453395843506\n",
      "fold: 0, epoch: 13,                       train_loss : 5.2946710884571075, valid_loss : 5.66437840461731\n",
      "fold: 0, epoch: 14,                       train_loss : 5.224271714687347, valid_loss : 5.511005878448486\n",
      "fold: 0, epoch: 15,                       train_loss : 5.177381664514542, valid_loss : 5.532100439071655\n",
      "fold: 0, epoch: 16,                       train_loss : 5.085685968399048, valid_loss : 5.490965366363525\n",
      "fold: 0, epoch: 17,                       train_loss : 5.063395380973816, valid_loss : 5.322005271911621\n",
      "fold: 0, epoch: 18,                       train_loss : 5.0239420384168625, valid_loss : 5.340301513671875\n",
      "fold: 0, epoch: 19,                       train_loss : 4.960908651351929, valid_loss : 5.283545970916748\n",
      "fold: 0, epoch: 20,                       train_loss : 4.891118511557579, valid_loss : 5.1968584060668945\n",
      "fold: 0, epoch: 21,                       train_loss : 4.8550751358270645, valid_loss : 5.146227598190308\n",
      "fold: 0, epoch: 22,                       train_loss : 4.799982666969299, valid_loss : 5.159705400466919\n",
      "fold: 0, epoch: 23,                       train_loss : 4.748894244432449, valid_loss : 5.051547050476074\n",
      "fold: 0, epoch: 24,                       train_loss : 4.720312297344208, valid_loss : 5.003478288650513\n",
      "fold: 0, epoch: 25,                       train_loss : 4.700405701994896, valid_loss : 5.045932054519653\n",
      "fold: 0, epoch: 26,                       train_loss : 4.6290602684021, valid_loss : 4.9319376945495605\n",
      "fold: 0, epoch: 27,                       train_loss : 4.624674692749977, valid_loss : 4.913711071014404\n",
      "fold: 0, epoch: 28,                       train_loss : 4.599884450435638, valid_loss : 4.877724647521973\n",
      "fold: 0, epoch: 29,                       train_loss : 4.555492863059044, valid_loss : 4.825835227966309\n",
      "fold: 0, epoch: 30,                       train_loss : 4.532219618558884, valid_loss : 4.836636543273926\n",
      "fold: 0, epoch: 31,                       train_loss : 4.510458156466484, valid_loss : 4.836733341217041\n",
      "fold: 0, epoch: 32,                       train_loss : 4.482953175902367, valid_loss : 4.829512357711792\n",
      "fold: 0, epoch: 33,                       train_loss : 4.461164876818657, valid_loss : 4.7944700717926025\n",
      "fold: 0, epoch: 34,                       train_loss : 4.448465213179588, valid_loss : 4.851555109024048\n",
      "fold: 0, epoch: 35,                       train_loss : 4.42103511095047, valid_loss : 4.664422035217285\n",
      "fold: 0, epoch: 36,                       train_loss : 4.384494125843048, valid_loss : 4.771725654602051\n",
      "fold: 1, epoch: 0,                       train_loss : 4.425144776701927, valid_loss : 4.129315137863159\n",
      "fold: 2, epoch: 0,                       train_loss : 4.473550796508789, valid_loss : 3.5687382221221924\n",
      "fold: 3, epoch: 0,                       train_loss : 4.38273261487484, valid_loss : 4.090048670768738\n",
      "fold: 4, epoch: 0,                       train_loss : 4.433664858341217, valid_loss : 3.7902164459228516\n",
      "fold: 5, epoch: 0,                       train_loss : 4.309158474206924, valid_loss : 4.3636696338653564\n",
      "fold: 6, epoch: 0,                       train_loss : 4.333055466413498, valid_loss : 4.306925296783447\n",
      "fold: 7, epoch: 0,                       train_loss : 4.220970809459686, valid_loss : 4.835082769393921\n",
      "fold: 8, epoch: 0,                       train_loss : 4.3449480682611465, valid_loss : 4.011925220489502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:27:30,477]\u001b[0m Trial 87 finished with value: 4.303071701526642 and parameters: {'num_layers': 3, 'hidden_size': 20, 'batch_size': 170, 'learning_rate': 0.004913586265723232}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.174160376191139, valid_loss : 5.270373582839966\n",
      "fold: 0, epoch: 0,                       train_loss : 5.9147439832272735, valid_loss : 5.6381198565165205\n",
      "fold: 0, epoch: 1,                       train_loss : 5.6526070263074795, valid_loss : 5.477344671885173\n",
      "fold: 0, epoch: 2,                       train_loss : 5.467850788779881, valid_loss : 4.955217043558757\n",
      "fold: 0, epoch: 3,                       train_loss : 5.186799132305643, valid_loss : 4.760068893432617\n",
      "fold: 0, epoch: 4,                       train_loss : 4.965835063353829, valid_loss : 4.625830332438151\n",
      "fold: 0, epoch: 5,                       train_loss : 4.7753938591998555, valid_loss : 4.457997481028239\n",
      "fold: 0, epoch: 6,                       train_loss : 4.698333522547847, valid_loss : 4.4591170946757\n",
      "fold: 0, epoch: 7,                       train_loss : 4.568440250728441, valid_loss : 4.283857981363933\n",
      "fold: 0, epoch: 8,                       train_loss : 4.505808933921482, valid_loss : 4.284237225850423\n",
      "fold: 0, epoch: 9,                       train_loss : 4.474543540374093, valid_loss : 4.011412461598714\n",
      "fold: 0, epoch: 10,                       train_loss : 4.339515281760174, valid_loss : 4.131199200948079\n",
      "fold: 0, epoch: 11,                       train_loss : 4.2927161092343535, valid_loss : 4.055680513381958\n",
      "fold: 0, epoch: 12,                       train_loss : 4.418637679970783, valid_loss : 3.973394234975179\n",
      "fold: 0, epoch: 13,                       train_loss : 4.240435278933981, valid_loss : 3.9516164461771646\n",
      "fold: 0, epoch: 14,                       train_loss : 4.326168723728346, valid_loss : 3.9744770526885986\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1952968473019805, valid_loss : 3.925255060195923\n",
      "fold: 0, epoch: 16,                       train_loss : 4.2168921076733135, valid_loss : 3.969390074412028\n",
      "fold: 0, epoch: 17,                       train_loss : 4.210839427035788, valid_loss : 3.9874836603800454\n",
      "fold: 0, epoch: 18,                       train_loss : 4.233562023743339, valid_loss : 3.8564466635386148\n",
      "fold: 0, epoch: 19,                       train_loss : 4.2686549373295, valid_loss : 3.842663367589315\n",
      "fold: 0, epoch: 20,                       train_loss : 4.193109232446422, valid_loss : 3.8653056621551514\n",
      "fold: 0, epoch: 21,                       train_loss : 4.141427102296249, valid_loss : 3.7473286787668862\n",
      "fold: 0, epoch: 22,                       train_loss : 4.178063620691714, valid_loss : 4.049536307652791\n",
      "fold: 0, epoch: 23,                       train_loss : 4.1499750095865, valid_loss : 3.7553861141204834\n",
      "fold: 0, epoch: 24,                       train_loss : 4.218874661818795, valid_loss : 3.98831574122111\n",
      "fold: 1, epoch: 0,                       train_loss : 4.18130838352701, valid_loss : 3.641124884287516\n",
      "fold: 2, epoch: 0,                       train_loss : 4.1650290696517285, valid_loss : 3.6429443359375\n",
      "fold: 3, epoch: 0,                       train_loss : 4.100010498710301, valid_loss : 3.9743666648864746\n",
      "fold: 4, epoch: 0,                       train_loss : 4.122807274694028, valid_loss : 4.198533296585083\n",
      "fold: 5, epoch: 0,                       train_loss : 4.152755706206612, valid_loss : 3.941769599914551\n",
      "fold: 6, epoch: 0,                       train_loss : 4.069455955339515, valid_loss : 4.671866734822591\n",
      "fold: 7, epoch: 0,                       train_loss : 4.167204100152721, valid_loss : 4.582622210184733\n",
      "fold: 8, epoch: 0,                       train_loss : 4.0845238540483555, valid_loss : 4.216041882832845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:27:43,081]\u001b[0m Trial 88 finished with value: 4.109265120824178 and parameters: {'num_layers': 5, 'hidden_size': 30, 'batch_size': 120, 'learning_rate': 0.011125038625054538}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.0295203354047695, valid_loss : 4.476052920023601\n",
      "fold: 0, epoch: 0,                       train_loss : 6.1856658988528785, valid_loss : 5.966010808944702\n",
      "fold: 0, epoch: 1,                       train_loss : 5.720754967795478, valid_loss : 5.5248024463653564\n",
      "fold: 0, epoch: 2,                       train_loss : 5.140248537063599, valid_loss : 4.651539921760559\n",
      "fold: 0, epoch: 3,                       train_loss : 4.263251900672913, valid_loss : 4.0813223123550415\n",
      "fold: 0, epoch: 4,                       train_loss : 4.158274465137058, valid_loss : 4.078583359718323\n",
      "fold: 0, epoch: 5,                       train_loss : 4.144144442346361, valid_loss : 4.063196778297424\n",
      "fold: 0, epoch: 6,                       train_loss : 4.133126391304864, valid_loss : 4.075782775878906\n",
      "fold: 0, epoch: 7,                       train_loss : 4.140775442123413, valid_loss : 4.070684432983398\n",
      "fold: 0, epoch: 8,                       train_loss : 4.153871615727742, valid_loss : 4.069413423538208\n",
      "fold: 0, epoch: 9,                       train_loss : 4.134811706013149, valid_loss : 4.075034737586975\n",
      "fold: 0, epoch: 10,                       train_loss : 4.13157762421502, valid_loss : 4.07253885269165\n",
      "fold: 0, epoch: 11,                       train_loss : 4.143888579474555, valid_loss : 4.0749863386154175\n",
      "fold: 0, epoch: 12,                       train_loss : 4.147201008266872, valid_loss : 4.074000358581543\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1457305616802635, valid_loss : 4.070222616195679\n",
      "fold: 0, epoch: 14,                       train_loss : 4.138026237487793, valid_loss : 4.07909631729126\n",
      "fold: 0, epoch: 15,                       train_loss : 4.136376963721381, valid_loss : 4.075319290161133\n",
      "fold: 0, epoch: 16,                       train_loss : 4.142555024888781, valid_loss : 4.080796480178833\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1298046641879615, valid_loss : 4.084673762321472\n",
      "fold: 2, epoch: 0,                       train_loss : 4.165068997277154, valid_loss : 3.858268141746521\n",
      "fold: 3, epoch: 0,                       train_loss : 4.12925570540958, valid_loss : 4.282455325126648\n",
      "fold: 4, epoch: 0,                       train_loss : 4.063418414857653, valid_loss : 4.726722002029419\n",
      "fold: 5, epoch: 0,                       train_loss : 4.156260503662957, valid_loss : 3.9400582313537598\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1381420559353295, valid_loss : 4.084567546844482\n",
      "fold: 7, epoch: 0,                       train_loss : 4.126080380545722, valid_loss : 4.258258938789368\n",
      "fold: 8, epoch: 0,                       train_loss : 4.135333961910671, valid_loss : 4.137202858924866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:27:59,091]\u001b[0m Trial 89 finished with value: 4.137462592124939 and parameters: {'num_layers': 6, 'hidden_size': 90, 'batch_size': 150, 'learning_rate': 0.006494624861418424}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.161708235740662, valid_loss : 3.9392223358154297\n",
      "fold: 0, epoch: 0,                       train_loss : 5.810085072236903, valid_loss : 5.959491968154907\n",
      "fold: 0, epoch: 1,                       train_loss : 5.623413057888255, valid_loss : 5.717066764831543\n",
      "fold: 0, epoch: 2,                       train_loss : 5.389198415419635, valid_loss : 5.429286956787109\n",
      "fold: 0, epoch: 3,                       train_loss : 4.8889423678903015, valid_loss : 4.714293003082275\n",
      "fold: 0, epoch: 4,                       train_loss : 4.217490967582254, valid_loss : 4.3083038330078125\n",
      "fold: 0, epoch: 5,                       train_loss : 4.138609759947833, valid_loss : 4.27881121635437\n",
      "fold: 0, epoch: 6,                       train_loss : 4.137180749107809, valid_loss : 4.2718682289123535\n",
      "fold: 0, epoch: 7,                       train_loss : 4.140130772310145, valid_loss : 4.266659498214722\n",
      "fold: 0, epoch: 8,                       train_loss : 4.153906864278457, valid_loss : 4.277164459228516\n",
      "fold: 0, epoch: 9,                       train_loss : 4.126628609264598, valid_loss : 4.212925314903259\n",
      "fold: 0, epoch: 10,                       train_loss : 4.122489157844992, valid_loss : 4.252694606781006\n",
      "fold: 0, epoch: 11,                       train_loss : 4.112477470846737, valid_loss : 4.263528347015381\n",
      "fold: 0, epoch: 12,                       train_loss : 4.12331363734077, valid_loss : 4.245715856552124\n",
      "fold: 0, epoch: 13,                       train_loss : 4.11930263743681, valid_loss : 4.24999475479126\n",
      "fold: 0, epoch: 14,                       train_loss : 4.123300748712876, valid_loss : 4.313076138496399\n",
      "fold: 0, epoch: 15,                       train_loss : 4.128046751022339, valid_loss : 4.243107318878174\n",
      "fold: 0, epoch: 16,                       train_loss : 4.1225362244774315, valid_loss : 4.276638031005859\n",
      "fold: 0, epoch: 17,                       train_loss : 4.121681493871352, valid_loss : 4.256924867630005\n",
      "fold: 0, epoch: 18,                       train_loss : 4.132083345861996, valid_loss : 4.2441253662109375\n",
      "fold: 0, epoch: 19,                       train_loss : 4.114242048824535, valid_loss : 4.292114973068237\n",
      "fold: 1, epoch: 0,                       train_loss : 4.107972285326789, valid_loss : 4.432683706283569\n",
      "fold: 2, epoch: 0,                       train_loss : 4.239114312564626, valid_loss : 3.385353207588196\n",
      "fold: 3, epoch: 0,                       train_loss : 4.205261076197905, valid_loss : 3.408676862716675\n",
      "fold: 4, epoch: 0,                       train_loss : 4.175805582719691, valid_loss : 3.8492929935455322\n",
      "fold: 5, epoch: 0,                       train_loss : 4.145068098517025, valid_loss : 4.078078866004944\n",
      "fold: 6, epoch: 0,                       train_loss : 4.078522569992963, valid_loss : 4.644709825515747\n",
      "fold: 7, epoch: 0,                       train_loss : 4.070393197676715, valid_loss : 4.827960014343262\n",
      "fold: 8, epoch: 0,                       train_loss : 4.120844125747681, valid_loss : 4.128999948501587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:28:09,114]\u001b[0m Trial 90 finished with value: 4.138224923610688 and parameters: {'num_layers': 4, 'hidden_size': 40, 'batch_size': 160, 'learning_rate': 0.0025721672429163327}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.090431620092953, valid_loss : 4.413568496704102\n",
      "fold: 0, epoch: 0,                       train_loss : 5.7291253735037415, valid_loss : 5.711936593055725\n",
      "fold: 0, epoch: 1,                       train_loss : 5.632824000190286, valid_loss : 5.499777317047119\n",
      "fold: 0, epoch: 2,                       train_loss : 5.538534059244044, valid_loss : 5.383613348007202\n",
      "fold: 0, epoch: 3,                       train_loss : 5.422578657374663, valid_loss : 5.329617142677307\n",
      "fold: 0, epoch: 4,                       train_loss : 5.310577154159546, valid_loss : 5.275762915611267\n",
      "fold: 0, epoch: 5,                       train_loss : 5.227831447825713, valid_loss : 5.121432065963745\n",
      "fold: 0, epoch: 6,                       train_loss : 5.2033746873631195, valid_loss : 5.00405216217041\n",
      "fold: 0, epoch: 7,                       train_loss : 5.075654703028062, valid_loss : 5.038678050041199\n",
      "fold: 0, epoch: 8,                       train_loss : 4.985563825158512, valid_loss : 4.836994409561157\n",
      "fold: 0, epoch: 9,                       train_loss : 4.956538235439973, valid_loss : 4.868214011192322\n",
      "fold: 0, epoch: 10,                       train_loss : 4.861094327533946, valid_loss : 4.803681492805481\n",
      "fold: 0, epoch: 11,                       train_loss : 4.811835618580089, valid_loss : 4.68129563331604\n",
      "fold: 0, epoch: 12,                       train_loss : 4.723121523857117, valid_loss : 4.642114520072937\n",
      "fold: 0, epoch: 13,                       train_loss : 4.687322826946483, valid_loss : 4.60930597782135\n",
      "fold: 0, epoch: 14,                       train_loss : 4.632988649256089, valid_loss : 4.516858875751495\n",
      "fold: 0, epoch: 15,                       train_loss : 4.590531959253199, valid_loss : 4.5541534423828125\n",
      "fold: 0, epoch: 16,                       train_loss : 4.559643913717831, valid_loss : 4.40030038356781\n",
      "fold: 0, epoch: 17,                       train_loss : 4.503933114164016, valid_loss : 4.477228403091431\n",
      "fold: 0, epoch: 18,                       train_loss : 4.494159453055438, valid_loss : 4.475613176822662\n",
      "fold: 0, epoch: 19,                       train_loss : 4.453286395353429, valid_loss : 4.423535704612732\n",
      "fold: 0, epoch: 20,                       train_loss : 4.439649680081536, valid_loss : 4.308766663074493\n",
      "fold: 0, epoch: 21,                       train_loss : 4.405477671062245, valid_loss : 4.281195402145386\n",
      "fold: 0, epoch: 22,                       train_loss : 4.357884757659015, valid_loss : 4.24356609582901\n",
      "fold: 0, epoch: 23,                       train_loss : 4.301251895287457, valid_loss : 4.193993806838989\n",
      "fold: 0, epoch: 24,                       train_loss : 4.360730108092813, valid_loss : 4.259076237678528\n",
      "fold: 0, epoch: 25,                       train_loss : 4.300105831202338, valid_loss : 4.261521279811859\n",
      "fold: 0, epoch: 26,                       train_loss : 4.286839976030238, valid_loss : 4.314259767532349\n",
      "fold: 0, epoch: 27,                       train_loss : 4.319082091836369, valid_loss : 4.147497892379761\n",
      "fold: 0, epoch: 28,                       train_loss : 4.2765687914455635, valid_loss : 4.173550486564636\n",
      "fold: 0, epoch: 29,                       train_loss : 4.2898000969606285, valid_loss : 4.042483925819397\n",
      "fold: 0, epoch: 30,                       train_loss : 4.23522821594687, valid_loss : 4.138273894786835\n",
      "fold: 1, epoch: 0,                       train_loss : 4.24526840097764, valid_loss : 3.7962708473205566\n",
      "fold: 2, epoch: 0,                       train_loss : 4.245789527893066, valid_loss : 3.981588065624237\n",
      "fold: 3, epoch: 0,                       train_loss : 4.099872399778927, valid_loss : 4.870565056800842\n",
      "fold: 4, epoch: 0,                       train_loss : 4.25144027261173, valid_loss : 3.937470555305481\n",
      "fold: 5, epoch: 0,                       train_loss : 4.1352322592454795, valid_loss : 4.729661762714386\n",
      "fold: 6, epoch: 0,                       train_loss : 4.195246170548832, valid_loss : 3.876019060611725\n",
      "fold: 7, epoch: 0,                       train_loss : 4.1643111144795135, valid_loss : 4.101252794265747\n",
      "fold: 8, epoch: 0,                       train_loss : 4.257930019322564, valid_loss : 3.5091171264648438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:28:39,296]\u001b[0m Trial 91 finished with value: 4.191454702615738 and parameters: {'num_layers': 3, 'hidden_size': 50, 'batch_size': 80, 'learning_rate': 0.00319318586717011}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.090678376310012, valid_loss : 5.070117831230164\n",
      "fold: 0, epoch: 0,                       train_loss : 5.892647329966227, valid_loss : 5.527099847793579\n",
      "fold: 0, epoch: 1,                       train_loss : 5.39903138478597, valid_loss : 5.223760962486267\n",
      "fold: 0, epoch: 2,                       train_loss : 4.748058954874675, valid_loss : 4.388011634349823\n",
      "fold: 0, epoch: 3,                       train_loss : 4.289604663848877, valid_loss : 3.8935303688049316\n",
      "fold: 0, epoch: 4,                       train_loss : 4.14446402390798, valid_loss : 3.8111847639083862\n",
      "fold: 0, epoch: 5,                       train_loss : 4.144687207539876, valid_loss : 3.7973941564559937\n",
      "fold: 0, epoch: 6,                       train_loss : 4.137634054819743, valid_loss : 4.587922692298889\n",
      "fold: 0, epoch: 7,                       train_loss : 4.131806635856629, valid_loss : 3.9447646141052246\n",
      "fold: 0, epoch: 8,                       train_loss : 4.142062544822693, valid_loss : 3.723363757133484\n",
      "fold: 0, epoch: 9,                       train_loss : 4.152165500322978, valid_loss : 3.967935562133789\n",
      "fold: 0, epoch: 10,                       train_loss : 4.142619768778483, valid_loss : 4.039292931556702\n",
      "fold: 0, epoch: 11,                       train_loss : 4.151855007807414, valid_loss : 3.948818862438202\n",
      "fold: 0, epoch: 12,                       train_loss : 4.137653946876526, valid_loss : 3.9866288900375366\n",
      "fold: 0, epoch: 13,                       train_loss : 4.130585614840189, valid_loss : 4.02579003572464\n",
      "fold: 0, epoch: 14,                       train_loss : 4.167668318748474, valid_loss : 3.9808319807052612\n",
      "fold: 0, epoch: 15,                       train_loss : 4.137241609891256, valid_loss : 4.0506396889686584\n",
      "fold: 0, epoch: 16,                       train_loss : 4.148816235860189, valid_loss : 3.75509774684906\n",
      "fold: 0, epoch: 17,                       train_loss : 4.1516864935557045, valid_loss : 3.9172486066818237\n",
      "fold: 1, epoch: 0,                       train_loss : 4.133503333727519, valid_loss : 4.367002248764038\n",
      "fold: 2, epoch: 0,                       train_loss : 4.154167032241821, valid_loss : 3.9688076972961426\n",
      "fold: 3, epoch: 0,                       train_loss : 4.081192000706991, valid_loss : 4.392145037651062\n",
      "fold: 4, epoch: 0,                       train_loss : 4.122017645835877, valid_loss : 4.267788231372833\n",
      "fold: 5, epoch: 0,                       train_loss : 4.14774899482727, valid_loss : 4.275797784328461\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1697252750396725, valid_loss : 3.672336995601654\n",
      "fold: 7, epoch: 0,                       train_loss : 4.1430145343144735, valid_loss : 4.089133679866791\n",
      "fold: 8, epoch: 0,                       train_loss : 4.208693703015645, valid_loss : 3.383137583732605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:29:00,306]\u001b[0m Trial 92 finished with value: 4.0795354545116425 and parameters: {'num_layers': 3, 'hidden_size': 60, 'batch_size': 90, 'learning_rate': 0.0058089337652961395}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.086898771921794, valid_loss : 4.655841529369354\n",
      "fold: 0, epoch: 0,                       train_loss : 5.685225658416748, valid_loss : 6.298693497975667\n",
      "fold: 0, epoch: 1,                       train_loss : 5.266227493286133, valid_loss : 5.7487359046936035\n",
      "fold: 0, epoch: 2,                       train_loss : 4.888867444992066, valid_loss : 5.477972189585368\n",
      "fold: 0, epoch: 3,                       train_loss : 4.359960403442383, valid_loss : 4.788015127182007\n",
      "fold: 0, epoch: 4,                       train_loss : 4.124817733764648, valid_loss : 4.801088809967041\n",
      "fold: 0, epoch: 5,                       train_loss : 4.06239577293396, valid_loss : 4.660299460093181\n",
      "fold: 0, epoch: 6,                       train_loss : 4.113286256790161, valid_loss : 4.858091592788696\n",
      "fold: 0, epoch: 7,                       train_loss : 4.110519599914551, valid_loss : 4.666081269582112\n",
      "fold: 0, epoch: 8,                       train_loss : 4.0676724815368654, valid_loss : 4.6743292808532715\n",
      "fold: 0, epoch: 9,                       train_loss : 4.072256555557251, valid_loss : 4.760807832082112\n",
      "fold: 0, epoch: 10,                       train_loss : 4.0639575099945064, valid_loss : 4.66727876663208\n",
      "fold: 0, epoch: 11,                       train_loss : 4.038944568634033, valid_loss : 4.7435611089070635\n",
      "fold: 0, epoch: 12,                       train_loss : 4.114419422149658, valid_loss : 4.692830562591553\n",
      "fold: 0, epoch: 13,                       train_loss : 4.033491516113282, valid_loss : 4.706791241963704\n",
      "fold: 0, epoch: 14,                       train_loss : 4.081923971176147, valid_loss : 4.826271454493205\n",
      "fold: 0, epoch: 15,                       train_loss : 4.068325662612915, valid_loss : 4.644950071970622\n",
      "fold: 0, epoch: 16,                       train_loss : 4.073291034698486, valid_loss : 4.647183418273926\n",
      "fold: 1, epoch: 0,                       train_loss : 4.138197317123413, valid_loss : 4.018656253814697\n",
      "fold: 2, epoch: 0,                       train_loss : 4.220430097579956, valid_loss : 3.8834516207377114\n",
      "fold: 3, epoch: 0,                       train_loss : 4.128956718444824, valid_loss : 3.789271593093872\n",
      "fold: 4, epoch: 0,                       train_loss : 4.126226739883423, valid_loss : 3.9461748600006104\n",
      "fold: 5, epoch: 0,                       train_loss : 4.245954322814941, valid_loss : 4.0586897532145185\n",
      "fold: 6, epoch: 0,                       train_loss : 4.10205904006958, valid_loss : 4.203944126764934\n",
      "fold: 7, epoch: 0,                       train_loss : 4.1065285205841064, valid_loss : 4.024041652679443\n",
      "fold: 8, epoch: 0,                       train_loss : 4.091091432571411, valid_loss : 4.201685349146525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:29:18,969]\u001b[0m Trial 93 finished with value: 4.12901672522227 and parameters: {'num_layers': 2, 'hidden_size': 70, 'batch_size': 110, 'learning_rate': 0.003791900811648478}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.049273309707641, valid_loss : 4.519301970799764\n",
      "fold: 0, epoch: 0,                       train_loss : 6.297641118367513, valid_loss : 5.7305908203125\n",
      "fold: 0, epoch: 1,                       train_loss : 5.663382085164388, valid_loss : 4.911908388137817\n",
      "fold: 0, epoch: 2,                       train_loss : 5.066017436981201, valid_loss : 4.001609265804291\n",
      "fold: 0, epoch: 3,                       train_loss : 4.541432452201843, valid_loss : 3.9925214052200317\n",
      "fold: 0, epoch: 4,                       train_loss : 4.2929755846659345, valid_loss : 3.8319444060325623\n",
      "fold: 0, epoch: 5,                       train_loss : 4.194789258639018, valid_loss : 3.7720726132392883\n",
      "fold: 0, epoch: 6,                       train_loss : 4.176995650927226, valid_loss : 3.8823219537734985\n",
      "fold: 0, epoch: 7,                       train_loss : 4.182452686627706, valid_loss : 3.60041743516922\n",
      "fold: 0, epoch: 8,                       train_loss : 4.1868987560272215, valid_loss : 3.718365490436554\n",
      "fold: 0, epoch: 9,                       train_loss : 4.181319006284078, valid_loss : 3.897565186023712\n",
      "fold: 0, epoch: 10,                       train_loss : 4.175358366966248, valid_loss : 3.7524114847183228\n",
      "fold: 0, epoch: 11,                       train_loss : 4.2040825366973875, valid_loss : 3.690447509288788\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1692585945129395, valid_loss : 4.105193555355072\n",
      "fold: 0, epoch: 13,                       train_loss : 4.171217672030131, valid_loss : 3.5812641978263855\n",
      "fold: 0, epoch: 14,                       train_loss : 4.181492662429809, valid_loss : 3.472336530685425\n",
      "fold: 0, epoch: 15,                       train_loss : 4.186935178438822, valid_loss : 3.8582486510276794\n",
      "fold: 0, epoch: 16,                       train_loss : 4.187584273020426, valid_loss : 3.5874162316322327\n",
      "fold: 0, epoch: 17,                       train_loss : 4.18912103176117, valid_loss : 3.676985800266266\n",
      "fold: 0, epoch: 18,                       train_loss : 4.185785015424092, valid_loss : 3.718309223651886\n",
      "fold: 0, epoch: 19,                       train_loss : 4.178065093358358, valid_loss : 3.521296203136444\n",
      "fold: 1, epoch: 0,                       train_loss : 4.174069023132324, valid_loss : 3.724592864513397\n",
      "fold: 2, epoch: 0,                       train_loss : 4.117417852083842, valid_loss : 3.960430085659027\n",
      "fold: 3, epoch: 0,                       train_loss : 4.099344404538472, valid_loss : 4.495203614234924\n",
      "fold: 4, epoch: 0,                       train_loss : 4.095194045702616, valid_loss : 4.091628074645996\n",
      "fold: 5, epoch: 0,                       train_loss : 4.090576434135437, valid_loss : 4.4663039445877075\n",
      "fold: 6, epoch: 0,                       train_loss : 4.135963384310404, valid_loss : 4.027118980884552\n",
      "fold: 7, epoch: 0,                       train_loss : 4.134751168886821, valid_loss : 4.019419312477112\n",
      "fold: 8, epoch: 0,                       train_loss : 4.161911916732788, valid_loss : 3.6945585012435913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:29:54,381]\u001b[0m Trial 94 finished with value: 3.9851562440395356 and parameters: {'num_layers': 3, 'hidden_size': 110, 'batch_size': 90, 'learning_rate': 0.007653446609133344}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1545026461283365, valid_loss : 3.899970531463623\n",
      "fold: 0, epoch: 0,                       train_loss : 5.739919241736917, valid_loss : 4.686999976634979\n",
      "fold: 0, epoch: 1,                       train_loss : 4.13886534466463, valid_loss : 4.559353828430176\n",
      "fold: 0, epoch: 2,                       train_loss : 4.194872442413779, valid_loss : 4.479845225811005\n",
      "fold: 0, epoch: 3,                       train_loss : 4.089186864740708, valid_loss : 4.497994840145111\n",
      "fold: 0, epoch: 4,                       train_loss : 4.1252009237513825, valid_loss : 4.43851363658905\n",
      "fold: 0, epoch: 5,                       train_loss : 4.0797986633637375, valid_loss : 4.467517077922821\n",
      "fold: 0, epoch: 6,                       train_loss : 4.119514114716473, valid_loss : 4.493333101272583\n",
      "fold: 0, epoch: 7,                       train_loss : 4.100088056396036, valid_loss : 4.48978853225708\n",
      "fold: 0, epoch: 8,                       train_loss : 4.114329856984756, valid_loss : 4.4319692850112915\n",
      "fold: 0, epoch: 9,                       train_loss : 4.128207417095409, valid_loss : 4.54504257440567\n",
      "fold: 0, epoch: 10,                       train_loss : 4.116190812166999, valid_loss : 4.494387447834015\n",
      "fold: 0, epoch: 11,                       train_loss : 4.121877291623284, valid_loss : 4.399087071418762\n",
      "fold: 0, epoch: 12,                       train_loss : 4.11078167662901, valid_loss : 4.596542716026306\n",
      "fold: 0, epoch: 13,                       train_loss : 4.114651147057028, valid_loss : 4.429268658161163\n",
      "fold: 0, epoch: 14,                       train_loss : 4.1071235362221215, valid_loss : 4.502821385860443\n",
      "fold: 0, epoch: 15,                       train_loss : 4.0967653218437645, valid_loss : 4.435329556465149\n",
      "fold: 0, epoch: 16,                       train_loss : 4.152836427969091, valid_loss : 4.439829170703888\n",
      "fold: 1, epoch: 0,                       train_loss : 4.250829801839941, valid_loss : 3.608546733856201\n",
      "fold: 2, epoch: 0,                       train_loss : 4.157046486349667, valid_loss : 4.053396105766296\n",
      "fold: 3, epoch: 0,                       train_loss : 4.118260376593646, valid_loss : 4.260295331478119\n",
      "fold: 4, epoch: 0,                       train_loss : 4.10332190990448, valid_loss : 4.3048887848854065\n",
      "fold: 5, epoch: 0,                       train_loss : 4.140607392086702, valid_loss : 4.009401023387909\n",
      "fold: 6, epoch: 0,                       train_loss : 4.13619736362906, valid_loss : 4.013727843761444\n",
      "fold: 7, epoch: 0,                       train_loss : 4.172324552255518, valid_loss : 4.03792679309845\n",
      "fold: 8, epoch: 0,                       train_loss : 4.120287193971522, valid_loss : 4.0607553124427795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:30:26,824]\u001b[0m Trial 95 finished with value: 4.134958386421204 and parameters: {'num_layers': 6, 'hidden_size': 100, 'batch_size': 80, 'learning_rate': 0.012421848516903094}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.132113589959986, valid_loss : 4.601558864116669\n",
      "fold: 0, epoch: 0,                       train_loss : 6.156791877746582, valid_loss : 5.4613010088602705\n",
      "fold: 0, epoch: 1,                       train_loss : 5.655494427680969, valid_loss : 5.481587092081706\n",
      "fold: 0, epoch: 2,                       train_loss : 5.229111647605896, valid_loss : 4.803486029307048\n",
      "fold: 0, epoch: 3,                       train_loss : 4.710909450054169, valid_loss : 4.1607399781545\n",
      "fold: 0, epoch: 4,                       train_loss : 4.179962229728699, valid_loss : 4.552481094996135\n",
      "fold: 0, epoch: 5,                       train_loss : 3.995331424474716, valid_loss : 3.735220193862915\n",
      "fold: 0, epoch: 6,                       train_loss : 4.20349338054657, valid_loss : 3.5720993677775064\n",
      "fold: 0, epoch: 7,                       train_loss : 4.02472048997879, valid_loss : 4.79246973991394\n",
      "fold: 0, epoch: 8,                       train_loss : 4.412253141403198, valid_loss : 3.9391531944274902\n",
      "fold: 0, epoch: 9,                       train_loss : 4.159258842468262, valid_loss : 4.118516763051351\n",
      "fold: 0, epoch: 10,                       train_loss : 4.292649936676026, valid_loss : 4.754515568415324\n",
      "fold: 0, epoch: 11,                       train_loss : 4.138993895053863, valid_loss : 3.825854778289795\n",
      "fold: 0, epoch: 12,                       train_loss : 4.259972107410431, valid_loss : 3.7170477708180747\n",
      "fold: 0, epoch: 13,                       train_loss : 4.07854642868042, valid_loss : 4.130545298258464\n",
      "fold: 0, epoch: 14,                       train_loss : 4.3854567289352415, valid_loss : 3.8414023717244468\n",
      "fold: 0, epoch: 15,                       train_loss : 4.111419069766998, valid_loss : 3.7604339122772217\n",
      "fold: 1, epoch: 0,                       train_loss : 3.9661089420318603, valid_loss : 3.733417352040609\n",
      "fold: 2, epoch: 0,                       train_loss : 4.269856643676758, valid_loss : 3.6497864723205566\n",
      "fold: 3, epoch: 0,                       train_loss : 4.128900635242462, valid_loss : 4.016575972239177\n",
      "fold: 4, epoch: 0,                       train_loss : 4.08636189699173, valid_loss : 3.4762489795684814\n",
      "fold: 5, epoch: 0,                       train_loss : 4.013083136081695, valid_loss : 4.742533445358276\n",
      "fold: 6, epoch: 0,                       train_loss : 4.080420017242432, valid_loss : 4.002867142359416\n",
      "fold: 7, epoch: 0,                       train_loss : 4.2328849077224735, valid_loss : 3.6672399838765464\n",
      "fold: 8, epoch: 0,                       train_loss : 3.9880066514015198, valid_loss : 4.789394060770671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:30:48,245]\u001b[0m Trial 96 finished with value: 3.897482053438823 and parameters: {'num_layers': 3, 'hidden_size': 110, 'batch_size': 140, 'learning_rate': 0.007136024684136778}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.233105087280274, valid_loss : 3.324657758076986\n",
      "fold: 0, epoch: 0,                       train_loss : 5.697169923782349, valid_loss : 4.798670530319214\n",
      "fold: 0, epoch: 1,                       train_loss : 5.474930787086487, valid_loss : 5.401712894439697\n",
      "fold: 0, epoch: 2,                       train_loss : 4.768391764163971, valid_loss : 4.236893018086751\n",
      "fold: 0, epoch: 3,                       train_loss : 4.360898965597153, valid_loss : 4.220182816187541\n",
      "fold: 0, epoch: 4,                       train_loss : 4.323681426048279, valid_loss : 3.512495279312134\n",
      "fold: 0, epoch: 5,                       train_loss : 4.081316745281219, valid_loss : 3.427079757054647\n",
      "fold: 0, epoch: 6,                       train_loss : 4.1701729655265805, valid_loss : 3.8341920375823975\n",
      "fold: 0, epoch: 7,                       train_loss : 4.123643064498902, valid_loss : 3.5750110944112143\n",
      "fold: 0, epoch: 8,                       train_loss : 4.141107857227325, valid_loss : 3.7753854592641196\n",
      "fold: 0, epoch: 9,                       train_loss : 4.384589970111847, valid_loss : 4.15329925219218\n",
      "fold: 0, epoch: 10,                       train_loss : 4.155472552776336, valid_loss : 4.282152096430461\n",
      "fold: 0, epoch: 11,                       train_loss : 4.111462986469268, valid_loss : 3.6126747926076255\n",
      "fold: 0, epoch: 12,                       train_loss : 4.064991217851639, valid_loss : 3.889163335164388\n",
      "fold: 0, epoch: 13,                       train_loss : 4.41443772315979, valid_loss : 4.2658742268880205\n",
      "fold: 0, epoch: 14,                       train_loss : 4.113558053970337, valid_loss : 3.131725788116455\n",
      "fold: 0, epoch: 15,                       train_loss : 4.13325297832489, valid_loss : 4.0231395562489825\n",
      "fold: 0, epoch: 16,                       train_loss : 4.084484112262726, valid_loss : 4.227767626444499\n",
      "fold: 1, epoch: 0,                       train_loss : 4.030231618881226, valid_loss : 4.564988613128662\n",
      "fold: 2, epoch: 0,                       train_loss : 4.090317523479461, valid_loss : 3.521017074584961\n",
      "fold: 3, epoch: 0,                       train_loss : 4.858347654342651, valid_loss : 4.824893474578857\n",
      "fold: 4, epoch: 0,                       train_loss : 4.057061183452606, valid_loss : 3.7116032441457114\n",
      "fold: 5, epoch: 0,                       train_loss : 4.165517175197602, valid_loss : 4.86353079477946\n",
      "fold: 6, epoch: 0,                       train_loss : 4.119555878639221, valid_loss : 4.128878275553386\n",
      "fold: 7, epoch: 0,                       train_loss : 4.026578783988953, valid_loss : 3.8452415466308594\n",
      "fold: 8, epoch: 0,                       train_loss : 4.143731713294983, valid_loss : 4.180482864379883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:31:12,184]\u001b[0m Trial 97 finished with value: 4.075824205080669 and parameters: {'num_layers': 3, 'hidden_size': 120, 'batch_size': 140, 'learning_rate': 0.008433458781747697}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.053469169139862, valid_loss : 3.9858803749084473\n",
      "fold: 0, epoch: 0,                       train_loss : 6.600358989503649, valid_loss : 7.260845422744751\n",
      "fold: 0, epoch: 1,                       train_loss : 6.599691046608819, valid_loss : 7.240058898925781\n",
      "fold: 0, epoch: 2,                       train_loss : 6.576245625813802, valid_loss : 7.232322692871094\n",
      "fold: 0, epoch: 3,                       train_loss : 6.561474800109863, valid_loss : 7.206875562667847\n",
      "fold: 0, epoch: 4,                       train_loss : 6.548973613315159, valid_loss : 7.187782526016235\n",
      "fold: 0, epoch: 5,                       train_loss : 6.516187641355726, valid_loss : 7.1710405349731445\n",
      "fold: 0, epoch: 6,                       train_loss : 6.503119945526123, valid_loss : 7.161332130432129\n",
      "fold: 0, epoch: 7,                       train_loss : 6.492969857321845, valid_loss : 7.134207248687744\n",
      "fold: 0, epoch: 8,                       train_loss : 6.485059022903442, valid_loss : 7.122110366821289\n",
      "fold: 0, epoch: 9,                       train_loss : 6.465497308307224, valid_loss : 7.108008861541748\n",
      "fold: 0, epoch: 10,                       train_loss : 6.43748582734002, valid_loss : 7.085929870605469\n",
      "fold: 0, epoch: 11,                       train_loss : 6.425667259428236, valid_loss : 7.065720558166504\n",
      "fold: 0, epoch: 12,                       train_loss : 6.41074013710022, valid_loss : 7.05071234703064\n",
      "fold: 0, epoch: 13,                       train_loss : 6.387714015112983, valid_loss : 7.0361692905426025\n",
      "fold: 0, epoch: 14,                       train_loss : 6.360633532206218, valid_loss : 7.016506195068359\n",
      "fold: 0, epoch: 15,                       train_loss : 6.369864781697591, valid_loss : 6.992990732192993\n",
      "fold: 0, epoch: 16,                       train_loss : 6.327716535992092, valid_loss : 6.986222505569458\n",
      "fold: 0, epoch: 17,                       train_loss : 6.3149926132626, valid_loss : 6.94963812828064\n",
      "fold: 0, epoch: 18,                       train_loss : 6.307402531305949, valid_loss : 6.9484336376190186\n",
      "fold: 0, epoch: 19,                       train_loss : 6.282216866811116, valid_loss : 6.936084508895874\n",
      "fold: 0, epoch: 20,                       train_loss : 6.272341012954712, valid_loss : 6.907433986663818\n",
      "fold: 0, epoch: 21,                       train_loss : 6.25589034292433, valid_loss : 6.892765522003174\n",
      "fold: 0, epoch: 22,                       train_loss : 6.229074743058947, valid_loss : 6.870645761489868\n",
      "fold: 0, epoch: 23,                       train_loss : 6.222005632188585, valid_loss : 6.8605873584747314\n",
      "fold: 0, epoch: 24,                       train_loss : 6.203996022542317, valid_loss : 6.843318939208984\n",
      "fold: 0, epoch: 25,                       train_loss : 6.172753890355428, valid_loss : 6.830258846282959\n",
      "fold: 0, epoch: 26,                       train_loss : 6.175357474221124, valid_loss : 6.802247762680054\n",
      "fold: 0, epoch: 27,                       train_loss : 6.145886447694567, valid_loss : 6.776417016983032\n",
      "fold: 0, epoch: 28,                       train_loss : 6.117517789204915, valid_loss : 6.772842168807983\n",
      "fold: 0, epoch: 29,                       train_loss : 6.098395188649495, valid_loss : 6.748044967651367\n",
      "fold: 0, epoch: 30,                       train_loss : 6.096153815587361, valid_loss : 6.732707500457764\n",
      "fold: 0, epoch: 31,                       train_loss : 6.066513220469157, valid_loss : 6.723087549209595\n",
      "fold: 0, epoch: 32,                       train_loss : 6.04925995402866, valid_loss : 6.705266952514648\n",
      "fold: 0, epoch: 33,                       train_loss : 6.037598901324802, valid_loss : 6.676906585693359\n",
      "fold: 0, epoch: 34,                       train_loss : 6.0154168075985375, valid_loss : 6.6564624309539795\n",
      "fold: 0, epoch: 35,                       train_loss : 6.00933821996053, valid_loss : 6.6403586864471436\n",
      "fold: 0, epoch: 36,                       train_loss : 5.9812624719407825, valid_loss : 6.619043827056885\n",
      "fold: 0, epoch: 37,                       train_loss : 5.960796515146892, valid_loss : 6.605418682098389\n",
      "fold: 0, epoch: 38,                       train_loss : 5.957707511054145, valid_loss : 6.601343870162964\n",
      "fold: 0, epoch: 39,                       train_loss : 5.938688808017307, valid_loss : 6.583536386489868\n",
      "fold: 0, epoch: 40,                       train_loss : 5.920568969514635, valid_loss : 6.562002658843994\n",
      "fold: 0, epoch: 41,                       train_loss : 5.898076189888848, valid_loss : 6.547299146652222\n",
      "fold: 0, epoch: 42,                       train_loss : 5.895664930343628, valid_loss : 6.52755331993103\n",
      "fold: 0, epoch: 43,                       train_loss : 5.861349874072605, valid_loss : 6.504760980606079\n",
      "fold: 0, epoch: 44,                       train_loss : 5.84991881582472, valid_loss : 6.49275016784668\n",
      "fold: 0, epoch: 45,                       train_loss : 5.82603907585144, valid_loss : 6.481006860733032\n",
      "fold: 0, epoch: 46,                       train_loss : 5.809837712181939, valid_loss : 6.455889940261841\n",
      "fold: 0, epoch: 47,                       train_loss : 5.80353389845954, valid_loss : 6.439979553222656\n",
      "fold: 0, epoch: 48,                       train_loss : 5.776891390482585, valid_loss : 6.4296345710754395\n",
      "fold: 0, epoch: 49,                       train_loss : 5.76904492908054, valid_loss : 6.4129321575164795\n",
      "fold: 0, epoch: 50,                       train_loss : 5.742068847020467, valid_loss : 6.391417980194092\n",
      "fold: 0, epoch: 51,                       train_loss : 5.738031440311008, valid_loss : 6.382336854934692\n",
      "fold: 0, epoch: 52,                       train_loss : 5.713540103700426, valid_loss : 6.359566688537598\n",
      "fold: 0, epoch: 53,                       train_loss : 5.70164434115092, valid_loss : 6.348765850067139\n",
      "fold: 0, epoch: 54,                       train_loss : 5.67428806093004, valid_loss : 6.329475164413452\n",
      "fold: 0, epoch: 55,                       train_loss : 5.660280227661133, valid_loss : 6.322740077972412\n",
      "fold: 0, epoch: 56,                       train_loss : 5.652817673153347, valid_loss : 6.298072338104248\n",
      "fold: 0, epoch: 57,                       train_loss : 5.641635550392999, valid_loss : 6.288286209106445\n",
      "fold: 0, epoch: 58,                       train_loss : 5.6188698874579535, valid_loss : 6.2694549560546875\n",
      "fold: 0, epoch: 59,                       train_loss : 5.605358468161689, valid_loss : 6.244823932647705\n",
      "fold: 0, epoch: 60,                       train_loss : 5.595718489752875, valid_loss : 6.243091344833374\n",
      "fold: 0, epoch: 61,                       train_loss : 5.5896265506744385, valid_loss : 6.221976041793823\n",
      "fold: 0, epoch: 62,                       train_loss : 5.5592441823747425, valid_loss : 6.2157464027404785\n",
      "fold: 0, epoch: 63,                       train_loss : 5.5331774022844105, valid_loss : 6.2005369663238525\n",
      "fold: 0, epoch: 64,                       train_loss : 5.530482318666246, valid_loss : 6.183987140655518\n",
      "fold: 0, epoch: 65,                       train_loss : 5.518245299657186, valid_loss : 6.15790057182312\n",
      "fold: 0, epoch: 66,                       train_loss : 5.515088717142741, valid_loss : 6.152754306793213\n",
      "fold: 0, epoch: 67,                       train_loss : 5.495234648386638, valid_loss : 6.136411666870117\n",
      "fold: 0, epoch: 68,                       train_loss : 5.469678428437975, valid_loss : 6.1246724128723145\n",
      "fold: 0, epoch: 69,                       train_loss : 5.458183579974705, valid_loss : 6.109525442123413\n",
      "fold: 0, epoch: 70,                       train_loss : 5.4353789223565, valid_loss : 6.093714714050293\n",
      "fold: 0, epoch: 71,                       train_loss : 5.437356630961101, valid_loss : 6.075730085372925\n",
      "fold: 0, epoch: 72,                       train_loss : 5.420657979117499, valid_loss : 6.068785667419434\n",
      "fold: 0, epoch: 73,                       train_loss : 5.415614234076606, valid_loss : 6.056764364242554\n",
      "fold: 0, epoch: 74,                       train_loss : 5.385180393854777, valid_loss : 6.05029821395874\n",
      "fold: 0, epoch: 75,                       train_loss : 5.390601899888781, valid_loss : 6.041057825088501\n",
      "fold: 0, epoch: 76,                       train_loss : 5.376231008105808, valid_loss : 6.01322603225708\n",
      "fold: 0, epoch: 77,                       train_loss : 5.3583616150750055, valid_loss : 6.004475116729736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 78,                       train_loss : 5.341483328077528, valid_loss : 5.991154193878174\n",
      "fold: 0, epoch: 79,                       train_loss : 5.331812169816759, valid_loss : 5.97107458114624\n",
      "fold: 0, epoch: 80,                       train_loss : 5.310163418451945, valid_loss : 5.955991983413696\n",
      "fold: 0, epoch: 81,                       train_loss : 5.289693037668864, valid_loss : 5.9424216747283936\n",
      "fold: 0, epoch: 82,                       train_loss : 5.294947226842244, valid_loss : 5.940265417098999\n",
      "fold: 0, epoch: 83,                       train_loss : 5.270508342319065, valid_loss : 5.929267168045044\n",
      "fold: 0, epoch: 84,                       train_loss : 5.275390452808804, valid_loss : 5.910741567611694\n",
      "fold: 0, epoch: 85,                       train_loss : 5.240860303243001, valid_loss : 5.893832445144653\n",
      "fold: 0, epoch: 86,                       train_loss : 5.246523910098606, valid_loss : 5.8906872272491455\n",
      "fold: 0, epoch: 87,                       train_loss : 5.201251308123271, valid_loss : 5.874350309371948\n",
      "fold: 0, epoch: 88,                       train_loss : 5.202546146180895, valid_loss : 5.864293336868286\n",
      "fold: 0, epoch: 89,                       train_loss : 5.202460474438137, valid_loss : 5.8453590869903564\n",
      "fold: 0, epoch: 90,                       train_loss : 5.202855878406101, valid_loss : 5.837768077850342\n",
      "fold: 0, epoch: 91,                       train_loss : 5.177847994698419, valid_loss : 5.826133966445923\n",
      "fold: 0, epoch: 92,                       train_loss : 5.166808313793606, valid_loss : 5.811596632003784\n",
      "fold: 0, epoch: 93,                       train_loss : 5.150083435906304, valid_loss : 5.797867774963379\n",
      "fold: 0, epoch: 94,                       train_loss : 5.14418970213996, valid_loss : 5.779155254364014\n",
      "fold: 0, epoch: 95,                       train_loss : 5.134186082416111, valid_loss : 5.778384685516357\n",
      "fold: 0, epoch: 96,                       train_loss : 5.122003740734524, valid_loss : 5.7641777992248535\n",
      "fold: 0, epoch: 97,                       train_loss : 5.102506637573242, valid_loss : 5.752067565917969\n",
      "fold: 0, epoch: 98,                       train_loss : 5.099090761608547, valid_loss : 5.73922061920166\n",
      "fold: 0, epoch: 99,                       train_loss : 5.086909161673652, valid_loss : 5.73850679397583\n",
      "fold: 0, epoch: 100,                       train_loss : 5.064739015367296, valid_loss : 5.714519262313843\n",
      "fold: 0, epoch: 101,                       train_loss : 5.054863850275676, valid_loss : 5.703677654266357\n",
      "fold: 0, epoch: 102,                       train_loss : 5.059350464079115, valid_loss : 5.700999975204468\n",
      "fold: 0, epoch: 103,                       train_loss : 5.0402371353573265, valid_loss : 5.691420078277588\n",
      "fold: 0, epoch: 104,                       train_loss : 5.014971825811598, valid_loss : 5.6815102100372314\n",
      "fold: 0, epoch: 105,                       train_loss : 4.999052365620931, valid_loss : 5.664882659912109\n",
      "fold: 0, epoch: 106,                       train_loss : 4.991431951522827, valid_loss : 5.645041227340698\n",
      "fold: 0, epoch: 107,                       train_loss : 4.990204360749987, valid_loss : 5.641786098480225\n",
      "fold: 0, epoch: 108,                       train_loss : 4.98344263765547, valid_loss : 5.636660099029541\n",
      "fold: 0, epoch: 109,                       train_loss : 4.9753283394707575, valid_loss : 5.629728078842163\n",
      "fold: 0, epoch: 110,                       train_loss : 4.961063888337877, valid_loss : 5.611576557159424\n",
      "fold: 0, epoch: 111,                       train_loss : 4.965943839814928, valid_loss : 5.606552600860596\n",
      "fold: 0, epoch: 112,                       train_loss : 4.938757207658556, valid_loss : 5.598151445388794\n",
      "fold: 0, epoch: 113,                       train_loss : 4.937203539742364, valid_loss : 5.590525150299072\n",
      "fold: 0, epoch: 114,                       train_loss : 4.935590028762817, valid_loss : 5.584239721298218\n",
      "fold: 0, epoch: 115,                       train_loss : 4.900106324089898, valid_loss : 5.566301584243774\n",
      "fold: 0, epoch: 116,                       train_loss : 4.900680224100749, valid_loss : 5.5594322681427\n",
      "fold: 0, epoch: 117,                       train_loss : 4.885094814830357, valid_loss : 5.545496702194214\n",
      "fold: 0, epoch: 118,                       train_loss : 4.882608519660102, valid_loss : 5.543320894241333\n",
      "fold: 0, epoch: 119,                       train_loss : 4.871129314104716, valid_loss : 5.5255515575408936\n",
      "fold: 0, epoch: 120,                       train_loss : 4.860950946807861, valid_loss : 5.526966571807861\n",
      "fold: 0, epoch: 121,                       train_loss : 4.854636642667982, valid_loss : 5.502956867218018\n",
      "fold: 0, epoch: 122,                       train_loss : 4.8367460701200695, valid_loss : 5.493223667144775\n",
      "fold: 0, epoch: 123,                       train_loss : 4.82864424917433, valid_loss : 5.490098476409912\n",
      "fold: 0, epoch: 124,                       train_loss : 4.81831509537167, valid_loss : 5.4780967235565186\n",
      "fold: 0, epoch: 125,                       train_loss : 4.818062623341878, valid_loss : 5.477484464645386\n",
      "fold: 0, epoch: 126,                       train_loss : 4.80936665005154, valid_loss : 5.467036724090576\n",
      "fold: 0, epoch: 127,                       train_loss : 4.793635620011224, valid_loss : 5.460878610610962\n",
      "fold: 0, epoch: 128,                       train_loss : 4.785967681143019, valid_loss : 5.444519281387329\n",
      "fold: 0, epoch: 129,                       train_loss : 4.780878027280171, valid_loss : 5.442384481430054\n",
      "fold: 0, epoch: 130,                       train_loss : 4.775551875432332, valid_loss : 5.438164234161377\n",
      "fold: 0, epoch: 131,                       train_loss : 4.7656800746917725, valid_loss : 5.420227527618408\n",
      "fold: 0, epoch: 132,                       train_loss : 4.767424954308404, valid_loss : 5.40586256980896\n",
      "fold: 0, epoch: 133,                       train_loss : 4.744850317637126, valid_loss : 5.401549339294434\n",
      "fold: 0, epoch: 134,                       train_loss : 4.736904462178548, valid_loss : 5.39850115776062\n",
      "fold: 0, epoch: 135,                       train_loss : 4.725035773383246, valid_loss : 5.388076305389404\n",
      "fold: 0, epoch: 136,                       train_loss : 4.7387790944841175, valid_loss : 5.3821070194244385\n",
      "fold: 0, epoch: 137,                       train_loss : 4.69991217719184, valid_loss : 5.374337673187256\n",
      "fold: 0, epoch: 138,                       train_loss : 4.710721241103278, valid_loss : 5.3640501499176025\n",
      "fold: 0, epoch: 139,                       train_loss : 4.681256029340956, valid_loss : 5.366472244262695\n",
      "fold: 0, epoch: 140,                       train_loss : 4.684265931447347, valid_loss : 5.348385572433472\n",
      "fold: 0, epoch: 141,                       train_loss : 4.677078617943658, valid_loss : 5.334938049316406\n",
      "fold: 0, epoch: 142,                       train_loss : 4.661863485972087, valid_loss : 5.328475475311279\n",
      "fold: 0, epoch: 143,                       train_loss : 4.664499958356221, valid_loss : 5.325837850570679\n",
      "fold: 0, epoch: 144,                       train_loss : 4.643217470910814, valid_loss : 5.312996864318848\n",
      "fold: 0, epoch: 145,                       train_loss : 4.651217182477315, valid_loss : 5.307812690734863\n",
      "fold: 0, epoch: 146,                       train_loss : 4.645225445429484, valid_loss : 5.300304889678955\n",
      "fold: 0, epoch: 147,                       train_loss : 4.627006027433607, valid_loss : 5.300510406494141\n",
      "fold: 0, epoch: 148,                       train_loss : 4.610365973578559, valid_loss : 5.292327642440796\n",
      "fold: 0, epoch: 149,                       train_loss : 4.628635737631056, valid_loss : 5.275543689727783\n",
      "fold: 0, epoch: 150,                       train_loss : 4.60196132130093, valid_loss : 5.269160270690918\n",
      "fold: 0, epoch: 151,                       train_loss : 4.586068974600898, valid_loss : 5.257155179977417\n",
      "fold: 0, epoch: 152,                       train_loss : 4.593963715765211, valid_loss : 5.252396821975708\n",
      "fold: 0, epoch: 153,                       train_loss : 4.5864020983378095, valid_loss : 5.256653308868408\n",
      "fold: 0, epoch: 154,                       train_loss : 4.57721647951338, valid_loss : 5.242441892623901\n",
      "fold: 0, epoch: 155,                       train_loss : 4.571618212593926, valid_loss : 5.239382028579712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 156,                       train_loss : 4.573317713207668, valid_loss : 5.227877855300903\n",
      "fold: 0, epoch: 157,                       train_loss : 4.560610810915629, valid_loss : 5.219043731689453\n",
      "fold: 0, epoch: 158,                       train_loss : 4.550339486863878, valid_loss : 5.203731060028076\n",
      "fold: 0, epoch: 159,                       train_loss : 4.543531007236904, valid_loss : 5.19848108291626\n",
      "fold: 0, epoch: 160,                       train_loss : 4.54379325442844, valid_loss : 5.2015111446380615\n",
      "fold: 0, epoch: 161,                       train_loss : 4.532331638866001, valid_loss : 5.202826261520386\n",
      "fold: 0, epoch: 162,                       train_loss : 4.527624289194743, valid_loss : 5.1940085887908936\n",
      "fold: 0, epoch: 163,                       train_loss : 4.519144203927782, valid_loss : 5.182538986206055\n",
      "fold: 0, epoch: 164,                       train_loss : 4.520484924316406, valid_loss : 5.182495594024658\n",
      "fold: 0, epoch: 165,                       train_loss : 4.509628229671055, valid_loss : 5.174104452133179\n",
      "fold: 0, epoch: 166,                       train_loss : 4.512652132246229, valid_loss : 5.158244609832764\n",
      "fold: 0, epoch: 167,                       train_loss : 4.50815220673879, valid_loss : 5.159247159957886\n",
      "fold: 0, epoch: 168,                       train_loss : 4.491440653800964, valid_loss : 5.164341449737549\n",
      "fold: 0, epoch: 169,                       train_loss : 4.488040010134379, valid_loss : 5.138921737670898\n",
      "fold: 0, epoch: 170,                       train_loss : 4.467962980270386, valid_loss : 5.134968280792236\n",
      "fold: 0, epoch: 171,                       train_loss : 4.466343349880642, valid_loss : 5.126310110092163\n",
      "fold: 0, epoch: 172,                       train_loss : 4.471472991837396, valid_loss : 5.130569219589233\n",
      "fold: 0, epoch: 173,                       train_loss : 4.455339299307929, valid_loss : 5.119558095932007\n",
      "fold: 0, epoch: 174,                       train_loss : 4.457009461190966, valid_loss : 5.116345643997192\n",
      "fold: 0, epoch: 175,                       train_loss : 4.445002264446682, valid_loss : 5.097570419311523\n",
      "fold: 0, epoch: 176,                       train_loss : 4.454595963160197, valid_loss : 5.102671146392822\n",
      "fold: 0, epoch: 177,                       train_loss : 4.4274553590350685, valid_loss : 5.101352691650391\n",
      "fold: 1, epoch: 0,                       train_loss : 4.423291325569153, valid_loss : 5.119587182998657\n",
      "fold: 2, epoch: 0,                       train_loss : 4.516753951708476, valid_loss : 4.305331468582153\n",
      "fold: 3, epoch: 0,                       train_loss : 4.461691790156895, valid_loss : 4.614167213439941\n",
      "fold: 4, epoch: 0,                       train_loss : 4.484393530421787, valid_loss : 4.514451742172241\n",
      "fold: 5, epoch: 0,                       train_loss : 4.484468791219923, valid_loss : 4.322996497154236\n",
      "fold: 6, epoch: 0,                       train_loss : 4.449430969026354, valid_loss : 4.58195161819458\n",
      "fold: 7, epoch: 0,                       train_loss : 4.502291573418511, valid_loss : 4.180485963821411\n",
      "fold: 8, epoch: 0,                       train_loss : 4.526694112353855, valid_loss : 3.843191623687744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:33:31,326]\u001b[0m Trial 98 finished with value: 4.478884077072143 and parameters: {'num_layers': 3, 'hidden_size': 110, 'batch_size': 150, 'learning_rate': 0.0008779568833212759}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.477928280830383, valid_loss : 4.209107041358948\n",
      "fold: 0, epoch: 0,                       train_loss : 6.228691109904537, valid_loss : 5.2524036566416425\n",
      "fold: 0, epoch: 1,                       train_loss : 4.546046102488482, valid_loss : 4.064512530962626\n",
      "fold: 0, epoch: 2,                       train_loss : 4.159776232860707, valid_loss : 4.033188978830974\n",
      "fold: 0, epoch: 3,                       train_loss : 4.149272667037116, valid_loss : 4.020019769668579\n",
      "fold: 0, epoch: 4,                       train_loss : 4.143557870829547, valid_loss : 4.0726810693740845\n",
      "fold: 0, epoch: 5,                       train_loss : 4.200825810432434, valid_loss : 4.029753724733989\n",
      "fold: 0, epoch: 6,                       train_loss : 4.180271709406817, valid_loss : 4.039292295773824\n",
      "fold: 0, epoch: 7,                       train_loss : 4.150081056135672, valid_loss : 4.0563725233078\n",
      "fold: 0, epoch: 8,                       train_loss : 4.139337570578964, valid_loss : 4.082582791646321\n",
      "fold: 0, epoch: 9,                       train_loss : 4.148386067814297, valid_loss : 4.029649138450623\n",
      "fold: 0, epoch: 10,                       train_loss : 4.151198139897099, valid_loss : 4.019834518432617\n",
      "fold: 0, epoch: 11,                       train_loss : 4.1363035219687, valid_loss : 4.076606273651123\n",
      "fold: 0, epoch: 12,                       train_loss : 4.136088574374163, valid_loss : 4.044737895329793\n",
      "fold: 0, epoch: 13,                       train_loss : 4.197157224019368, valid_loss : 4.06109619140625\n",
      "fold: 0, epoch: 14,                       train_loss : 4.166938101803815, valid_loss : 4.054317196210225\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1316841531682895, valid_loss : 4.047821521759033\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1798458055213645, valid_loss : 3.6754178206125894\n",
      "fold: 2, epoch: 0,                       train_loss : 4.1942725932156595, valid_loss : 3.9732097387313843\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1007793347040815, valid_loss : 4.2267725467681885\n",
      "fold: 4, epoch: 0,                       train_loss : 4.123595189165186, valid_loss : 4.190563360850017\n",
      "fold: 5, epoch: 0,                       train_loss : 4.120819665767528, valid_loss : 4.2308244705200195\n",
      "fold: 6, epoch: 0,                       train_loss : 4.0190120405620995, valid_loss : 5.097684224446614\n",
      "fold: 7, epoch: 0,                       train_loss : 4.1825696097479925, valid_loss : 3.880958159764608\n",
      "fold: 8, epoch: 0,                       train_loss : 4.188629949534381, valid_loss : 4.071878115336101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:34:20,378]\u001b[0m Trial 99 finished with value: 4.136174122492472 and parameters: {'num_layers': 3, 'hidden_size': 100, 'batch_size': 50, 'learning_rate': 0.004793348811476496}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.182398862308926, valid_loss : 3.9945982694625854\n",
      "fold: 0, epoch: 0,                       train_loss : 6.114985589627866, valid_loss : 5.0929365158081055\n",
      "fold: 0, epoch: 1,                       train_loss : 4.635136012677793, valid_loss : 3.9330793221791587\n",
      "fold: 0, epoch: 2,                       train_loss : 4.161572412208274, valid_loss : 3.921053171157837\n",
      "fold: 0, epoch: 3,                       train_loss : 4.153371846234357, valid_loss : 3.921809116999308\n",
      "fold: 0, epoch: 4,                       train_loss : 4.184597183156897, valid_loss : 3.933730125427246\n",
      "fold: 0, epoch: 5,                       train_loss : 4.1664215282157615, valid_loss : 3.907872756322225\n",
      "fold: 0, epoch: 6,                       train_loss : 4.162866963280572, valid_loss : 3.9208460648854575\n",
      "fold: 0, epoch: 7,                       train_loss : 4.150504403644138, valid_loss : 3.9317684968312583\n",
      "fold: 0, epoch: 8,                       train_loss : 4.169672815888016, valid_loss : 3.938105662663778\n",
      "fold: 0, epoch: 9,                       train_loss : 4.15125615508468, valid_loss : 3.916429042816162\n",
      "fold: 0, epoch: 10,                       train_loss : 4.1594231746814865, valid_loss : 3.922881762186686\n",
      "fold: 0, epoch: 11,                       train_loss : 4.168531718077483, valid_loss : 3.9143807093302407\n",
      "fold: 0, epoch: 12,                       train_loss : 4.156160169177586, valid_loss : 3.9224701722462973\n",
      "fold: 0, epoch: 13,                       train_loss : 4.167104668087429, valid_loss : 3.9196995894114175\n",
      "fold: 0, epoch: 14,                       train_loss : 4.162746138042873, valid_loss : 3.9241485595703125\n",
      "fold: 1, epoch: 0,                       train_loss : 4.103801462385389, valid_loss : 4.392799536387126\n",
      "fold: 2, epoch: 0,                       train_loss : 4.116960693288733, valid_loss : 4.246052662531535\n",
      "fold: 3, epoch: 0,                       train_loss : 4.133126700365985, valid_loss : 4.137677907943726\n",
      "fold: 4, epoch: 0,                       train_loss : 4.192946645948622, valid_loss : 3.67573881149292\n",
      "fold: 5, epoch: 0,                       train_loss : 4.146203712180808, valid_loss : 4.023410876592\n",
      "fold: 6, epoch: 0,                       train_loss : 4.128239296100758, valid_loss : 4.1893149216969805\n",
      "fold: 7, epoch: 0,                       train_loss : 4.068149601971662, valid_loss : 4.653984387715657\n",
      "fold: 8, epoch: 0,                       train_loss : 4.144704553816053, valid_loss : 4.08466108640035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:34:42,239]\u001b[0m Trial 100 finished with value: 4.13843116760254 and parameters: {'num_layers': 3, 'hidden_size': 90, 'batch_size': 100, 'learning_rate': 0.010304391299676948}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.135035090976292, valid_loss : 4.072798728942871\n",
      "fold: 0, epoch: 0,                       train_loss : 5.572010653359549, valid_loss : 4.622764587402344\n",
      "fold: 0, epoch: 1,                       train_loss : 4.487285579953875, valid_loss : 3.5185941060384116\n",
      "fold: 0, epoch: 2,                       train_loss : 4.183715593247187, valid_loss : 3.7329355080922446\n",
      "fold: 0, epoch: 3,                       train_loss : 4.220123904091971, valid_loss : 3.6324216524759927\n",
      "fold: 0, epoch: 4,                       train_loss : 4.207546359016781, valid_loss : 3.75618847211202\n",
      "fold: 0, epoch: 5,                       train_loss : 4.180443184716361, valid_loss : 3.7600844701131186\n",
      "fold: 0, epoch: 6,                       train_loss : 4.190166325796218, valid_loss : 3.7351147333780923\n",
      "fold: 0, epoch: 7,                       train_loss : 4.192163183575585, valid_loss : 3.6146744887034097\n",
      "fold: 0, epoch: 8,                       train_loss : 4.18631530943371, valid_loss : 3.646824677785238\n",
      "fold: 0, epoch: 9,                       train_loss : 4.189378431865147, valid_loss : 3.7594005266825357\n",
      "fold: 0, epoch: 10,                       train_loss : 4.194281657536824, valid_loss : 3.5691389242808023\n",
      "fold: 0, epoch: 11,                       train_loss : 4.182607786996024, valid_loss : 3.7083706061045327\n",
      "fold: 0, epoch: 12,                       train_loss : 4.143278246834164, valid_loss : 3.5447726249694824\n",
      "fold: 1, epoch: 0,                       train_loss : 4.0565663405827115, valid_loss : 4.208803176879883\n",
      "fold: 2, epoch: 0,                       train_loss : 4.146441312063308, valid_loss : 4.363013903299968\n",
      "fold: 3, epoch: 0,                       train_loss : 4.169218812670026, valid_loss : 3.8674117724100747\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1249557222638815, valid_loss : 4.237445116043091\n",
      "fold: 5, epoch: 0,                       train_loss : 4.116803373609271, valid_loss : 4.390745480855306\n",
      "fold: 6, epoch: 0,                       train_loss : 4.179727849506197, valid_loss : 3.78505531946818\n",
      "fold: 7, epoch: 0,                       train_loss : 4.094776119504656, valid_loss : 4.247862815856934\n",
      "fold: 8, epoch: 0,                       train_loss : 4.12038829213097, valid_loss : 4.133156379063924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:35:03,641]\u001b[0m Trial 101 finished with value: 4.071331024169923 and parameters: {'num_layers': 6, 'hidden_size': 120, 'batch_size': 130, 'learning_rate': 0.00682709636840874}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.156919229598272, valid_loss : 3.9612221717834473\n",
      "fold: 0, epoch: 0,                       train_loss : 5.97153491973877, valid_loss : 5.004442771275838\n",
      "fold: 0, epoch: 1,                       train_loss : 4.731458333134651, valid_loss : 4.229594310124715\n",
      "fold: 0, epoch: 2,                       train_loss : 4.063253319263458, valid_loss : 4.70310378074646\n",
      "fold: 0, epoch: 3,                       train_loss : 3.9982372522354126, valid_loss : 4.029391288757324\n",
      "fold: 0, epoch: 4,                       train_loss : 4.217255651950836, valid_loss : 4.545835256576538\n",
      "fold: 0, epoch: 5,                       train_loss : 4.062013304233551, valid_loss : 5.009487549463908\n",
      "fold: 0, epoch: 6,                       train_loss : 4.249130690097809, valid_loss : 4.068979660669963\n",
      "fold: 0, epoch: 7,                       train_loss : 4.098658895492553, valid_loss : 3.538077235221863\n",
      "fold: 0, epoch: 8,                       train_loss : 4.247959542274475, valid_loss : 4.547217766443889\n",
      "fold: 0, epoch: 9,                       train_loss : 4.0450252294540405, valid_loss : 3.8965845108032227\n",
      "fold: 0, epoch: 10,                       train_loss : 4.079750871658325, valid_loss : 4.049496968587239\n",
      "fold: 0, epoch: 11,                       train_loss : 4.029734706878662, valid_loss : 3.939353624979655\n",
      "fold: 0, epoch: 12,                       train_loss : 4.184313058853149, valid_loss : 4.275600910186768\n",
      "fold: 0, epoch: 13,                       train_loss : 4.099327659606933, valid_loss : 4.435248851776123\n",
      "fold: 0, epoch: 14,                       train_loss : 3.9743414610624312, valid_loss : 4.253491957982381\n",
      "fold: 1, epoch: 0,                       train_loss : 4.140122902393341, valid_loss : 4.885719935099284\n",
      "fold: 2, epoch: 0,                       train_loss : 4.023093128204346, valid_loss : 4.033711910247803\n",
      "fold: 3, epoch: 0,                       train_loss : 4.063417303562164, valid_loss : 3.7127838134765625\n",
      "fold: 4, epoch: 0,                       train_loss : 4.147077095508576, valid_loss : 4.482529799143474\n",
      "fold: 5, epoch: 0,                       train_loss : 3.9838842272758486, valid_loss : 4.18137248357137\n",
      "fold: 6, epoch: 0,                       train_loss : 4.4684364795684814, valid_loss : 3.935087521870931\n",
      "fold: 7, epoch: 0,                       train_loss : 4.087642729282379, valid_loss : 4.935593048731486\n",
      "fold: 8, epoch: 0,                       train_loss : 4.050439977645874, valid_loss : 3.782271226247152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:35:24,174]\u001b[0m Trial 102 finished with value: 4.103709566593171 and parameters: {'num_layers': 3, 'hidden_size': 110, 'batch_size': 140, 'learning_rate': 0.007320252445428768}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.445890116691589, valid_loss : 3.5499486923217773\n",
      "fold: 0, epoch: 0,                       train_loss : 5.738754630088806, valid_loss : 5.203298886617024\n",
      "fold: 0, epoch: 1,                       train_loss : 5.345859265327453, valid_loss : 4.793455600738525\n",
      "fold: 0, epoch: 2,                       train_loss : 5.382908058166504, valid_loss : 4.244418223698934\n",
      "fold: 0, epoch: 3,                       train_loss : 4.649769413471222, valid_loss : 4.023623625437419\n",
      "fold: 0, epoch: 4,                       train_loss : 4.330724442005158, valid_loss : 3.5719372431437173\n",
      "fold: 0, epoch: 5,                       train_loss : 4.401158058643341, valid_loss : 3.8504180908203125\n",
      "fold: 0, epoch: 6,                       train_loss : 4.090347009897232, valid_loss : 3.84022323290507\n",
      "fold: 0, epoch: 7,                       train_loss : 4.124851679801941, valid_loss : 3.9568822383880615\n",
      "fold: 0, epoch: 8,                       train_loss : 4.6275563597679135, valid_loss : 4.423468430836995\n",
      "fold: 0, epoch: 9,                       train_loss : 4.033269000053406, valid_loss : 3.4626172383626304\n",
      "fold: 0, epoch: 10,                       train_loss : 4.082182943820953, valid_loss : 3.7936999797821045\n",
      "fold: 0, epoch: 11,                       train_loss : 4.100086224079132, valid_loss : 4.00322699546814\n",
      "fold: 0, epoch: 12,                       train_loss : 4.042418783903122, valid_loss : 3.599342664082845\n",
      "fold: 0, epoch: 13,                       train_loss : 4.051005762815476, valid_loss : 3.557081460952759\n",
      "fold: 0, epoch: 14,                       train_loss : 4.054602926969528, valid_loss : 3.802135626475016\n",
      "fold: 0, epoch: 15,                       train_loss : 4.047941476106644, valid_loss : 3.546266476313273\n",
      "fold: 0, epoch: 16,                       train_loss : 4.081592333316803, valid_loss : 3.857182264328003\n",
      "fold: 1, epoch: 0,                       train_loss : 4.218911707401276, valid_loss : 3.625948111216227\n",
      "fold: 2, epoch: 0,                       train_loss : 4.062484490871429, valid_loss : 4.256331284840901\n",
      "fold: 3, epoch: 0,                       train_loss : 4.006539213657379, valid_loss : 4.730766773223877\n",
      "fold: 4, epoch: 0,                       train_loss : 4.072262835502625, valid_loss : 4.207163016001384\n",
      "fold: 5, epoch: 0,                       train_loss : 4.255209469795227, valid_loss : 3.7801595528920493\n",
      "fold: 6, epoch: 0,                       train_loss : 4.171166050434112, valid_loss : 4.06188702583313\n",
      "fold: 7, epoch: 0,                       train_loss : 4.07993358373642, valid_loss : 3.36174742380778\n",
      "fold: 8, epoch: 0,                       train_loss : 4.120614409446716, valid_loss : 4.245989481608073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:35:49,288]\u001b[0m Trial 103 finished with value: 3.9664447943369545 and parameters: {'num_layers': 4, 'hidden_size': 130, 'batch_size': 140, 'learning_rate': 0.005861189867537903}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.156892418861389, valid_loss : 3.931838035583496\n",
      "fold: 0, epoch: 0,                       train_loss : 5.682919049263001, valid_loss : 5.91811736424764\n",
      "fold: 0, epoch: 1,                       train_loss : 5.650056648254394, valid_loss : 5.699657599131267\n",
      "fold: 0, epoch: 2,                       train_loss : 5.617836356163025, valid_loss : 6.024097601572673\n",
      "fold: 0, epoch: 3,                       train_loss : 5.464287388324737, valid_loss : 5.909560203552246\n",
      "fold: 0, epoch: 4,                       train_loss : 5.633194184303283, valid_loss : 6.19834582010905\n",
      "fold: 0, epoch: 5,                       train_loss : 5.587951517105102, valid_loss : 6.673427263895671\n",
      "fold: 0, epoch: 6,                       train_loss : 5.49654233455658, valid_loss : 5.7781937917073565\n",
      "fold: 0, epoch: 7,                       train_loss : 5.294705498218536, valid_loss : 6.5730509757995605\n",
      "fold: 0, epoch: 8,                       train_loss : 5.253631675243378, valid_loss : 5.568886915842692\n",
      "fold: 0, epoch: 9,                       train_loss : 5.389475870132446, valid_loss : 5.409779707590739\n",
      "fold: 0, epoch: 10,                       train_loss : 5.316809773445129, valid_loss : 4.741026401519775\n",
      "fold: 0, epoch: 11,                       train_loss : 5.304534888267517, valid_loss : 5.264966011047363\n",
      "fold: 0, epoch: 12,                       train_loss : 5.207665812969208, valid_loss : 4.898536841074626\n",
      "fold: 0, epoch: 13,                       train_loss : 5.2979594469070435, valid_loss : 5.187399864196777\n",
      "fold: 0, epoch: 14,                       train_loss : 5.48006911277771, valid_loss : 4.862397034962972\n",
      "fold: 0, epoch: 15,                       train_loss : 5.579018378257752, valid_loss : 5.655623435974121\n",
      "fold: 1, epoch: 0,                       train_loss : 5.12421555519104, valid_loss : 5.035707473754883\n",
      "fold: 2, epoch: 0,                       train_loss : 5.153542757034302, valid_loss : 4.443176905314128\n",
      "fold: 3, epoch: 0,                       train_loss : 5.225502872467041, valid_loss : 4.969497203826904\n",
      "fold: 4, epoch: 0,                       train_loss : 5.019947063922882, valid_loss : 5.980710506439209\n",
      "fold: 5, epoch: 0,                       train_loss : 5.246706295013428, valid_loss : 4.862914403279622\n",
      "fold: 6, epoch: 0,                       train_loss : 5.331858468055725, valid_loss : 4.787350654602051\n",
      "fold: 7, epoch: 0,                       train_loss : 4.962000393867493, valid_loss : 5.388019879659017\n",
      "fold: 8, epoch: 0,                       train_loss : 5.00602947473526, valid_loss : 4.6585744222005205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:36:13,038]\u001b[0m Trial 104 finished with value: 4.956171274185181 and parameters: {'num_layers': 4, 'hidden_size': 130, 'batch_size': 140, 'learning_rate': 0.001453490145701231}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 5.0474873065948485, valid_loss : 4.694734891255696\n",
      "fold: 0, epoch: 0,                       train_loss : 6.328490522172716, valid_loss : 6.208754539489746\n",
      "fold: 0, epoch: 1,                       train_loss : 6.108366966247559, valid_loss : 6.030053377151489\n",
      "fold: 0, epoch: 2,                       train_loss : 5.959905200534397, valid_loss : 5.875983715057373\n",
      "fold: 0, epoch: 3,                       train_loss : 5.830277575386895, valid_loss : 5.775233268737793\n",
      "fold: 0, epoch: 4,                       train_loss : 5.743579970465766, valid_loss : 5.681735515594482\n",
      "fold: 0, epoch: 5,                       train_loss : 5.6272753609551325, valid_loss : 5.574865102767944\n",
      "fold: 0, epoch: 6,                       train_loss : 5.5316847165425616, valid_loss : 5.476355791091919\n",
      "fold: 0, epoch: 7,                       train_loss : 5.452670070860121, valid_loss : 5.388697862625122\n",
      "fold: 0, epoch: 8,                       train_loss : 5.370645470089382, valid_loss : 5.302091598510742\n",
      "fold: 0, epoch: 9,                       train_loss : 5.2751644717322455, valid_loss : 5.221786022186279\n",
      "fold: 0, epoch: 10,                       train_loss : 5.2151915894614325, valid_loss : 5.138742923736572\n",
      "fold: 0, epoch: 11,                       train_loss : 5.109700865215725, valid_loss : 5.068986892700195\n",
      "fold: 0, epoch: 12,                       train_loss : 5.049258444044325, valid_loss : 4.995259046554565\n",
      "fold: 0, epoch: 13,                       train_loss : 4.987502773602803, valid_loss : 4.941662311553955\n",
      "fold: 0, epoch: 14,                       train_loss : 4.930933952331543, valid_loss : 4.865251064300537\n",
      "fold: 0, epoch: 15,                       train_loss : 4.862093554602729, valid_loss : 4.809280633926392\n",
      "fold: 0, epoch: 16,                       train_loss : 4.803414225578308, valid_loss : 4.759800672531128\n",
      "fold: 0, epoch: 17,                       train_loss : 4.753862380981445, valid_loss : 4.703874349594116\n",
      "fold: 0, epoch: 18,                       train_loss : 4.724244978692797, valid_loss : 4.662940740585327\n",
      "fold: 0, epoch: 19,                       train_loss : 4.67565299404992, valid_loss : 4.6152184009552\n",
      "fold: 0, epoch: 20,                       train_loss : 4.6213489638434515, valid_loss : 4.573996543884277\n",
      "fold: 0, epoch: 21,                       train_loss : 4.571262280146281, valid_loss : 4.532104730606079\n",
      "fold: 0, epoch: 22,                       train_loss : 4.559273693296644, valid_loss : 4.489938259124756\n",
      "fold: 0, epoch: 23,                       train_loss : 4.52279696199629, valid_loss : 4.463057994842529\n",
      "fold: 0, epoch: 24,                       train_loss : 4.485729389720493, valid_loss : 4.4236884117126465\n",
      "fold: 0, epoch: 25,                       train_loss : 4.451168378194173, valid_loss : 4.400193214416504\n",
      "fold: 0, epoch: 26,                       train_loss : 4.427675167719523, valid_loss : 4.365839242935181\n",
      "fold: 0, epoch: 27,                       train_loss : 4.403654999203152, valid_loss : 4.33634090423584\n",
      "fold: 0, epoch: 28,                       train_loss : 4.368223640653822, valid_loss : 4.323681950569153\n",
      "fold: 0, epoch: 29,                       train_loss : 4.350396699375576, valid_loss : 4.294506549835205\n",
      "fold: 0, epoch: 30,                       train_loss : 4.324508097436693, valid_loss : 4.272505044937134\n",
      "fold: 0, epoch: 31,                       train_loss : 4.335881471633911, valid_loss : 4.251502752304077\n",
      "fold: 0, epoch: 32,                       train_loss : 4.315119173791674, valid_loss : 4.241086721420288\n",
      "fold: 0, epoch: 33,                       train_loss : 4.292807949913873, valid_loss : 4.208762049674988\n",
      "fold: 0, epoch: 34,                       train_loss : 4.282640430662367, valid_loss : 4.205367088317871\n",
      "fold: 0, epoch: 35,                       train_loss : 4.261730776892768, valid_loss : 4.194348096847534\n",
      "fold: 0, epoch: 36,                       train_loss : 4.25945868757036, valid_loss : 4.176397919654846\n",
      "fold: 0, epoch: 37,                       train_loss : 4.255277739630805, valid_loss : 4.173483371734619\n",
      "fold: 0, epoch: 38,                       train_loss : 4.235735813776652, valid_loss : 4.1518003940582275\n",
      "fold: 0, epoch: 39,                       train_loss : 4.224825925297207, valid_loss : 4.152454853057861\n",
      "fold: 0, epoch: 40,                       train_loss : 4.229226774639553, valid_loss : 4.141681671142578\n",
      "fold: 0, epoch: 41,                       train_loss : 4.20523394478692, valid_loss : 4.130454778671265\n",
      "fold: 0, epoch: 42,                       train_loss : 4.205128577020433, valid_loss : 4.126216411590576\n",
      "fold: 0, epoch: 43,                       train_loss : 4.186404122246636, valid_loss : 4.125806570053101\n",
      "fold: 0, epoch: 44,                       train_loss : 4.200401730007595, valid_loss : 4.122408032417297\n",
      "fold: 0, epoch: 45,                       train_loss : 4.186251269446479, valid_loss : 4.109692811965942\n",
      "fold: 0, epoch: 46,                       train_loss : 4.168483760621813, valid_loss : 4.11026132106781\n",
      "fold: 0, epoch: 47,                       train_loss : 4.173768334918552, valid_loss : 4.101423263549805\n",
      "fold: 0, epoch: 48,                       train_loss : 4.160784019364251, valid_loss : 4.1003313064575195\n",
      "fold: 0, epoch: 49,                       train_loss : 4.166429135534498, valid_loss : 4.095916748046875\n",
      "fold: 0, epoch: 50,                       train_loss : 4.176660511228773, valid_loss : 4.097459554672241\n",
      "fold: 0, epoch: 51,                       train_loss : 4.177820669280158, valid_loss : 4.0973957777023315\n",
      "fold: 0, epoch: 52,                       train_loss : 4.1596528556611805, valid_loss : 4.090358734130859\n",
      "fold: 0, epoch: 53,                       train_loss : 4.161499950620863, valid_loss : 4.092939257621765\n",
      "fold: 0, epoch: 54,                       train_loss : 4.155220521820916, valid_loss : 4.093100666999817\n",
      "fold: 0, epoch: 55,                       train_loss : 4.155683239301045, valid_loss : 4.082631587982178\n",
      "fold: 0, epoch: 56,                       train_loss : 4.139731129010518, valid_loss : 4.079697966575623\n",
      "fold: 0, epoch: 57,                       train_loss : 4.146974444389343, valid_loss : 4.0806955099105835\n",
      "fold: 0, epoch: 58,                       train_loss : 4.144294182459514, valid_loss : 4.086437225341797\n",
      "fold: 0, epoch: 59,                       train_loss : 4.146102163526747, valid_loss : 4.080765008926392\n",
      "fold: 0, epoch: 60,                       train_loss : 4.147294402122498, valid_loss : 4.076439619064331\n",
      "fold: 0, epoch: 61,                       train_loss : 4.143805424372355, valid_loss : 4.0827271938323975\n",
      "fold: 0, epoch: 62,                       train_loss : 4.139866259362963, valid_loss : 4.080522537231445\n",
      "fold: 1, epoch: 0,                       train_loss : 4.17047135035197, valid_loss : 3.842666983604431\n",
      "fold: 2, epoch: 0,                       train_loss : 4.162260890007019, valid_loss : 4.0164406299591064\n",
      "fold: 3, epoch: 0,                       train_loss : 4.106690459781223, valid_loss : 4.485108137130737\n",
      "fold: 4, epoch: 0,                       train_loss : 4.084813541836208, valid_loss : 4.572787523269653\n",
      "fold: 5, epoch: 0,                       train_loss : 4.106461763381958, valid_loss : 4.3740153312683105\n",
      "fold: 6, epoch: 0,                       train_loss : 4.15473669105106, valid_loss : 3.9801440238952637\n",
      "fold: 7, epoch: 0,                       train_loss : 4.143176039059957, valid_loss : 4.012362718582153\n",
      "fold: 8, epoch: 0,                       train_loss : 4.125766277313232, valid_loss : 4.192012786865234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:37:17,504]\u001b[0m Trial 105 finished with value: 4.13707069158554 and parameters: {'num_layers': 4, 'hidden_size': 140, 'batch_size': 150, 'learning_rate': 0.005724802778042207}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.16388463973999, valid_loss : 3.8187291622161865\n",
      "fold: 0, epoch: 0,                       train_loss : 5.912524938583374, valid_loss : 5.0318427085876465\n",
      "fold: 0, epoch: 1,                       train_loss : 5.629816638098823, valid_loss : 4.77244758605957\n",
      "fold: 0, epoch: 2,                       train_loss : 5.340684466891819, valid_loss : 4.518933057785034\n",
      "fold: 0, epoch: 3,                       train_loss : 5.072897434234619, valid_loss : 4.245113372802734\n",
      "fold: 0, epoch: 4,                       train_loss : 4.800556368298, valid_loss : 4.001285195350647\n",
      "fold: 0, epoch: 5,                       train_loss : 4.548436866866218, valid_loss : 3.837398886680603\n",
      "fold: 0, epoch: 6,                       train_loss : 4.3850292629665795, valid_loss : 3.7400301694869995\n",
      "fold: 0, epoch: 7,                       train_loss : 4.290892985132006, valid_loss : 3.6963828802108765\n",
      "fold: 0, epoch: 8,                       train_loss : 4.206492159101698, valid_loss : 3.6857627630233765\n",
      "fold: 0, epoch: 9,                       train_loss : 4.19676234987047, valid_loss : 3.687122344970703\n",
      "fold: 0, epoch: 10,                       train_loss : 4.180255624983046, valid_loss : 3.6930298805236816\n",
      "fold: 0, epoch: 11,                       train_loss : 4.1815158526102705, valid_loss : 3.6956310272216797\n",
      "fold: 0, epoch: 12,                       train_loss : 4.197142759958903, valid_loss : 3.700979709625244\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1749252743191185, valid_loss : 3.6941428184509277\n",
      "fold: 0, epoch: 14,                       train_loss : 4.186095979478624, valid_loss : 3.6982861757278442\n",
      "fold: 0, epoch: 15,                       train_loss : 4.187453269958496, valid_loss : 3.6948312520980835\n",
      "fold: 0, epoch: 16,                       train_loss : 4.1845370001263085, valid_loss : 3.697408437728882\n",
      "fold: 0, epoch: 17,                       train_loss : 4.18869952360789, valid_loss : 3.695222020149231\n",
      "fold: 0, epoch: 18,                       train_loss : 4.192244052886963, valid_loss : 3.6977860927581787\n",
      "fold: 0, epoch: 19,                       train_loss : 4.181335647900899, valid_loss : 3.6943618059158325\n",
      "fold: 1, epoch: 0,                       train_loss : 4.106021285057068, valid_loss : 4.297597885131836\n",
      "fold: 2, epoch: 0,                       train_loss : 4.033383409182231, valid_loss : 5.042468309402466\n",
      "fold: 3, epoch: 0,                       train_loss : 4.164662520090739, valid_loss : 3.885879874229431\n",
      "fold: 4, epoch: 0,                       train_loss : 4.144430783059862, valid_loss : 3.9593783617019653\n",
      "fold: 5, epoch: 0,                       train_loss : 4.176503459612529, valid_loss : 3.7814844846725464\n",
      "fold: 6, epoch: 0,                       train_loss : 4.183081216282314, valid_loss : 3.6542139053344727\n",
      "fold: 7, epoch: 0,                       train_loss : 4.090675738122728, valid_loss : 4.549484014511108\n",
      "fold: 8, epoch: 0,                       train_loss : 4.104749454392327, valid_loss : 4.461130499839783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:37:35,365]\u001b[0m Trial 106 finished with value: 4.13286874294281 and parameters: {'num_layers': 3, 'hidden_size': 90, 'batch_size': 150, 'learning_rate': 0.005258568055983232}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1493518352508545, valid_loss : 4.011287331581116\n",
      "fold: 0, epoch: 0,                       train_loss : 6.251638007164002, valid_loss : 5.260054747263591\n",
      "fold: 0, epoch: 1,                       train_loss : 4.641886126995087, valid_loss : 4.404704729715983\n",
      "fold: 0, epoch: 2,                       train_loss : 4.514751219749451, valid_loss : 4.574401140213013\n",
      "fold: 0, epoch: 3,                       train_loss : 4.380440199375153, valid_loss : 3.3125979900360107\n",
      "fold: 0, epoch: 4,                       train_loss : 4.281783330440521, valid_loss : 4.083048899968465\n",
      "fold: 0, epoch: 5,                       train_loss : 4.052479326725006, valid_loss : 4.055613279342651\n",
      "fold: 0, epoch: 6,                       train_loss : 4.026082688570023, valid_loss : 3.3938122590382895\n",
      "fold: 0, epoch: 7,                       train_loss : 4.242876696586609, valid_loss : 4.258390665054321\n",
      "fold: 0, epoch: 8,                       train_loss : 4.106764340400696, valid_loss : 3.8531344731648765\n",
      "fold: 0, epoch: 9,                       train_loss : 4.233002495765686, valid_loss : 3.6046223640441895\n",
      "fold: 0, epoch: 10,                       train_loss : 4.029457080364227, valid_loss : 3.621321519215902\n",
      "fold: 0, epoch: 11,                       train_loss : 4.084664654731751, valid_loss : 4.906014362970988\n",
      "fold: 0, epoch: 12,                       train_loss : 4.07079291343689, valid_loss : 3.406229575475057\n",
      "fold: 0, epoch: 13,                       train_loss : 4.072164750099182, valid_loss : 4.049946705500285\n",
      "fold: 1, epoch: 0,                       train_loss : 4.033216679096222, valid_loss : 4.002447605133057\n",
      "fold: 2, epoch: 0,                       train_loss : 3.9756270051002502, valid_loss : 3.981829563776652\n",
      "fold: 3, epoch: 0,                       train_loss : 3.9466285586357115, valid_loss : 4.642140706380208\n",
      "fold: 4, epoch: 0,                       train_loss : 4.2392458319664, valid_loss : 4.186721483866374\n",
      "fold: 5, epoch: 0,                       train_loss : 4.067649149894715, valid_loss : 3.696229855219523\n",
      "fold: 6, epoch: 0,                       train_loss : 4.227737498283386, valid_loss : 4.352324803670247\n",
      "fold: 7, epoch: 0,                       train_loss : 4.263059628009796, valid_loss : 4.619218667348226\n",
      "fold: 8, epoch: 0,                       train_loss : 4.046638852357864, valid_loss : 3.767001152038574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:38:02,048]\u001b[0m Trial 107 finished with value: 4.005068484942118 and parameters: {'num_layers': 4, 'hidden_size': 160, 'batch_size': 140, 'learning_rate': 0.009179639869939239}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.098517274856567, valid_loss : 3.490173021952311\n",
      "fold: 0, epoch: 0,                       train_loss : 6.114609690273509, valid_loss : 6.00359582901001\n",
      "fold: 0, epoch: 1,                       train_loss : 4.557484023711261, valid_loss : 4.433456897735596\n",
      "fold: 0, epoch: 2,                       train_loss : 4.161461816114538, valid_loss : 4.39400327205658\n",
      "fold: 0, epoch: 3,                       train_loss : 4.1096846075618965, valid_loss : 4.414643049240112\n",
      "fold: 0, epoch: 4,                       train_loss : 4.125507929745843, valid_loss : 4.398910999298096\n",
      "fold: 0, epoch: 5,                       train_loss : 4.10629379048067, valid_loss : 4.39146876335144\n",
      "fold: 0, epoch: 6,                       train_loss : 4.117193951326258, valid_loss : 4.450247764587402\n",
      "fold: 0, epoch: 7,                       train_loss : 4.120074328254251, valid_loss : 4.404156684875488\n",
      "fold: 0, epoch: 8,                       train_loss : 4.123857834759881, valid_loss : 4.419597864151001\n",
      "fold: 0, epoch: 9,                       train_loss : 4.118368653690114, valid_loss : 4.474154472351074\n",
      "fold: 0, epoch: 10,                       train_loss : 4.106959286858054, valid_loss : 4.470056533813477\n",
      "fold: 0, epoch: 11,                       train_loss : 4.114080036387724, valid_loss : 4.434601545333862\n",
      "fold: 0, epoch: 12,                       train_loss : 4.093020340975593, valid_loss : 4.4250266551971436\n",
      "fold: 0, epoch: 13,                       train_loss : 4.095469152226167, valid_loss : 4.416124105453491\n",
      "fold: 0, epoch: 14,                       train_loss : 4.100614603827982, valid_loss : 4.468897581100464\n",
      "fold: 1, epoch: 0,                       train_loss : 4.065985721700332, valid_loss : 4.675295948982239\n",
      "fold: 2, epoch: 0,                       train_loss : 4.127061100567088, valid_loss : 4.086508274078369\n",
      "fold: 3, epoch: 0,                       train_loss : 4.157331284354715, valid_loss : 3.9953869581222534\n",
      "fold: 4, epoch: 0,                       train_loss : 4.136988359339097, valid_loss : 4.048140168190002\n",
      "fold: 5, epoch: 0,                       train_loss : 4.105305489371805, valid_loss : 4.419291615486145\n",
      "fold: 6, epoch: 0,                       train_loss : 4.138318314271815, valid_loss : 4.158774971961975\n",
      "fold: 7, epoch: 0,                       train_loss : 4.183758427115047, valid_loss : 3.6186914443969727\n",
      "fold: 8, epoch: 0,                       train_loss : 4.147389313753913, valid_loss : 3.981982946395874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:38:21,310]\u001b[0m Trial 108 finished with value: 4.116706430912018 and parameters: {'num_layers': 5, 'hidden_size': 130, 'batch_size': 160, 'learning_rate': 0.014476536768308046}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.180254571578082, valid_loss : 3.7915232181549072\n",
      "fold: 0, epoch: 0,                       train_loss : 5.791821002960205, valid_loss : 5.792898337046306\n",
      "fold: 0, epoch: 1,                       train_loss : 5.355107307434082, valid_loss : 4.956278165181478\n",
      "fold: 0, epoch: 2,                       train_loss : 4.605601356143043, valid_loss : 4.615835189819336\n",
      "fold: 0, epoch: 3,                       train_loss : 4.138198614120483, valid_loss : 3.958660920461019\n",
      "fold: 0, epoch: 4,                       train_loss : 4.163198130471366, valid_loss : 3.8995255629221597\n",
      "fold: 0, epoch: 5,                       train_loss : 4.105391025543213, valid_loss : 4.225542147954305\n",
      "fold: 0, epoch: 6,                       train_loss : 4.127981776282901, valid_loss : 4.175977468490601\n",
      "fold: 0, epoch: 7,                       train_loss : 4.154069185256958, valid_loss : 4.854530413945516\n",
      "fold: 0, epoch: 8,                       train_loss : 4.126370509465535, valid_loss : 4.1351563930511475\n",
      "fold: 0, epoch: 9,                       train_loss : 4.128283932095482, valid_loss : 3.7903687953948975\n",
      "fold: 0, epoch: 10,                       train_loss : 4.13365854535784, valid_loss : 4.082133531570435\n",
      "fold: 0, epoch: 11,                       train_loss : 4.122495219821022, valid_loss : 4.4580380121866865\n",
      "fold: 0, epoch: 12,                       train_loss : 4.111255123501732, valid_loss : 4.053658803304036\n",
      "fold: 0, epoch: 13,                       train_loss : 4.129909821919033, valid_loss : 4.223852634429932\n",
      "fold: 0, epoch: 14,                       train_loss : 4.110325904119582, valid_loss : 4.261865615844727\n",
      "fold: 0, epoch: 15,                       train_loss : 4.110335474922543, valid_loss : 4.363455454508464\n",
      "fold: 0, epoch: 16,                       train_loss : 4.084295613425119, valid_loss : 4.318010171254476\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1691903954460505, valid_loss : 3.7460151513417563\n",
      "fold: 2, epoch: 0,                       train_loss : 4.147176401955741, valid_loss : 4.10156496365865\n",
      "fold: 3, epoch: 0,                       train_loss : 4.129957914352417, valid_loss : 4.112410068511963\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1807794116792225, valid_loss : 3.877781947453817\n",
      "fold: 5, epoch: 0,                       train_loss : 4.089030629112607, valid_loss : 4.741196155548096\n",
      "fold: 6, epoch: 0,                       train_loss : 4.143788916724069, valid_loss : 4.268319209416707\n",
      "fold: 7, epoch: 0,                       train_loss : 4.138928731282552, valid_loss : 3.974780559539795\n",
      "fold: 8, epoch: 0,                       train_loss : 4.143401145935059, valid_loss : 4.165347258249919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:38:42,954]\u001b[0m Trial 109 finished with value: 4.1144681851069125 and parameters: {'num_layers': 5, 'hidden_size': 100, 'batch_size': 130, 'learning_rate': 0.004375231160804515}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.087272791635423, valid_loss : 4.366897741953532\n",
      "fold: 0, epoch: 0,                       train_loss : 6.3214278843091884, valid_loss : 6.570331573486328\n",
      "fold: 0, epoch: 1,                       train_loss : 6.297070067861806, valid_loss : 6.498910586039226\n",
      "fold: 0, epoch: 2,                       train_loss : 6.2409810605256455, valid_loss : 6.635964711507161\n",
      "fold: 0, epoch: 3,                       train_loss : 6.2986879141434375, valid_loss : 6.589330514272054\n",
      "fold: 0, epoch: 4,                       train_loss : 6.286027472952138, valid_loss : 6.493143717447917\n",
      "fold: 0, epoch: 5,                       train_loss : 6.286512167557426, valid_loss : 6.651793797810872\n",
      "fold: 0, epoch: 6,                       train_loss : 6.248690086862315, valid_loss : 6.473872343699138\n",
      "fold: 0, epoch: 7,                       train_loss : 6.333291675733483, valid_loss : 6.62849775950114\n",
      "fold: 0, epoch: 8,                       train_loss : 6.2150797843933105, valid_loss : 6.596347014109294\n",
      "fold: 0, epoch: 9,                       train_loss : 6.167602891507356, valid_loss : 6.543043613433838\n",
      "fold: 0, epoch: 10,                       train_loss : 6.177678294803785, valid_loss : 6.439894994099935\n",
      "fold: 0, epoch: 11,                       train_loss : 6.2225858232249385, valid_loss : 6.5552412668863935\n",
      "fold: 0, epoch: 12,                       train_loss : 6.288590058036473, valid_loss : 6.350236256917317\n",
      "fold: 0, epoch: 13,                       train_loss : 6.226960949275805, valid_loss : 6.536552270253499\n",
      "fold: 0, epoch: 14,                       train_loss : 6.156631179477857, valid_loss : 6.340171178181966\n",
      "fold: 0, epoch: 15,                       train_loss : 6.153357132621434, valid_loss : 6.498977025349935\n",
      "fold: 0, epoch: 16,                       train_loss : 6.0940837652786914, valid_loss : 6.62868070602417\n",
      "fold: 0, epoch: 17,                       train_loss : 6.1199686216271445, valid_loss : 6.412088235219319\n",
      "fold: 1, epoch: 0,                       train_loss : 6.172701752704123, valid_loss : 6.08224630355835\n",
      "fold: 2, epoch: 0,                       train_loss : 6.177651757779329, valid_loss : 5.523169835408528\n",
      "fold: 3, epoch: 0,                       train_loss : 6.089514690896739, valid_loss : 6.321219444274902\n",
      "fold: 4, epoch: 0,                       train_loss : 6.076482482578443, valid_loss : 6.546515146891276\n",
      "fold: 5, epoch: 0,                       train_loss : 6.208220917245616, valid_loss : 6.067885080973308\n",
      "fold: 6, epoch: 0,                       train_loss : 6.028654886328655, valid_loss : 6.026151974995931\n",
      "fold: 7, epoch: 0,                       train_loss : 6.076878547668457, valid_loss : 6.128017584482829\n",
      "fold: 8, epoch: 0,                       train_loss : 5.968572015347688, valid_loss : 6.395933310190837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:39:04,240]\u001b[0m Trial 110 finished with value: 6.133892917633057 and parameters: {'num_layers': 2, 'hidden_size': 80, 'batch_size': 120, 'learning_rate': 0.00010662627440906141}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 6.097277890080991, valid_loss : 5.90761931737264\n",
      "fold: 0, epoch: 0,                       train_loss : 5.628373610973358, valid_loss : 5.460743268330892\n",
      "fold: 0, epoch: 1,                       train_loss : 4.61879518032074, valid_loss : 4.66704519589742\n",
      "fold: 0, epoch: 2,                       train_loss : 4.351558911800384, valid_loss : 4.762747526168823\n",
      "fold: 0, epoch: 3,                       train_loss : 4.0434167861938475, valid_loss : 3.9462927977244058\n",
      "fold: 0, epoch: 4,                       train_loss : 4.382476568222046, valid_loss : 3.9115334351857505\n",
      "fold: 0, epoch: 5,                       train_loss : 4.289973092079163, valid_loss : 3.7438457012176514\n",
      "fold: 0, epoch: 6,                       train_loss : 4.2403247356414795, valid_loss : 5.248369375864665\n",
      "fold: 0, epoch: 7,                       train_loss : 4.011830604076385, valid_loss : 4.311010440190633\n",
      "fold: 0, epoch: 8,                       train_loss : 3.9962960720062255, valid_loss : 5.951568603515625\n",
      "fold: 0, epoch: 9,                       train_loss : 4.6541417121887205, valid_loss : 4.062190055847168\n",
      "fold: 0, epoch: 10,                       train_loss : 4.068901681900025, valid_loss : 4.353219827016194\n",
      "fold: 0, epoch: 11,                       train_loss : 4.053685104846954, valid_loss : 4.101667006810506\n",
      "fold: 0, epoch: 12,                       train_loss : 4.0971264243125916, valid_loss : 4.410523811976115\n",
      "fold: 0, epoch: 13,                       train_loss : 4.077573275566101, valid_loss : 4.171662092208862\n",
      "fold: 0, epoch: 14,                       train_loss : 3.989608907699585, valid_loss : 3.98207426071167\n",
      "fold: 0, epoch: 15,                       train_loss : 4.093087697029114, valid_loss : 3.8454975287119546\n",
      "fold: 1, epoch: 0,                       train_loss : 4.344048619270325, valid_loss : 3.7291322549184165\n",
      "fold: 2, epoch: 0,                       train_loss : 4.16546448469162, valid_loss : 3.5941418011983237\n",
      "fold: 3, epoch: 0,                       train_loss : 4.139310824871063, valid_loss : 3.9889997641245523\n",
      "fold: 4, epoch: 0,                       train_loss : 4.088807916641235, valid_loss : 3.7503036657969155\n",
      "fold: 5, epoch: 0,                       train_loss : 4.440565645694733, valid_loss : 3.5332268873850503\n",
      "fold: 6, epoch: 0,                       train_loss : 3.946646511554718, valid_loss : 5.355340480804443\n",
      "fold: 7, epoch: 0,                       train_loss : 4.119157671928406, valid_loss : 3.5329020818074546\n",
      "fold: 8, epoch: 0,                       train_loss : 4.198817050457, valid_loss : 3.644020954767863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:39:31,624]\u001b[0m Trial 111 finished with value: 3.9724196672439573 and parameters: {'num_layers': 4, 'hidden_size': 150, 'batch_size': 140, 'learning_rate': 0.009248049221555883}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.148201990127563, valid_loss : 4.852283080418904\n",
      "fold: 0, epoch: 0,                       train_loss : 5.602746260166168, valid_loss : 5.447234948476155\n",
      "fold: 0, epoch: 1,                       train_loss : 5.728810167312622, valid_loss : 5.479840278625488\n",
      "fold: 0, epoch: 2,                       train_loss : 5.533152341842651, valid_loss : 5.2482906977335615\n",
      "fold: 0, epoch: 3,                       train_loss : 5.538492035865784, valid_loss : 5.1410190264383955\n",
      "fold: 0, epoch: 4,                       train_loss : 5.142951619625092, valid_loss : 5.2789004643758135\n",
      "fold: 0, epoch: 5,                       train_loss : 4.989348292350769, valid_loss : 4.56801700592041\n",
      "fold: 0, epoch: 6,                       train_loss : 4.817845642566681, valid_loss : 4.442636728286743\n",
      "fold: 0, epoch: 7,                       train_loss : 4.27243310213089, valid_loss : 4.171963691711426\n",
      "fold: 0, epoch: 8,                       train_loss : 4.075460755825043, valid_loss : 4.09580938021342\n",
      "fold: 0, epoch: 9,                       train_loss : 4.0447944641113285, valid_loss : 4.103827317555745\n",
      "fold: 0, epoch: 10,                       train_loss : 4.159364664554596, valid_loss : 3.902995506922404\n",
      "fold: 0, epoch: 11,                       train_loss : 4.211159789562226, valid_loss : 4.232463598251343\n",
      "fold: 0, epoch: 12,                       train_loss : 4.2322711706161495, valid_loss : 4.16349736849467\n",
      "fold: 0, epoch: 13,                       train_loss : 4.016226029396057, valid_loss : 3.928539991378784\n",
      "fold: 0, epoch: 14,                       train_loss : 4.276281726360321, valid_loss : 3.738138437271118\n",
      "fold: 0, epoch: 15,                       train_loss : 4.150082969665528, valid_loss : 5.2345123291015625\n",
      "fold: 0, epoch: 16,                       train_loss : 4.330445027351379, valid_loss : 4.225137233734131\n",
      "fold: 0, epoch: 17,                       train_loss : 4.024057251214981, valid_loss : 3.7789577643076577\n",
      "fold: 0, epoch: 18,                       train_loss : 4.2564453959465025, valid_loss : 3.8097251256306968\n",
      "fold: 0, epoch: 19,                       train_loss : 4.1661512613296505, valid_loss : 5.209619442621867\n",
      "fold: 1, epoch: 0,                       train_loss : 4.016157186031341, valid_loss : 3.3716347217559814\n",
      "fold: 2, epoch: 0,                       train_loss : 3.9457436561584474, valid_loss : 5.34748633702596\n",
      "fold: 3, epoch: 0,                       train_loss : 4.015320098400116, valid_loss : 4.722694396972656\n",
      "fold: 4, epoch: 0,                       train_loss : 4.062495541572571, valid_loss : 3.5671908060709634\n",
      "fold: 5, epoch: 0,                       train_loss : 4.064318776130676, valid_loss : 3.545994599660238\n",
      "fold: 6, epoch: 0,                       train_loss : 4.100761294364929, valid_loss : 3.4634581406911216\n",
      "fold: 7, epoch: 0,                       train_loss : 4.527681386470794, valid_loss : 4.771898905436198\n",
      "fold: 8, epoch: 0,                       train_loss : 4.34303605556488, valid_loss : 4.705947955449422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:39:58,326]\u001b[0m Trial 112 finished with value: 4.053483549753825 and parameters: {'num_layers': 4, 'hidden_size': 120, 'batch_size': 140, 'learning_rate': 0.0012278643651758754}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.303891205787659, valid_loss : 3.30039119720459\n",
      "fold: 0, epoch: 0,                       train_loss : 6.262448628743489, valid_loss : 5.504798412322998\n",
      "fold: 0, epoch: 1,                       train_loss : 5.11941012882051, valid_loss : 3.675205945968628\n",
      "fold: 0, epoch: 2,                       train_loss : 4.176768348330543, valid_loss : 3.9173046747843423\n",
      "fold: 0, epoch: 3,                       train_loss : 4.162190743855068, valid_loss : 4.002727508544922\n",
      "fold: 0, epoch: 4,                       train_loss : 4.174168927328927, valid_loss : 4.171496073404948\n",
      "fold: 0, epoch: 5,                       train_loss : 4.154138769422259, valid_loss : 3.7895779609680176\n",
      "fold: 0, epoch: 6,                       train_loss : 4.137256224950154, valid_loss : 3.9934749603271484\n",
      "fold: 0, epoch: 7,                       train_loss : 4.164523612885248, valid_loss : 3.752863963445028\n",
      "fold: 0, epoch: 8,                       train_loss : 4.14504945845831, valid_loss : 3.885107437769572\n",
      "fold: 0, epoch: 9,                       train_loss : 4.153864928654262, valid_loss : 3.9163877964019775\n",
      "fold: 0, epoch: 10,                       train_loss : 4.185282514208839, valid_loss : 3.9276746114095054\n",
      "fold: 0, epoch: 11,                       train_loss : 4.158307211739676, valid_loss : 4.135353326797485\n",
      "fold: 0, epoch: 12,                       train_loss : 4.126854794366019, valid_loss : 3.676945765813192\n",
      "fold: 1, epoch: 0,                       train_loss : 4.131913798195975, valid_loss : 4.611300786336263\n",
      "fold: 2, epoch: 0,                       train_loss : 4.136700789133708, valid_loss : 3.9620723724365234\n",
      "fold: 3, epoch: 0,                       train_loss : 4.136318899336315, valid_loss : 4.266540765762329\n",
      "fold: 4, epoch: 0,                       train_loss : 4.075596446082706, valid_loss : 4.17143980662028\n",
      "fold: 5, epoch: 0,                       train_loss : 4.133782159714472, valid_loss : 4.083575010299683\n",
      "fold: 6, epoch: 0,                       train_loss : 4.138124817893619, valid_loss : 4.101615031560262\n",
      "fold: 7, epoch: 0,                       train_loss : 4.08645883060637, valid_loss : 4.36155382792155\n",
      "fold: 8, epoch: 0,                       train_loss : 4.14749779020037, valid_loss : 3.8558152516682944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:40:23,799]\u001b[0m Trial 113 finished with value: 4.085928185780843 and parameters: {'num_layers': 4, 'hidden_size': 150, 'batch_size': 130, 'learning_rate': 0.008015708127273341}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.195519890104022, valid_loss : 3.770163059234619\n",
      "fold: 0, epoch: 0,                       train_loss : 6.455885357326931, valid_loss : 5.748525142669678\n",
      "fold: 0, epoch: 1,                       train_loss : 6.0389072100321455, valid_loss : 5.170299768447876\n",
      "fold: 0, epoch: 2,                       train_loss : 4.979478504922655, valid_loss : 3.8667945861816406\n",
      "fold: 0, epoch: 3,                       train_loss : 4.190197189648946, valid_loss : 3.885318160057068\n",
      "fold: 0, epoch: 4,                       train_loss : 4.166927602556017, valid_loss : 3.8713698387145996\n",
      "fold: 0, epoch: 5,                       train_loss : 4.163977079921299, valid_loss : 3.885084390640259\n",
      "fold: 0, epoch: 6,                       train_loss : 4.158167494667901, valid_loss : 3.884474277496338\n",
      "fold: 0, epoch: 7,                       train_loss : 4.155143234464857, valid_loss : 3.8712655305862427\n",
      "fold: 0, epoch: 8,                       train_loss : 4.17491336663564, valid_loss : 3.890587568283081\n",
      "fold: 0, epoch: 9,                       train_loss : 4.149221671952142, valid_loss : 3.8742443323135376\n",
      "fold: 0, epoch: 10,                       train_loss : 4.170774711502923, valid_loss : 3.868538737297058\n",
      "fold: 0, epoch: 11,                       train_loss : 4.177121771706475, valid_loss : 3.885550379753113\n",
      "fold: 0, epoch: 12,                       train_loss : 4.175425118870205, valid_loss : 3.8754056692123413\n",
      "fold: 0, epoch: 13,                       train_loss : 4.174553526772393, valid_loss : 3.8875707387924194\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1429010894563465, valid_loss : 4.047402024269104\n",
      "fold: 2, epoch: 0,                       train_loss : 4.0985682010650635, valid_loss : 4.431317687034607\n",
      "fold: 3, epoch: 0,                       train_loss : 4.115728100140889, valid_loss : 4.336204290390015\n",
      "fold: 4, epoch: 0,                       train_loss : 4.139215999179417, valid_loss : 4.145756483078003\n",
      "fold: 5, epoch: 0,                       train_loss : 4.131517608960469, valid_loss : 4.138145208358765\n",
      "fold: 6, epoch: 0,                       train_loss : 4.171215520964728, valid_loss : 3.8358771800994873\n",
      "fold: 7, epoch: 0,                       train_loss : 4.114772054884169, valid_loss : 4.341518759727478\n",
      "fold: 8, epoch: 0,                       train_loss : 4.116327444712321, valid_loss : 4.283183336257935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:40:47,378]\u001b[0m Trial 114 finished with value: 4.135234129428864 and parameters: {'num_layers': 4, 'hidden_size': 170, 'batch_size': 150, 'learning_rate': 0.00639287554555238}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1592238081826105, valid_loss : 3.9261417388916016\n",
      "fold: 0, epoch: 0,                       train_loss : 6.093300485610962, valid_loss : 6.552611351013184\n",
      "fold: 0, epoch: 1,                       train_loss : 5.646389651298523, valid_loss : 4.675820271174113\n",
      "fold: 0, epoch: 2,                       train_loss : 4.404783546924591, valid_loss : 3.940772851308187\n",
      "fold: 0, epoch: 3,                       train_loss : 4.144109439849854, valid_loss : 3.79376482963562\n",
      "fold: 0, epoch: 4,                       train_loss : 4.009437996149063, valid_loss : 4.127159436543782\n",
      "fold: 0, epoch: 5,                       train_loss : 4.123471939563752, valid_loss : 3.9298248291015625\n",
      "fold: 0, epoch: 6,                       train_loss : 4.026098757982254, valid_loss : 4.346842686335246\n",
      "fold: 0, epoch: 7,                       train_loss : 4.251033902168274, valid_loss : 3.6437367598215737\n",
      "fold: 0, epoch: 8,                       train_loss : 4.106761610507965, valid_loss : 4.010453224182129\n",
      "fold: 0, epoch: 9,                       train_loss : 4.216228985786438, valid_loss : 3.8778297901153564\n",
      "fold: 0, epoch: 10,                       train_loss : 4.433897924423218, valid_loss : 3.404217998186747\n",
      "fold: 0, epoch: 11,                       train_loss : 4.2828924536705015, valid_loss : 3.68425718943278\n",
      "fold: 0, epoch: 12,                       train_loss : 4.01737209558487, valid_loss : 3.336359739303589\n",
      "fold: 0, epoch: 13,                       train_loss : 4.236389470100403, valid_loss : 3.600677569707235\n",
      "fold: 0, epoch: 14,                       train_loss : 4.081463122367859, valid_loss : 3.5789918899536133\n",
      "fold: 0, epoch: 15,                       train_loss : 4.498238742351532, valid_loss : 3.7552688916524253\n",
      "fold: 0, epoch: 16,                       train_loss : 4.14488410949707, valid_loss : 4.396085023880005\n",
      "fold: 0, epoch: 17,                       train_loss : 4.335685431957245, valid_loss : 4.394116322199504\n",
      "fold: 1, epoch: 0,                       train_loss : 3.987234318256378, valid_loss : 3.8827644983927407\n",
      "fold: 2, epoch: 0,                       train_loss : 4.065588754415512, valid_loss : 4.159897804260254\n",
      "fold: 3, epoch: 0,                       train_loss : 4.464592587947846, valid_loss : 4.3662651379903155\n",
      "fold: 4, epoch: 0,                       train_loss : 4.08263109922409, valid_loss : 4.004093090693156\n",
      "fold: 5, epoch: 0,                       train_loss : 4.0869645237922665, valid_loss : 4.840599377950032\n",
      "fold: 6, epoch: 0,                       train_loss : 4.216176044940949, valid_loss : 4.141647974650065\n",
      "fold: 7, epoch: 0,                       train_loss : 4.225266182422638, valid_loss : 3.9091458320617676\n",
      "fold: 8, epoch: 0,                       train_loss : 4.078780221939087, valid_loss : 4.081630865732829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:41:10,634]\u001b[0m Trial 115 finished with value: 4.0744012435277295 and parameters: {'num_layers': 4, 'hidden_size': 110, 'batch_size': 140, 'learning_rate': 0.011309827393825403}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.026845788955688, valid_loss : 4.021608114242554\n",
      "fold: 0, epoch: 0,                       train_loss : 5.584293660663423, valid_loss : 5.760214646657308\n",
      "fold: 0, epoch: 1,                       train_loss : 4.413649661200387, valid_loss : 4.91468620300293\n",
      "fold: 0, epoch: 2,                       train_loss : 4.0667417503538585, valid_loss : 4.814528783162435\n",
      "fold: 0, epoch: 3,                       train_loss : 4.039144720349993, valid_loss : 4.881300131479899\n",
      "fold: 0, epoch: 4,                       train_loss : 4.043500559670584, valid_loss : 5.452914396921794\n",
      "fold: 0, epoch: 5,                       train_loss : 4.050748473122006, valid_loss : 4.599018971125285\n",
      "fold: 0, epoch: 6,                       train_loss : 4.0459084283737905, valid_loss : 5.169057369232178\n",
      "fold: 0, epoch: 7,                       train_loss : 4.047860747291928, valid_loss : 5.1057586669921875\n",
      "fold: 0, epoch: 8,                       train_loss : 4.046960172199068, valid_loss : 5.494714895884196\n",
      "fold: 0, epoch: 9,                       train_loss : 4.054723410379319, valid_loss : 4.598868052164714\n",
      "fold: 0, epoch: 10,                       train_loss : 4.035239537556966, valid_loss : 5.010390599568685\n",
      "fold: 0, epoch: 11,                       train_loss : 4.056306146440052, valid_loss : 4.624180157979329\n",
      "fold: 0, epoch: 12,                       train_loss : 4.039608376366751, valid_loss : 4.99202028910319\n",
      "fold: 0, epoch: 13,                       train_loss : 4.046504542941139, valid_loss : 4.77928352355957\n",
      "fold: 0, epoch: 14,                       train_loss : 4.040960209710257, valid_loss : 4.772280693054199\n",
      "fold: 0, epoch: 15,                       train_loss : 4.042537814094906, valid_loss : 4.739476680755615\n",
      "fold: 1, epoch: 0,                       train_loss : 4.102897496450515, valid_loss : 4.559066295623779\n",
      "fold: 2, epoch: 0,                       train_loss : 4.183336950483776, valid_loss : 3.851240634918213\n",
      "fold: 3, epoch: 0,                       train_loss : 4.119678781146095, valid_loss : 4.626961390177409\n",
      "fold: 4, epoch: 0,                       train_loss : 4.129198869069417, valid_loss : 4.176435708999634\n",
      "fold: 5, epoch: 0,                       train_loss : 4.188331990014939, valid_loss : 3.649850606918335\n",
      "fold: 6, epoch: 0,                       train_loss : 4.136464856919789, valid_loss : 3.8498754501342773\n",
      "fold: 7, epoch: 0,                       train_loss : 4.181296178272793, valid_loss : 3.750162045160929\n",
      "fold: 8, epoch: 0,                       train_loss : 4.135963485354469, valid_loss : 3.722890615463257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:41:41,018]\u001b[0m Trial 116 finished with value: 4.068615078926086 and parameters: {'num_layers': 3, 'hidden_size': 150, 'batch_size': 130, 'learning_rate': 0.007241153580063854}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.135335150219145, valid_loss : 3.9007999897003174\n",
      "fold: 0, epoch: 0,                       train_loss : 5.970633665720622, valid_loss : 6.085423469543457\n",
      "fold: 0, epoch: 1,                       train_loss : 5.727795044581096, valid_loss : 5.832014560699463\n",
      "fold: 0, epoch: 2,                       train_loss : 5.508670409520467, valid_loss : 5.5957465171813965\n",
      "fold: 0, epoch: 3,                       train_loss : 5.186881807115343, valid_loss : 5.165082693099976\n",
      "fold: 0, epoch: 4,                       train_loss : 4.783898207876417, valid_loss : 4.686595678329468\n",
      "fold: 0, epoch: 5,                       train_loss : 4.384335226482815, valid_loss : 4.298743724822998\n",
      "fold: 0, epoch: 6,                       train_loss : 4.182171146074931, valid_loss : 4.140374183654785\n",
      "fold: 0, epoch: 7,                       train_loss : 4.140151090092129, valid_loss : 4.104510545730591\n",
      "fold: 0, epoch: 8,                       train_loss : 4.1380845705668134, valid_loss : 4.099650144577026\n",
      "fold: 0, epoch: 9,                       train_loss : 4.142466041776869, valid_loss : 4.1006165742874146\n",
      "fold: 0, epoch: 10,                       train_loss : 4.1489478084776135, valid_loss : 4.105281352996826\n",
      "fold: 0, epoch: 11,                       train_loss : 4.130149629380968, valid_loss : 4.107148885726929\n",
      "fold: 0, epoch: 12,                       train_loss : 4.141695155037774, valid_loss : 4.1101237535476685\n",
      "fold: 0, epoch: 13,                       train_loss : 4.13024804327223, valid_loss : 4.1015061140060425\n",
      "fold: 0, epoch: 14,                       train_loss : 4.129338661829631, valid_loss : 4.106293797492981\n",
      "fold: 0, epoch: 15,                       train_loss : 4.145072486665514, valid_loss : 4.113980293273926\n",
      "fold: 0, epoch: 16,                       train_loss : 4.135131624009874, valid_loss : 4.107162952423096\n",
      "fold: 0, epoch: 17,                       train_loss : 4.135234726799859, valid_loss : 4.100257992744446\n",
      "fold: 0, epoch: 18,                       train_loss : 4.1350827482011585, valid_loss : 4.092794179916382\n",
      "fold: 0, epoch: 19,                       train_loss : 4.133976565466987, valid_loss : 4.1001750230789185\n",
      "fold: 0, epoch: 20,                       train_loss : 4.1431665950351295, valid_loss : 4.108955502510071\n",
      "fold: 1, epoch: 0,                       train_loss : 4.130118780665928, valid_loss : 4.158873677253723\n",
      "fold: 2, epoch: 0,                       train_loss : 4.069122420416938, valid_loss : 4.600116729736328\n",
      "fold: 3, epoch: 0,                       train_loss : 4.138404846191406, valid_loss : 4.067379951477051\n",
      "fold: 4, epoch: 0,                       train_loss : 4.140541659461127, valid_loss : 4.139943599700928\n",
      "fold: 5, epoch: 0,                       train_loss : 4.200274387995402, valid_loss : 3.5987249612808228\n",
      "fold: 6, epoch: 0,                       train_loss : 4.108192827966478, valid_loss : 4.252913951873779\n",
      "fold: 7, epoch: 0,                       train_loss : 4.141543481085035, valid_loss : 4.0848188400268555\n",
      "fold: 8, epoch: 0,                       train_loss : 4.1375835869047375, valid_loss : 4.058072805404663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:42:01,874]\u001b[0m Trial 117 finished with value: 4.132942795753479 and parameters: {'num_layers': 5, 'hidden_size': 100, 'batch_size': 150, 'learning_rate': 0.003574970673068829}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.13051254219479, valid_loss : 4.275789260864258\n",
      "fold: 0, epoch: 0,                       train_loss : 6.156768957773845, valid_loss : 5.5096060037612915\n",
      "fold: 0, epoch: 1,                       train_loss : 6.1019169648488365, valid_loss : 4.986413359642029\n",
      "fold: 0, epoch: 2,                       train_loss : 6.028915627797445, valid_loss : 4.953507125377655\n",
      "fold: 0, epoch: 3,                       train_loss : 5.9545769691467285, valid_loss : 5.139637231826782\n",
      "fold: 0, epoch: 4,                       train_loss : 5.888918908437093, valid_loss : 4.717039406299591\n",
      "fold: 0, epoch: 5,                       train_loss : 5.811860545476278, valid_loss : 5.676226496696472\n",
      "fold: 0, epoch: 6,                       train_loss : 5.750892035166422, valid_loss : 4.746737957000732\n",
      "fold: 0, epoch: 7,                       train_loss : 5.686239004135132, valid_loss : 4.787188768386841\n",
      "fold: 0, epoch: 8,                       train_loss : 5.6494824409484865, valid_loss : 5.340066194534302\n",
      "fold: 0, epoch: 9,                       train_loss : 5.563528076807658, valid_loss : 4.845435380935669\n",
      "fold: 0, epoch: 10,                       train_loss : 5.495596249898274, valid_loss : 4.6086190938949585\n",
      "fold: 0, epoch: 11,                       train_loss : 5.4419266064961755, valid_loss : 4.7242865562438965\n",
      "fold: 0, epoch: 12,                       train_loss : 5.379509631792704, valid_loss : 4.407204210758209\n",
      "fold: 0, epoch: 13,                       train_loss : 5.339838560422262, valid_loss : 4.374301195144653\n",
      "fold: 0, epoch: 14,                       train_loss : 5.289907089869181, valid_loss : 4.586977183818817\n",
      "fold: 0, epoch: 15,                       train_loss : 5.25175994237264, valid_loss : 4.802021622657776\n",
      "fold: 0, epoch: 16,                       train_loss : 5.188270743687948, valid_loss : 4.267474055290222\n",
      "fold: 0, epoch: 17,                       train_loss : 5.1512174288431805, valid_loss : 4.519209146499634\n",
      "fold: 0, epoch: 18,                       train_loss : 5.110233330726624, valid_loss : 4.445810854434967\n",
      "fold: 1, epoch: 0,                       train_loss : 4.9895511309305824, valid_loss : 4.9906299114227295\n",
      "fold: 2, epoch: 0,                       train_loss : 4.915247742335001, valid_loss : 5.133358716964722\n",
      "fold: 3, epoch: 0,                       train_loss : 4.957670338948568, valid_loss : 4.693633794784546\n",
      "fold: 4, epoch: 0,                       train_loss : 4.9198150078455605, valid_loss : 4.406517207622528\n",
      "fold: 5, epoch: 0,                       train_loss : 4.878365238507588, valid_loss : 4.52015346288681\n",
      "fold: 6, epoch: 0,                       train_loss : 4.754135147730509, valid_loss : 5.027194023132324\n",
      "fold: 7, epoch: 0,                       train_loss : 4.753565979003906, valid_loss : 4.753885388374329\n",
      "fold: 8, epoch: 0,                       train_loss : 4.686559414863586, valid_loss : 5.4982781410217285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:42:36,722]\u001b[0m Trial 118 finished with value: 4.828849458694458 and parameters: {'num_layers': 6, 'hidden_size': 110, 'batch_size': 90, 'learning_rate': 0.002137334231168971}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.67661095460256, valid_loss : 4.997369885444641\n",
      "fold: 0, epoch: 0,                       train_loss : 6.0080774307250975, valid_loss : 6.290424664815267\n",
      "fold: 0, epoch: 1,                       train_loss : 5.475504374504089, valid_loss : 5.4415609041849775\n",
      "fold: 0, epoch: 2,                       train_loss : 4.928170478343963, valid_loss : 3.9926133155822754\n",
      "fold: 0, epoch: 3,                       train_loss : 4.267301905155182, valid_loss : 4.0322831471761065\n",
      "fold: 0, epoch: 4,                       train_loss : 4.064108908176422, valid_loss : 4.736520131429036\n",
      "fold: 0, epoch: 5,                       train_loss : 4.085267853736878, valid_loss : 3.719909191131592\n",
      "fold: 0, epoch: 6,                       train_loss : 4.425332844257355, valid_loss : 4.4760918617248535\n",
      "fold: 0, epoch: 7,                       train_loss : 4.3060865759849545, valid_loss : 3.8602637449900308\n",
      "fold: 0, epoch: 8,                       train_loss : 4.5657650351524355, valid_loss : 4.193835735321045\n",
      "fold: 0, epoch: 9,                       train_loss : 4.028574252128601, valid_loss : 4.538428783416748\n",
      "fold: 0, epoch: 10,                       train_loss : 4.180523777008057, valid_loss : 5.677296082178752\n",
      "fold: 0, epoch: 11,                       train_loss : 4.007503604888916, valid_loss : 4.680582523345947\n",
      "fold: 0, epoch: 12,                       train_loss : 3.960673400759697, valid_loss : 3.574136654535929\n",
      "fold: 0, epoch: 13,                       train_loss : 4.21612731218338, valid_loss : 4.14718755086263\n",
      "fold: 0, epoch: 14,                       train_loss : 4.003823518753052, valid_loss : 4.446604092915853\n",
      "fold: 0, epoch: 15,                       train_loss : 3.999516546726227, valid_loss : 4.731735865275065\n",
      "fold: 1, epoch: 0,                       train_loss : 4.442522382736206, valid_loss : 4.576162338256836\n",
      "fold: 2, epoch: 0,                       train_loss : 4.104674232006073, valid_loss : 4.202247778574626\n",
      "fold: 3, epoch: 0,                       train_loss : 4.338579416275024, valid_loss : 2.9011340141296387\n",
      "fold: 4, epoch: 0,                       train_loss : 3.9638458669185637, valid_loss : 4.6017435391743975\n",
      "fold: 5, epoch: 0,                       train_loss : 4.383266508579254, valid_loss : 4.453593810399373\n",
      "fold: 6, epoch: 0,                       train_loss : 4.067274355888367, valid_loss : 3.607863744099935\n",
      "fold: 7, epoch: 0,                       train_loss : 3.9920355558395384, valid_loss : 3.921645005544027\n",
      "fold: 8, epoch: 0,                       train_loss : 4.2332722544670105, valid_loss : 5.336838563283284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:43:02,048]\u001b[0m Trial 119 finished with value: 4.1022149880727135 and parameters: {'num_layers': 5, 'hidden_size': 140, 'batch_size': 140, 'learning_rate': 0.00896052774324995}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.124597501754761, valid_loss : 3.8467844327290854\n",
      "fold: 0, epoch: 0,                       train_loss : 6.348213009212328, valid_loss : 5.653422832489014\n",
      "fold: 0, epoch: 1,                       train_loss : 5.0263846024223, valid_loss : 3.832991679509481\n",
      "fold: 0, epoch: 2,                       train_loss : 4.246275653009829, valid_loss : 3.781588157018026\n",
      "fold: 0, epoch: 3,                       train_loss : 4.156715330870255, valid_loss : 3.6775001684824624\n",
      "fold: 0, epoch: 4,                       train_loss : 4.182631243830142, valid_loss : 3.808159669240316\n",
      "fold: 0, epoch: 5,                       train_loss : 4.196908183719801, valid_loss : 3.7324956258138022\n",
      "fold: 0, epoch: 6,                       train_loss : 4.17114225677822, valid_loss : 3.7377243836720786\n",
      "fold: 0, epoch: 7,                       train_loss : 4.14451495460842, valid_loss : 3.594031810760498\n",
      "fold: 0, epoch: 8,                       train_loss : 4.282430171966553, valid_loss : 3.694317897160848\n",
      "fold: 0, epoch: 9,                       train_loss : 4.139908365581347, valid_loss : 3.5992279052734375\n",
      "fold: 0, epoch: 10,                       train_loss : 4.13203447798024, valid_loss : 3.7311959266662598\n",
      "fold: 0, epoch: 11,                       train_loss : 4.148234232612278, valid_loss : 3.814475695292155\n",
      "fold: 0, epoch: 12,                       train_loss : 4.187808824622112, valid_loss : 3.7755067348480225\n",
      "fold: 0, epoch: 13,                       train_loss : 4.174500486125117, valid_loss : 3.7697500387827554\n",
      "fold: 0, epoch: 14,                       train_loss : 4.193908173104991, valid_loss : 3.593855857849121\n",
      "fold: 0, epoch: 15,                       train_loss : 4.150177561718484, valid_loss : 3.8686424096425376\n",
      "fold: 0, epoch: 16,                       train_loss : 4.147104460260143, valid_loss : 3.560129086176554\n",
      "fold: 0, epoch: 17,                       train_loss : 4.165829347527546, valid_loss : 3.8425656159718833\n",
      "fold: 1, epoch: 0,                       train_loss : 4.076232018678085, valid_loss : 4.758808612823486\n",
      "fold: 2, epoch: 0,                       train_loss : 4.1492549129154375, valid_loss : 3.8834409713745117\n",
      "fold: 3, epoch: 0,                       train_loss : 4.128231017485909, valid_loss : 3.8399078845977783\n",
      "fold: 4, epoch: 0,                       train_loss : 4.12939130741617, valid_loss : 4.181889295578003\n",
      "fold: 5, epoch: 0,                       train_loss : 4.107285312984301, valid_loss : 4.03421680132548\n",
      "fold: 6, epoch: 0,                       train_loss : 4.137545181357342, valid_loss : 3.896493752797445\n",
      "fold: 7, epoch: 0,                       train_loss : 4.089982986450195, valid_loss : 4.847600777943929\n",
      "fold: 8, epoch: 0,                       train_loss : 4.09437894821167, valid_loss : 4.076273600260417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:43:23,385]\u001b[0m Trial 120 finished with value: 4.056414000193278 and parameters: {'num_layers': 6, 'hidden_size': 80, 'batch_size': 120, 'learning_rate': 0.012973658466609242}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1638102531433105, valid_loss : 3.485379219055176\n",
      "fold: 0, epoch: 0,                       train_loss : 6.080974268913269, valid_loss : 5.8984268506368\n",
      "fold: 0, epoch: 1,                       train_loss : 5.8609412670135494, valid_loss : 4.647876501083374\n",
      "fold: 0, epoch: 2,                       train_loss : 5.074812126159668, valid_loss : 4.721909046173096\n",
      "fold: 0, epoch: 3,                       train_loss : 4.4324521780014035, valid_loss : 3.39893372853597\n",
      "fold: 0, epoch: 4,                       train_loss : 4.101422643661499, valid_loss : 3.5878612995147705\n",
      "fold: 0, epoch: 5,                       train_loss : 4.153204190731048, valid_loss : 5.034618218739827\n",
      "fold: 0, epoch: 6,                       train_loss : 4.295050072669983, valid_loss : 3.6343387762705484\n",
      "fold: 0, epoch: 7,                       train_loss : 4.069158875942231, valid_loss : 4.012976725896199\n",
      "fold: 0, epoch: 8,                       train_loss : 4.086154973506927, valid_loss : 3.367542028427124\n",
      "fold: 0, epoch: 9,                       train_loss : 4.056206476688385, valid_loss : 3.345027486483256\n",
      "fold: 0, epoch: 10,                       train_loss : 4.532020318508148, valid_loss : 4.216988484064738\n",
      "fold: 0, epoch: 11,                       train_loss : 4.219618999958039, valid_loss : 3.4244980017344155\n",
      "fold: 0, epoch: 12,                       train_loss : 4.088085830211639, valid_loss : 3.929629643758138\n",
      "fold: 0, epoch: 13,                       train_loss : 4.3262647032737735, valid_loss : 4.795974651972453\n",
      "fold: 0, epoch: 14,                       train_loss : 4.086840057373047, valid_loss : 3.361158609390259\n",
      "fold: 0, epoch: 15,                       train_loss : 4.054121029376984, valid_loss : 3.9573041598002114\n",
      "fold: 1, epoch: 0,                       train_loss : 4.098705291748047, valid_loss : 4.576114654541016\n",
      "fold: 2, epoch: 0,                       train_loss : 4.049486750364304, valid_loss : 3.8401976426442466\n",
      "fold: 3, epoch: 0,                       train_loss : 4.058530634641647, valid_loss : 3.415753126144409\n",
      "fold: 4, epoch: 0,                       train_loss : 4.155512261390686, valid_loss : 4.344627380371094\n",
      "fold: 5, epoch: 0,                       train_loss : 4.4809217810630795, valid_loss : 4.422857602437337\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1062986850738525, valid_loss : 4.4943296909332275\n",
      "fold: 7, epoch: 0,                       train_loss : 4.012950766086578, valid_loss : 4.253665129343669\n",
      "fold: 8, epoch: 0,                       train_loss : 4.001496887207031, valid_loss : 4.530282338460286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:43:52,324]\u001b[0m Trial 121 finished with value: 4.18129130601883 and parameters: {'num_layers': 4, 'hidden_size': 160, 'batch_size': 140, 'learning_rate': 0.010006121220861914}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.401196932792663, valid_loss : 4.590058008829753\n",
      "fold: 0, epoch: 0,                       train_loss : 6.031621050834656, valid_loss : 6.146196524302165\n",
      "fold: 0, epoch: 1,                       train_loss : 5.643610644340515, valid_loss : 5.644374529520671\n",
      "fold: 0, epoch: 2,                       train_loss : 4.949421972036362, valid_loss : 4.956453800201416\n",
      "fold: 0, epoch: 3,                       train_loss : 4.524581301212311, valid_loss : 4.32070779800415\n",
      "fold: 0, epoch: 4,                       train_loss : 4.26635434627533, valid_loss : 4.131762663523356\n",
      "fold: 0, epoch: 5,                       train_loss : 4.059289705753327, valid_loss : 4.633422374725342\n",
      "fold: 0, epoch: 6,                       train_loss : 4.429530823230744, valid_loss : 4.482958793640137\n",
      "fold: 0, epoch: 7,                       train_loss : 4.185388123989105, valid_loss : 4.1935248374938965\n",
      "fold: 0, epoch: 8,                       train_loss : 4.047939920425415, valid_loss : 4.057068506876628\n",
      "fold: 0, epoch: 9,                       train_loss : 4.1226404190063475, valid_loss : 5.073308944702148\n",
      "fold: 0, epoch: 10,                       train_loss : 4.33589277267456, valid_loss : 4.642756462097168\n",
      "fold: 0, epoch: 11,                       train_loss : 4.080518972873688, valid_loss : 4.816198825836182\n",
      "fold: 0, epoch: 12,                       train_loss : 4.083066952228546, valid_loss : 4.456008593241374\n",
      "fold: 0, epoch: 13,                       train_loss : 4.012907588481903, valid_loss : 4.0816318194071455\n",
      "fold: 0, epoch: 14,                       train_loss : 4.006160426139831, valid_loss : 3.887800137201945\n",
      "fold: 0, epoch: 15,                       train_loss : 4.059267449378967, valid_loss : 5.317683378855388\n",
      "fold: 0, epoch: 16,                       train_loss : 4.140847897529602, valid_loss : 4.462188720703125\n",
      "fold: 0, epoch: 17,                       train_loss : 4.001139485836029, valid_loss : 5.071428616841634\n",
      "fold: 1, epoch: 0,                       train_loss : 3.944726014137268, valid_loss : 5.346879482269287\n",
      "fold: 2, epoch: 0,                       train_loss : 4.097451901435852, valid_loss : 3.5703787008921304\n",
      "fold: 3, epoch: 0,                       train_loss : 4.392605674266815, valid_loss : 3.7035903135935464\n",
      "fold: 4, epoch: 0,                       train_loss : 4.033816349506378, valid_loss : 3.854703903198242\n",
      "fold: 5, epoch: 0,                       train_loss : 4.098174035549164, valid_loss : 4.002838850021362\n",
      "fold: 6, epoch: 0,                       train_loss : 4.177496314048767, valid_loss : 4.154330889383952\n",
      "fold: 7, epoch: 0,                       train_loss : 4.123100447654724, valid_loss : 3.3311081727345786\n",
      "fold: 8, epoch: 0,                       train_loss : 4.046977829933167, valid_loss : 4.257972717285156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:44:23,885]\u001b[0m Trial 122 finished with value: 3.98427623907725 and parameters: {'num_layers': 4, 'hidden_size': 160, 'batch_size': 140, 'learning_rate': 0.008867551167097368}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.0480596899986265, valid_loss : 3.7331592241923013\n",
      "fold: 0, epoch: 0,                       train_loss : 6.227321577072144, valid_loss : 6.412737051645915\n",
      "fold: 0, epoch: 1,                       train_loss : 6.062960505485535, valid_loss : 7.012716293334961\n",
      "fold: 0, epoch: 2,                       train_loss : 5.937918400764465, valid_loss : 5.565857410430908\n",
      "fold: 0, epoch: 3,                       train_loss : 5.834237265586853, valid_loss : 5.734277884165446\n",
      "fold: 0, epoch: 4,                       train_loss : 5.100155282020569, valid_loss : 5.485922972361247\n",
      "fold: 0, epoch: 5,                       train_loss : 4.735470843315125, valid_loss : 4.892306804656982\n",
      "fold: 0, epoch: 6,                       train_loss : 4.620705580711364, valid_loss : 4.537838459014893\n",
      "fold: 0, epoch: 7,                       train_loss : 4.307268989086151, valid_loss : 4.60979684193929\n",
      "fold: 0, epoch: 8,                       train_loss : 4.214675772190094, valid_loss : 4.010017315546672\n",
      "fold: 0, epoch: 9,                       train_loss : 4.122907996177673, valid_loss : 4.3999307950337725\n",
      "fold: 0, epoch: 10,                       train_loss : 4.060177874565125, valid_loss : 4.265081882476807\n",
      "fold: 0, epoch: 11,                       train_loss : 4.183679413795471, valid_loss : 3.7490718364715576\n",
      "fold: 0, epoch: 12,                       train_loss : 4.161446392536163, valid_loss : 4.253337224324544\n",
      "fold: 0, epoch: 13,                       train_loss : 4.160617566108703, valid_loss : 4.3338883717854815\n",
      "fold: 0, epoch: 14,                       train_loss : 4.0594707250595095, valid_loss : 4.493025700251262\n",
      "fold: 0, epoch: 15,                       train_loss : 4.319227087497711, valid_loss : 3.69471804300944\n",
      "fold: 0, epoch: 16,                       train_loss : 3.9997290134429933, valid_loss : 4.966651439666748\n",
      "fold: 0, epoch: 17,                       train_loss : 3.9973695456981657, valid_loss : 3.9991820653279624\n",
      "fold: 0, epoch: 18,                       train_loss : 4.131148481369019, valid_loss : 3.871581554412842\n",
      "fold: 1, epoch: 0,                       train_loss : 4.484055542945862, valid_loss : 3.684699535369873\n",
      "fold: 2, epoch: 0,                       train_loss : 3.980145573616028, valid_loss : 5.392535130182902\n",
      "fold: 3, epoch: 0,                       train_loss : 4.117427253723145, valid_loss : 4.035136858622233\n",
      "fold: 4, epoch: 0,                       train_loss : 3.991847151517868, valid_loss : 3.7751189867655435\n",
      "fold: 5, epoch: 0,                       train_loss : 4.034398591518402, valid_loss : 3.555713653564453\n",
      "fold: 6, epoch: 0,                       train_loss : 3.9610273003578187, valid_loss : 4.197155634562175\n",
      "fold: 7, epoch: 0,                       train_loss : 4.023051488399505, valid_loss : 3.7781065305074057\n",
      "fold: 8, epoch: 0,                       train_loss : 4.327382957935333, valid_loss : 3.3580049673716226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:44:54,974]\u001b[0m Trial 123 finished with value: 3.9535035292307534 and parameters: {'num_layers': 4, 'hidden_size': 150, 'batch_size': 140, 'learning_rate': 0.00585512067694437}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.0960994303226474, valid_loss : 4.063845952351888\n",
      "fold: 0, epoch: 0,                       train_loss : 6.273484415478176, valid_loss : 6.140058517456055\n",
      "fold: 0, epoch: 1,                       train_loss : 6.050204012129042, valid_loss : 5.945608139038086\n",
      "fold: 0, epoch: 2,                       train_loss : 5.849386877483791, valid_loss : 5.742327928543091\n",
      "fold: 0, epoch: 3,                       train_loss : 5.627222299575806, valid_loss : 5.488375663757324\n",
      "fold: 0, epoch: 4,                       train_loss : 5.349536074532403, valid_loss : 5.1746885776519775\n",
      "fold: 0, epoch: 5,                       train_loss : 5.019442187415229, valid_loss : 4.794287204742432\n",
      "fold: 0, epoch: 6,                       train_loss : 4.654139002164205, valid_loss : 4.4286723136901855\n",
      "fold: 0, epoch: 7,                       train_loss : 4.3337189886305065, valid_loss : 4.17994225025177\n",
      "fold: 0, epoch: 8,                       train_loss : 4.1832202143139305, valid_loss : 4.10666298866272\n",
      "fold: 0, epoch: 9,                       train_loss : 4.136092768775092, valid_loss : 4.090373873710632\n",
      "fold: 0, epoch: 10,                       train_loss : 4.140239106284247, valid_loss : 4.096048951148987\n",
      "fold: 0, epoch: 11,                       train_loss : 4.132242639859517, valid_loss : 4.095539093017578\n",
      "fold: 0, epoch: 12,                       train_loss : 4.13272143734826, valid_loss : 4.085214018821716\n",
      "fold: 0, epoch: 13,                       train_loss : 4.139949295255873, valid_loss : 4.094028830528259\n",
      "fold: 0, epoch: 14,                       train_loss : 4.137001090579563, valid_loss : 4.090862274169922\n",
      "fold: 0, epoch: 15,                       train_loss : 4.145017623901367, valid_loss : 4.092581748962402\n",
      "fold: 0, epoch: 16,                       train_loss : 4.133196565839979, valid_loss : 4.091262698173523\n",
      "fold: 0, epoch: 17,                       train_loss : 4.14244106080797, valid_loss : 4.0981303453445435\n",
      "fold: 0, epoch: 18,                       train_loss : 4.1518400112787885, valid_loss : 4.092021107673645\n",
      "fold: 0, epoch: 19,                       train_loss : 4.144011828634474, valid_loss : 4.092265844345093\n",
      "fold: 0, epoch: 20,                       train_loss : 4.130143125851949, valid_loss : 4.09406042098999\n",
      "fold: 0, epoch: 21,                       train_loss : 4.140998787350124, valid_loss : 4.086239457130432\n",
      "fold: 1, epoch: 0,                       train_loss : 4.128183325131734, valid_loss : 4.21481466293335\n",
      "fold: 2, epoch: 0,                       train_loss : 4.11818352010515, valid_loss : 4.333768129348755\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1372794310251875, valid_loss : 4.184174656867981\n",
      "fold: 4, epoch: 0,                       train_loss : 4.138636390368144, valid_loss : 4.2104679346084595\n",
      "fold: 5, epoch: 0,                       train_loss : 4.106075459056431, valid_loss : 4.326158761978149\n",
      "fold: 6, epoch: 0,                       train_loss : 4.172901921802097, valid_loss : 3.6900229454040527\n",
      "fold: 7, epoch: 0,                       train_loss : 4.109381821420458, valid_loss : 4.308004856109619\n",
      "fold: 8, epoch: 0,                       train_loss : 4.127409312460157, valid_loss : 4.2571035623550415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:45:25,736]\u001b[0m Trial 124 finished with value: 4.133584678173065 and parameters: {'num_layers': 4, 'hidden_size': 150, 'batch_size': 150, 'learning_rate': 0.005314967678592677}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.179084168540107, valid_loss : 3.726117253303528\n",
      "fold: 0, epoch: 0,                       train_loss : 5.9038323901948475, valid_loss : 5.834507465362549\n",
      "fold: 0, epoch: 1,                       train_loss : 4.816589128403437, valid_loss : 4.463280439376831\n",
      "fold: 0, epoch: 2,                       train_loss : 4.080515441440401, valid_loss : 4.348026672999064\n",
      "fold: 0, epoch: 3,                       train_loss : 4.049662669499715, valid_loss : 4.715239604314168\n",
      "fold: 0, epoch: 4,                       train_loss : 4.057590700331188, valid_loss : 4.817121823628743\n",
      "fold: 0, epoch: 5,                       train_loss : 4.059576488676525, valid_loss : 4.535861333211263\n",
      "fold: 0, epoch: 6,                       train_loss : 4.05441951751709, valid_loss : 4.407919883728027\n",
      "fold: 0, epoch: 7,                       train_loss : 4.048248631613595, valid_loss : 4.647448539733887\n",
      "fold: 0, epoch: 8,                       train_loss : 4.038657336007981, valid_loss : 4.532544771830241\n",
      "fold: 0, epoch: 9,                       train_loss : 4.091945852552142, valid_loss : 4.422011295954387\n",
      "fold: 0, epoch: 10,                       train_loss : 4.067696105866205, valid_loss : 4.325854539871216\n",
      "fold: 0, epoch: 11,                       train_loss : 4.089681477773757, valid_loss : 4.412732442220052\n",
      "fold: 0, epoch: 12,                       train_loss : 4.082974751790364, valid_loss : 4.699629147847493\n",
      "fold: 0, epoch: 13,                       train_loss : 4.092352367582775, valid_loss : 4.996204217274983\n",
      "fold: 0, epoch: 14,                       train_loss : 4.063386167798724, valid_loss : 4.102169752120972\n",
      "fold: 0, epoch: 15,                       train_loss : 4.088729824338641, valid_loss : 4.766929229100545\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1824524856749035, valid_loss : 3.951000213623047\n",
      "fold: 2, epoch: 0,                       train_loss : 4.10970325697036, valid_loss : 4.147008101145427\n",
      "fold: 3, epoch: 0,                       train_loss : 4.121160461789086, valid_loss : 3.968175172805786\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1428750696636385, valid_loss : 4.34407114982605\n",
      "fold: 5, epoch: 0,                       train_loss : 4.1542375314803355, valid_loss : 3.5822019577026367\n",
      "fold: 6, epoch: 0,                       train_loss : 4.075018122082665, valid_loss : 4.859024365743001\n",
      "fold: 7, epoch: 0,                       train_loss : 4.138618015107655, valid_loss : 3.963614304860433\n",
      "fold: 8, epoch: 0,                       train_loss : 4.137264694486346, valid_loss : 4.531938234965007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:45:57,382]\u001b[0m Trial 125 finished with value: 4.1345141569773345 and parameters: {'num_layers': 4, 'hidden_size': 180, 'batch_size': 130, 'learning_rate': 0.006300055855808829}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.162048828034174, valid_loss : 3.8959383169809976\n",
      "fold: 0, epoch: 0,                       train_loss : 6.475587964057922, valid_loss : 6.2761454582214355\n",
      "fold: 0, epoch: 1,                       train_loss : 6.358675909042359, valid_loss : 7.553369045257568\n",
      "fold: 0, epoch: 2,                       train_loss : 6.0662449359893795, valid_loss : 5.905396143595378\n",
      "fold: 0, epoch: 3,                       train_loss : 5.785515761375427, valid_loss : 5.522014776865642\n",
      "fold: 0, epoch: 4,                       train_loss : 5.4120399951934814, valid_loss : 5.275695085525513\n",
      "fold: 0, epoch: 5,                       train_loss : 5.329229998588562, valid_loss : 6.110843022664388\n",
      "fold: 0, epoch: 6,                       train_loss : 5.213300144672393, valid_loss : 6.195535659790039\n",
      "fold: 0, epoch: 7,                       train_loss : 5.0598981261253355, valid_loss : 4.943454106648763\n",
      "fold: 0, epoch: 8,                       train_loss : 4.883086436986924, valid_loss : 5.03285280863444\n",
      "fold: 0, epoch: 9,                       train_loss : 4.808941853046417, valid_loss : 5.26068115234375\n",
      "fold: 0, epoch: 10,                       train_loss : 4.945493912696838, valid_loss : 5.955938339233398\n",
      "fold: 0, epoch: 11,                       train_loss : 4.542455829679966, valid_loss : 4.9267276128133135\n",
      "fold: 0, epoch: 12,                       train_loss : 4.558336770534515, valid_loss : 5.535273710886638\n",
      "fold: 0, epoch: 13,                       train_loss : 4.67372180223465, valid_loss : 4.761715332667033\n",
      "fold: 0, epoch: 14,                       train_loss : 4.593200039863587, valid_loss : 5.189435323079427\n",
      "fold: 0, epoch: 15,                       train_loss : 4.516049599647522, valid_loss : 4.3748265107472735\n",
      "fold: 0, epoch: 16,                       train_loss : 4.322405099868774, valid_loss : 4.3259867032368975\n",
      "fold: 0, epoch: 17,                       train_loss : 4.2489212334156035, valid_loss : 4.174658457438151\n",
      "fold: 0, epoch: 18,                       train_loss : 4.2703807830810545, valid_loss : 4.965731779734294\n",
      "fold: 0, epoch: 19,                       train_loss : 4.175276041030884, valid_loss : 4.23879861831665\n",
      "fold: 0, epoch: 20,                       train_loss : 4.15254499912262, valid_loss : 4.803728421529134\n",
      "fold: 1, epoch: 0,                       train_loss : 4.298452317714691, valid_loss : 4.934165875116984\n",
      "fold: 2, epoch: 0,                       train_loss : 4.175820809602738, valid_loss : 4.005175828933716\n",
      "fold: 3, epoch: 0,                       train_loss : 4.204783952236175, valid_loss : 4.054469108581543\n",
      "fold: 4, epoch: 0,                       train_loss : 4.324303233623505, valid_loss : 4.550980647404988\n",
      "fold: 5, epoch: 0,                       train_loss : 4.087648725509643, valid_loss : 5.045749028523763\n",
      "fold: 6, epoch: 0,                       train_loss : 4.323916637897492, valid_loss : 4.330474376678467\n",
      "fold: 7, epoch: 0,                       train_loss : 4.129384624958038, valid_loss : 3.718320369720459\n",
      "fold: 8, epoch: 0,                       train_loss : 4.023149144649506, valid_loss : 4.894571940104167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:46:32,796]\u001b[0m Trial 126 finished with value: 4.372705141703287 and parameters: {'num_layers': 4, 'hidden_size': 170, 'batch_size': 140, 'learning_rate': 0.00810976432753385}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.102854788303375, valid_loss : 4.01848578453064\n",
      "fold: 0, epoch: 0,                       train_loss : 6.554232573509216, valid_loss : 5.740936438242595\n",
      "fold: 0, epoch: 1,                       train_loss : 6.06046245098114, valid_loss : 6.049671014149983\n",
      "fold: 0, epoch: 2,                       train_loss : 5.9900905847549435, valid_loss : 5.4480048815409345\n",
      "fold: 0, epoch: 3,                       train_loss : 5.7143168449401855, valid_loss : 5.1776712735493975\n",
      "fold: 0, epoch: 4,                       train_loss : 4.7178997039794925, valid_loss : 4.529583772023519\n",
      "fold: 0, epoch: 5,                       train_loss : 4.235705411434173, valid_loss : 4.348817189534505\n",
      "fold: 0, epoch: 6,                       train_loss : 4.312998032569885, valid_loss : 4.572447220484416\n",
      "fold: 0, epoch: 7,                       train_loss : 3.994492030143738, valid_loss : 3.734633763631185\n",
      "fold: 0, epoch: 8,                       train_loss : 4.08837399482727, valid_loss : 4.801979064941406\n",
      "fold: 0, epoch: 9,                       train_loss : 4.620433044433594, valid_loss : 4.597554524739583\n",
      "fold: 0, epoch: 10,                       train_loss : 4.019885462522507, valid_loss : 4.176549911499023\n",
      "fold: 0, epoch: 11,                       train_loss : 4.338963747024536, valid_loss : 4.220425844192505\n",
      "fold: 0, epoch: 12,                       train_loss : 4.150361013412476, valid_loss : 4.019477844238281\n",
      "fold: 0, epoch: 13,                       train_loss : 4.014805388450623, valid_loss : 3.930633783340454\n",
      "fold: 0, epoch: 14,                       train_loss : 4.241292178630829, valid_loss : 4.365565379460652\n",
      "fold: 0, epoch: 15,                       train_loss : 4.2049576997756954, valid_loss : 4.532552003860474\n",
      "fold: 0, epoch: 16,                       train_loss : 4.1353308916091915, valid_loss : 4.163517157236735\n",
      "fold: 1, epoch: 0,                       train_loss : 3.979408884048462, valid_loss : 4.367800871531169\n",
      "fold: 2, epoch: 0,                       train_loss : 4.168072247505188, valid_loss : 4.814061721165975\n",
      "fold: 3, epoch: 0,                       train_loss : 4.141977870464325, valid_loss : 3.3686935106913247\n",
      "fold: 4, epoch: 0,                       train_loss : 4.310522401332856, valid_loss : 3.807096242904663\n",
      "fold: 5, epoch: 0,                       train_loss : 4.116198766231537, valid_loss : 4.0757261117299395\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1801515340805055, valid_loss : 4.255033651987712\n",
      "fold: 7, epoch: 0,                       train_loss : 4.0194923877716064, valid_loss : 4.534418980280559\n",
      "fold: 8, epoch: 0,                       train_loss : 4.011533033847809, valid_loss : 4.073567946751912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:46:59,802]\u001b[0m Trial 127 finished with value: 4.174248353640239 and parameters: {'num_layers': 4, 'hidden_size': 140, 'batch_size': 140, 'learning_rate': 0.00467404165499787}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 3.9677440881729127, valid_loss : 4.711450735727946\n",
      "fold: 0, epoch: 0,                       train_loss : 6.070994467962356, valid_loss : 5.349542140960693\n",
      "fold: 0, epoch: 1,                       train_loss : 5.521536327543712, valid_loss : 4.967613697052002\n",
      "fold: 0, epoch: 2,                       train_loss : 4.76702170144944, valid_loss : 3.7729607423146567\n",
      "fold: 0, epoch: 3,                       train_loss : 4.275052411215646, valid_loss : 3.758953412373861\n",
      "fold: 0, epoch: 4,                       train_loss : 4.202323107492356, valid_loss : 3.504204352696737\n",
      "fold: 0, epoch: 5,                       train_loss : 4.176176082520258, valid_loss : 3.9634934266408286\n",
      "fold: 0, epoch: 6,                       train_loss : 4.164896703901745, valid_loss : 3.39969793955485\n",
      "fold: 0, epoch: 7,                       train_loss : 4.175386269887288, valid_loss : 3.6241031487782798\n",
      "fold: 0, epoch: 8,                       train_loss : 4.176425797598703, valid_loss : 3.658555348714193\n",
      "fold: 0, epoch: 9,                       train_loss : 4.1630902744474865, valid_loss : 3.5684115886688232\n",
      "fold: 0, epoch: 10,                       train_loss : 4.184596674782889, valid_loss : 3.9924044609069824\n",
      "fold: 0, epoch: 11,                       train_loss : 4.214003880818685, valid_loss : 3.440467913945516\n",
      "fold: 0, epoch: 12,                       train_loss : 4.172882874806722, valid_loss : 3.56956148147583\n",
      "fold: 0, epoch: 13,                       train_loss : 4.172472068241665, valid_loss : 3.76951273282369\n",
      "fold: 0, epoch: 14,                       train_loss : 4.186500492550078, valid_loss : 3.521907329559326\n",
      "fold: 0, epoch: 15,                       train_loss : 4.167614108040219, valid_loss : 3.516458511352539\n",
      "fold: 0, epoch: 16,                       train_loss : 4.156381720588321, valid_loss : 3.4795826276143393\n",
      "fold: 1, epoch: 0,                       train_loss : 4.082362299873715, valid_loss : 4.465293248494466\n",
      "fold: 2, epoch: 0,                       train_loss : 4.115444183349609, valid_loss : 4.304056644439697\n",
      "fold: 3, epoch: 0,                       train_loss : 4.081274974913824, valid_loss : 4.041369438171387\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1113840738932295, valid_loss : 4.153386910756429\n",
      "fold: 5, epoch: 0,                       train_loss : 4.12238343556722, valid_loss : 4.03139599164327\n",
      "fold: 6, epoch: 0,                       train_loss : 4.201329855691819, valid_loss : 3.3249313831329346\n",
      "fold: 7, epoch: 0,                       train_loss : 4.149802639370873, valid_loss : 4.10398546854655\n",
      "fold: 8, epoch: 0,                       train_loss : 4.150510606311617, valid_loss : 4.047406037648519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:47:31,190]\u001b[0m Trial 128 finished with value: 4.061345879236857 and parameters: {'num_layers': 4, 'hidden_size': 160, 'batch_size': 130, 'learning_rate': 0.006144048314834992}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.0613269465310236, valid_loss : 4.741935729980469\n",
      "fold: 0, epoch: 0,                       train_loss : 6.034765028953553, valid_loss : 4.316893021265666\n",
      "fold: 0, epoch: 1,                       train_loss : 5.773495531082153, valid_loss : 4.877888123194377\n",
      "fold: 0, epoch: 2,                       train_loss : 5.143144524097442, valid_loss : 3.8458736737569175\n",
      "fold: 0, epoch: 3,                       train_loss : 4.8538313746452335, valid_loss : 4.112298806508382\n",
      "fold: 0, epoch: 4,                       train_loss : 4.721176743507385, valid_loss : 3.739889939626058\n",
      "fold: 0, epoch: 5,                       train_loss : 4.5859904289245605, valid_loss : 3.629615068435669\n",
      "fold: 0, epoch: 6,                       train_loss : 4.6527872562408445, valid_loss : 3.4026182492574057\n",
      "fold: 0, epoch: 7,                       train_loss : 4.408481776714325, valid_loss : 3.8831695715586343\n",
      "fold: 0, epoch: 8,                       train_loss : 4.254577052593231, valid_loss : 3.3886070251464844\n",
      "fold: 0, epoch: 9,                       train_loss : 4.1713613152503966, valid_loss : 3.730952421824137\n",
      "fold: 0, epoch: 10,                       train_loss : 4.225310552120209, valid_loss : 3.7380372683207193\n",
      "fold: 0, epoch: 11,                       train_loss : 4.178084599971771, valid_loss : 4.146538098653157\n",
      "fold: 0, epoch: 12,                       train_loss : 4.170441281795502, valid_loss : 3.704699993133545\n",
      "fold: 0, epoch: 13,                       train_loss : 4.2004554033279415, valid_loss : 3.777641534805298\n",
      "fold: 0, epoch: 14,                       train_loss : 4.16558985710144, valid_loss : 3.9451942443847656\n",
      "fold: 0, epoch: 15,                       train_loss : 4.716989946365357, valid_loss : 3.8150840600331626\n",
      "fold: 0, epoch: 16,                       train_loss : 4.085781365633011, valid_loss : 3.966896931330363\n",
      "fold: 1, epoch: 0,                       train_loss : 4.0094276666641235, valid_loss : 4.870865821838379\n",
      "fold: 2, epoch: 0,                       train_loss : 3.9601619243621826, valid_loss : 5.190681139628093\n",
      "fold: 3, epoch: 0,                       train_loss : 4.114548814296723, valid_loss : 3.8289531071980796\n",
      "fold: 4, epoch: 0,                       train_loss : 4.098929095268249, valid_loss : 4.989391326904297\n",
      "fold: 5, epoch: 0,                       train_loss : 4.017895963788033, valid_loss : 3.8133827845255532\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1577073097229, valid_loss : 4.6406426429748535\n",
      "fold: 7, epoch: 0,                       train_loss : 4.001614487171173, valid_loss : 5.060586134592692\n",
      "fold: 8, epoch: 0,                       train_loss : 4.253254985809326, valid_loss : 3.5557170708974204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:48:01,348]\u001b[0m Trial 129 finished with value: 4.3213007370630905 and parameters: {'num_layers': 4, 'hidden_size': 160, 'batch_size': 140, 'learning_rate': 0.017593351645930257}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.086958944797516, valid_loss : 3.874180316925049\n",
      "fold: 0, epoch: 0,                       train_loss : 6.1187384658389625, valid_loss : 5.485523462295532\n",
      "fold: 0, epoch: 1,                       train_loss : 5.5098404089609785, valid_loss : 4.758342027664185\n",
      "fold: 0, epoch: 2,                       train_loss : 4.6823435756895275, valid_loss : 4.055287003517151\n",
      "fold: 0, epoch: 3,                       train_loss : 4.193635291523403, valid_loss : 3.8915070295333862\n",
      "fold: 0, epoch: 4,                       train_loss : 4.176355176501804, valid_loss : 3.898643374443054\n",
      "fold: 0, epoch: 5,                       train_loss : 4.172344075308906, valid_loss : 3.8873966932296753\n",
      "fold: 0, epoch: 6,                       train_loss : 4.164230280452305, valid_loss : 3.882589817047119\n",
      "fold: 0, epoch: 7,                       train_loss : 4.162489665879144, valid_loss : 3.8887325525283813\n",
      "fold: 0, epoch: 8,                       train_loss : 4.165296488338047, valid_loss : 3.8851836919784546\n",
      "fold: 0, epoch: 9,                       train_loss : 4.153476648860508, valid_loss : 3.8881651163101196\n",
      "fold: 0, epoch: 10,                       train_loss : 4.161533739831713, valid_loss : 3.8846495151519775\n",
      "fold: 0, epoch: 11,                       train_loss : 4.158480564753215, valid_loss : 3.8876760005950928\n",
      "fold: 0, epoch: 12,                       train_loss : 4.158888909551832, valid_loss : 3.8862221240997314\n",
      "fold: 0, epoch: 13,                       train_loss : 4.162011464436849, valid_loss : 3.8875492811203003\n",
      "fold: 0, epoch: 14,                       train_loss : 4.160027199321323, valid_loss : 3.888082265853882\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1576173305511475, valid_loss : 3.8854018449783325\n",
      "fold: 0, epoch: 16,                       train_loss : 4.150340014033848, valid_loss : 3.8832828998565674\n",
      "fold: 1, epoch: 0,                       train_loss : 4.175966170099047, valid_loss : 3.7688536643981934\n",
      "fold: 2, epoch: 0,                       train_loss : 4.186613056394789, valid_loss : 3.7332292795181274\n",
      "fold: 3, epoch: 0,                       train_loss : 4.093513978852166, valid_loss : 4.476703643798828\n",
      "fold: 4, epoch: 0,                       train_loss : 4.207065569029914, valid_loss : 3.5917474031448364\n",
      "fold: 5, epoch: 0,                       train_loss : 4.097490217950609, valid_loss : 4.43082070350647\n",
      "fold: 6, epoch: 0,                       train_loss : 4.077846950954861, valid_loss : 4.634286165237427\n",
      "fold: 7, epoch: 0,                       train_loss : 4.07734039094713, valid_loss : 4.6602067947387695\n",
      "fold: 8, epoch: 0,                       train_loss : 4.214751813146803, valid_loss : 3.5210384130477905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:48:17,329]\u001b[0m Trial 130 finished with value: 4.13930698633194 and parameters: {'num_layers': 3, 'hidden_size': 90, 'batch_size': 150, 'learning_rate': 0.007160730170400681}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.0718245771196155, valid_loss : 4.693593978881836\n",
      "fold: 0, epoch: 0,                       train_loss : 5.621833801269531, valid_loss : 6.345724900563558\n",
      "fold: 0, epoch: 1,                       train_loss : 5.468694596063523, valid_loss : 5.335400501887004\n",
      "fold: 0, epoch: 2,                       train_loss : 5.269687675294422, valid_loss : 5.917442003885905\n",
      "fold: 0, epoch: 3,                       train_loss : 5.124201354526338, valid_loss : 5.2645894686381025\n",
      "fold: 0, epoch: 4,                       train_loss : 5.009179671605428, valid_loss : 5.174318313598633\n",
      "fold: 0, epoch: 5,                       train_loss : 4.856518200465611, valid_loss : 4.851838668187459\n",
      "fold: 0, epoch: 6,                       train_loss : 4.775408483686901, valid_loss : 4.763060808181763\n",
      "fold: 0, epoch: 7,                       train_loss : 4.66777989977882, valid_loss : 4.714817603429158\n",
      "fold: 0, epoch: 8,                       train_loss : 4.556871028173537, valid_loss : 5.1985727945963545\n",
      "fold: 0, epoch: 9,                       train_loss : 4.513149908610752, valid_loss : 4.800580660502116\n",
      "fold: 0, epoch: 10,                       train_loss : 4.437604597636631, valid_loss : 5.206583261489868\n",
      "fold: 0, epoch: 11,                       train_loss : 4.380307606288365, valid_loss : 4.836613178253174\n",
      "fold: 0, epoch: 12,                       train_loss : 4.292958270935785, valid_loss : 4.474917729695638\n",
      "fold: 0, epoch: 13,                       train_loss : 4.300305832000006, valid_loss : 4.274223804473877\n",
      "fold: 0, epoch: 14,                       train_loss : 4.283490385328021, valid_loss : 4.138612349828084\n",
      "fold: 0, epoch: 15,                       train_loss : 4.2548745927356535, valid_loss : 5.413043101628621\n",
      "fold: 0, epoch: 16,                       train_loss : 4.2049811567579, valid_loss : 4.50890572865804\n",
      "fold: 0, epoch: 17,                       train_loss : 4.1677086353302, valid_loss : 4.844479401906331\n",
      "fold: 0, epoch: 18,                       train_loss : 4.15132516906375, valid_loss : 4.368284225463867\n",
      "fold: 0, epoch: 19,                       train_loss : 4.15259363537743, valid_loss : 4.447458585103353\n",
      "fold: 0, epoch: 20,                       train_loss : 4.149168275651478, valid_loss : 4.713325182596843\n",
      "fold: 1, epoch: 0,                       train_loss : 4.245814822968983, valid_loss : 3.662941058476766\n",
      "fold: 2, epoch: 0,                       train_loss : 4.163810060137794, valid_loss : 3.8714140256245932\n",
      "fold: 3, epoch: 0,                       train_loss : 4.0821023895626976, valid_loss : 4.950949827829997\n",
      "fold: 4, epoch: 0,                       train_loss : 4.142344383966355, valid_loss : 4.270244677861531\n",
      "fold: 5, epoch: 0,                       train_loss : 4.13901390348162, valid_loss : 4.230456829071045\n",
      "fold: 6, epoch: 0,                       train_loss : 4.181301196416219, valid_loss : 3.9832207361857095\n",
      "fold: 7, epoch: 0,                       train_loss : 4.095059235890706, valid_loss : 4.294847806294759\n",
      "fold: 8, epoch: 0,                       train_loss : 4.122421855018253, valid_loss : 4.21639068921407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:48:39,369]\u001b[0m Trial 131 finished with value: 4.105078784624736 and parameters: {'num_layers': 4, 'hidden_size': 90, 'batch_size': 130, 'learning_rate': 0.008746308000406827}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.169723703747704, valid_loss : 3.4317098458607993\n",
      "fold: 0, epoch: 0,                       train_loss : 5.704716491699219, valid_loss : 6.645687739054362\n",
      "fold: 0, epoch: 1,                       train_loss : 4.5491751551628115, valid_loss : 4.115314642588298\n",
      "fold: 0, epoch: 2,                       train_loss : 4.133897519111633, valid_loss : 4.085217396418254\n",
      "fold: 0, epoch: 3,                       train_loss : 4.000701695680618, valid_loss : 3.522124449412028\n",
      "fold: 0, epoch: 4,                       train_loss : 4.047940188646317, valid_loss : 4.031123161315918\n",
      "fold: 0, epoch: 5,                       train_loss : 4.015644228458404, valid_loss : 3.9616350332895913\n",
      "fold: 0, epoch: 6,                       train_loss : 4.47029424905777, valid_loss : 3.8452045917510986\n",
      "fold: 0, epoch: 7,                       train_loss : 4.386316096782684, valid_loss : 4.02456267674764\n",
      "fold: 0, epoch: 8,                       train_loss : 4.117501103878022, valid_loss : 4.085231304168701\n",
      "fold: 0, epoch: 9,                       train_loss : 4.065758013725281, valid_loss : 4.104131460189819\n",
      "fold: 0, epoch: 10,                       train_loss : 4.112154293060303, valid_loss : 3.7322256565093994\n",
      "fold: 0, epoch: 11,                       train_loss : 4.285879492759705, valid_loss : 3.5521457195281982\n",
      "fold: 0, epoch: 12,                       train_loss : 4.05743054151535, valid_loss : 5.100974718729655\n",
      "fold: 0, epoch: 13,                       train_loss : 4.023851209878922, valid_loss : 4.4694070021311445\n",
      "fold: 0, epoch: 14,                       train_loss : 4.0967562079429625, valid_loss : 3.851123332977295\n",
      "fold: 1, epoch: 0,                       train_loss : 3.972059667110443, valid_loss : 4.729541619618733\n",
      "fold: 2, epoch: 0,                       train_loss : 4.564041125774383, valid_loss : 3.640223662058512\n",
      "fold: 3, epoch: 0,                       train_loss : 4.043648159503936, valid_loss : 3.62799334526062\n",
      "fold: 4, epoch: 0,                       train_loss : 4.044498836994171, valid_loss : 3.8989311059316\n",
      "fold: 5, epoch: 0,                       train_loss : 4.300756406784058, valid_loss : 3.5978926022847495\n",
      "fold: 6, epoch: 0,                       train_loss : 4.458365035057068, valid_loss : 4.091313441594441\n",
      "fold: 7, epoch: 0,                       train_loss : 4.002089190483093, valid_loss : 4.41552718480428\n",
      "fold: 8, epoch: 0,                       train_loss : 4.076420581340789, valid_loss : 5.189906120300293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:49:01,596]\u001b[0m Trial 132 finished with value: 3.9899112621943154 and parameters: {'num_layers': 6, 'hidden_size': 120, 'batch_size': 140, 'learning_rate': 0.005559168557943001}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.384791624546051, valid_loss : 3.185659090677897\n",
      "fold: 0, epoch: 0,                       train_loss : 5.760575029585096, valid_loss : 5.338653326034546\n",
      "fold: 0, epoch: 1,                       train_loss : 4.635592924224006, valid_loss : 4.227362632751465\n",
      "fold: 0, epoch: 2,                       train_loss : 4.144821604092916, valid_loss : 4.222249507904053\n",
      "fold: 0, epoch: 3,                       train_loss : 4.126335925526089, valid_loss : 4.222277879714966\n",
      "fold: 0, epoch: 4,                       train_loss : 4.128701501422459, valid_loss : 4.217368483543396\n",
      "fold: 0, epoch: 5,                       train_loss : 4.128242082066006, valid_loss : 4.223696708679199\n",
      "fold: 0, epoch: 6,                       train_loss : 4.137851569387648, valid_loss : 4.242570638656616\n",
      "fold: 0, epoch: 7,                       train_loss : 4.112991902563307, valid_loss : 4.228380799293518\n",
      "fold: 0, epoch: 8,                       train_loss : 4.126459625032213, valid_loss : 4.229214310646057\n",
      "fold: 0, epoch: 9,                       train_loss : 4.125578575664097, valid_loss : 4.233021378517151\n",
      "fold: 0, epoch: 10,                       train_loss : 4.132235752211677, valid_loss : 4.218355417251587\n",
      "fold: 0, epoch: 11,                       train_loss : 4.122556977801853, valid_loss : 4.220990538597107\n",
      "fold: 0, epoch: 12,                       train_loss : 4.121172123485142, valid_loss : 4.217984437942505\n",
      "fold: 0, epoch: 13,                       train_loss : 4.120650622579786, valid_loss : 4.220162391662598\n",
      "fold: 0, epoch: 14,                       train_loss : 4.124464723798964, valid_loss : 4.234463453292847\n",
      "fold: 1, epoch: 0,                       train_loss : 4.142399019665188, valid_loss : 4.005215048789978\n",
      "fold: 2, epoch: 0,                       train_loss : 4.034643583827549, valid_loss : 5.1083619594573975\n",
      "fold: 3, epoch: 0,                       train_loss : 4.144612775908576, valid_loss : 4.1103914976119995\n",
      "fold: 4, epoch: 0,                       train_loss : 4.114240368207295, valid_loss : 4.298413872718811\n",
      "fold: 5, epoch: 0,                       train_loss : 4.163338383038838, valid_loss : 3.942912459373474\n",
      "fold: 6, epoch: 0,                       train_loss : 4.199709388944838, valid_loss : 3.5855467319488525\n",
      "fold: 7, epoch: 0,                       train_loss : 4.143578926722209, valid_loss : 4.122665762901306\n",
      "fold: 8, epoch: 0,                       train_loss : 4.11633120642768, valid_loss : 4.299382448196411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:49:21,542]\u001b[0m Trial 133 finished with value: 4.139418637752533 and parameters: {'num_layers': 5, 'hidden_size': 130, 'batch_size': 150, 'learning_rate': 0.005655999506082033}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.192985124058193, valid_loss : 3.7039281129837036\n",
      "fold: 0, epoch: 0,                       train_loss : 5.9773725986480715, valid_loss : 6.8782016436258955\n",
      "fold: 0, epoch: 1,                       train_loss : 5.766064548492432, valid_loss : 4.977951447168986\n",
      "fold: 0, epoch: 2,                       train_loss : 4.313024854660034, valid_loss : 4.169697443644206\n",
      "fold: 0, epoch: 3,                       train_loss : 4.220346367359161, valid_loss : 4.926547129948934\n",
      "fold: 0, epoch: 4,                       train_loss : 4.039992809295654, valid_loss : 4.253285725911458\n",
      "fold: 0, epoch: 5,                       train_loss : 4.027172350883484, valid_loss : 4.120728572209676\n",
      "fold: 0, epoch: 6,                       train_loss : 3.9874498009681703, valid_loss : 3.9250357945760093\n",
      "fold: 0, epoch: 7,                       train_loss : 4.150915586948395, valid_loss : 3.940024216969808\n",
      "fold: 0, epoch: 8,                       train_loss : 4.340898847579956, valid_loss : 4.5062642097473145\n",
      "fold: 0, epoch: 9,                       train_loss : 4.232063102722168, valid_loss : 5.024469375610352\n",
      "fold: 0, epoch: 10,                       train_loss : 4.160477709770203, valid_loss : 4.642902692159017\n",
      "fold: 0, epoch: 11,                       train_loss : 4.027963280677795, valid_loss : 4.276943922042847\n",
      "fold: 0, epoch: 12,                       train_loss : 4.0217438578605655, valid_loss : 4.172578652699788\n",
      "fold: 0, epoch: 13,                       train_loss : 3.9686062216758726, valid_loss : 4.067416350046794\n",
      "fold: 0, epoch: 14,                       train_loss : 3.9640028953552244, valid_loss : 4.239049752553304\n",
      "fold: 0, epoch: 15,                       train_loss : 4.088621020317078, valid_loss : 4.00942333539327\n",
      "fold: 1, epoch: 0,                       train_loss : 4.011747127771377, valid_loss : 3.839050054550171\n",
      "fold: 2, epoch: 0,                       train_loss : 4.090928792953491, valid_loss : 5.917614301045735\n",
      "fold: 3, epoch: 0,                       train_loss : 4.036053168773651, valid_loss : 3.755122661590576\n",
      "fold: 4, epoch: 0,                       train_loss : 4.102382910251618, valid_loss : 4.266613483428955\n",
      "fold: 5, epoch: 0,                       train_loss : 4.093300759792328, valid_loss : 3.5157995223999023\n",
      "fold: 6, epoch: 0,                       train_loss : 3.9999625742435456, valid_loss : 4.524131774902344\n",
      "fold: 7, epoch: 0,                       train_loss : 4.1050230145454405, valid_loss : 4.1481021245320635\n",
      "fold: 8, epoch: 0,                       train_loss : 4.053064960241318, valid_loss : 3.4290188948313394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:49:44,583]\u001b[0m Trial 134 finished with value: 4.077892184257507 and parameters: {'num_layers': 6, 'hidden_size': 120, 'batch_size': 140, 'learning_rate': 0.0050695682391490105}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.058097910881043, valid_loss : 3.458433230717977\n",
      "fold: 0, epoch: 0,                       train_loss : 5.845969873316148, valid_loss : 5.512682676315308\n",
      "fold: 0, epoch: 1,                       train_loss : 5.628473955042222, valid_loss : 5.093399524688721\n",
      "fold: 0, epoch: 2,                       train_loss : 5.024618064655977, valid_loss : 4.25309944152832\n",
      "fold: 0, epoch: 3,                       train_loss : 4.226745100582347, valid_loss : 3.9770206212997437\n",
      "fold: 0, epoch: 4,                       train_loss : 4.1649596831377815, valid_loss : 3.952706217765808\n",
      "fold: 0, epoch: 5,                       train_loss : 4.147240007624907, valid_loss : 3.956565260887146\n",
      "fold: 0, epoch: 6,                       train_loss : 4.151316712884342, valid_loss : 3.972023844718933\n",
      "fold: 0, epoch: 7,                       train_loss : 4.15172150555779, valid_loss : 3.9674601554870605\n",
      "fold: 0, epoch: 8,                       train_loss : 4.178256792180679, valid_loss : 3.971691131591797\n",
      "fold: 0, epoch: 9,                       train_loss : 4.160071765675264, valid_loss : 3.9768651723861694\n",
      "fold: 0, epoch: 10,                       train_loss : 4.14375376701355, valid_loss : 3.9440349340438843\n",
      "fold: 0, epoch: 11,                       train_loss : 4.174754226908965, valid_loss : 3.9643776416778564\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1614695016075585, valid_loss : 4.002844572067261\n",
      "fold: 0, epoch: 13,                       train_loss : 4.15494777174557, valid_loss : 4.007546424865723\n",
      "fold: 0, epoch: 14,                       train_loss : 4.188273233525893, valid_loss : 3.9844948053359985\n",
      "fold: 0, epoch: 15,                       train_loss : 4.136605655445772, valid_loss : 3.949293375015259\n",
      "fold: 0, epoch: 16,                       train_loss : 4.132986194947186, valid_loss : 3.9484798908233643\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1166540314169495, valid_loss : 4.087282180786133\n",
      "fold: 2, epoch: 0,                       train_loss : 4.113759321324966, valid_loss : 4.233399391174316\n",
      "fold: 3, epoch: 0,                       train_loss : 4.116879140629488, valid_loss : 4.516480445861816\n",
      "fold: 4, epoch: 0,                       train_loss : 4.107957755818086, valid_loss : 4.283206462860107\n",
      "fold: 5, epoch: 0,                       train_loss : 4.121559704051299, valid_loss : 4.209824085235596\n",
      "fold: 6, epoch: 0,                       train_loss : 4.106775031370275, valid_loss : 4.362376928329468\n",
      "fold: 7, epoch: 0,                       train_loss : 4.223310162039364, valid_loss : 3.621940851211548\n",
      "fold: 8, epoch: 0,                       train_loss : 4.110674283083747, valid_loss : 4.516972780227661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:50:08,352]\u001b[0m Trial 135 finished with value: 4.13902381658554 and parameters: {'num_layers': 6, 'hidden_size': 150, 'batch_size': 160, 'learning_rate': 0.004081433002043592}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.174531207365148, valid_loss : 3.614720106124878\n",
      "fold: 0, epoch: 0,                       train_loss : 6.242114019393921, valid_loss : 5.880142370859782\n",
      "fold: 0, epoch: 1,                       train_loss : 6.298079657554626, valid_loss : 5.611997127532959\n",
      "fold: 0, epoch: 2,                       train_loss : 5.871440440416336, valid_loss : 5.89400847752889\n",
      "fold: 0, epoch: 3,                       train_loss : 6.05242612361908, valid_loss : 6.159127553304036\n",
      "fold: 0, epoch: 4,                       train_loss : 6.417488956451416, valid_loss : 5.314805507659912\n",
      "fold: 0, epoch: 5,                       train_loss : 5.878749370574951, valid_loss : 4.783457597096761\n",
      "fold: 0, epoch: 6,                       train_loss : 5.620832526683808, valid_loss : 5.766546408335368\n",
      "fold: 0, epoch: 7,                       train_loss : 5.579420447349548, valid_loss : 5.011723359425862\n",
      "fold: 0, epoch: 8,                       train_loss : 5.393556034564972, valid_loss : 4.9347944259643555\n",
      "fold: 0, epoch: 9,                       train_loss : 5.2252797961235045, valid_loss : 4.373850266138713\n",
      "fold: 0, epoch: 10,                       train_loss : 5.334020733833313, valid_loss : 4.7308980623881025\n",
      "fold: 0, epoch: 11,                       train_loss : 5.247471499443054, valid_loss : 4.931130409240723\n",
      "fold: 0, epoch: 12,                       train_loss : 5.037281179428101, valid_loss : 4.30837885538737\n",
      "fold: 0, epoch: 13,                       train_loss : 4.843788075447082, valid_loss : 5.034998019536336\n",
      "fold: 0, epoch: 14,                       train_loss : 4.912389266490936, valid_loss : 4.072520017623901\n",
      "fold: 0, epoch: 15,                       train_loss : 4.569555759429932, valid_loss : 3.8212879498799643\n",
      "fold: 0, epoch: 16,                       train_loss : 4.387442517280578, valid_loss : 3.9348642031351724\n",
      "fold: 0, epoch: 17,                       train_loss : 4.258011138439178, valid_loss : 4.451695919036865\n",
      "fold: 0, epoch: 18,                       train_loss : 4.232818675041199, valid_loss : 3.6290257771809897\n",
      "fold: 0, epoch: 19,                       train_loss : 4.144898164272308, valid_loss : 3.203432559967041\n",
      "fold: 0, epoch: 20,                       train_loss : 4.215084767341613, valid_loss : 3.9521780808766684\n",
      "fold: 1, epoch: 0,                       train_loss : 4.054434335231781, valid_loss : 4.292628765106201\n",
      "fold: 2, epoch: 0,                       train_loss : 4.020591163635254, valid_loss : 4.8061747550964355\n",
      "fold: 3, epoch: 0,                       train_loss : 4.094142282009125, valid_loss : 4.031829833984375\n",
      "fold: 4, epoch: 0,                       train_loss : 4.05358225107193, valid_loss : 4.07679557800293\n",
      "fold: 5, epoch: 0,                       train_loss : 4.1623500943183895, valid_loss : 4.68271525700887\n",
      "fold: 6, epoch: 0,                       train_loss : 4.121332287788391, valid_loss : 3.5993877251942954\n",
      "fold: 7, epoch: 0,                       train_loss : 4.033475017547607, valid_loss : 4.03369943300883\n",
      "fold: 8, epoch: 0,                       train_loss : 4.0391099691390995, valid_loss : 3.623051087061564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:50:43,556]\u001b[0m Trial 136 finished with value: 3.9952070474624626 and parameters: {'num_layers': 4, 'hidden_size': 170, 'batch_size': 140, 'learning_rate': 0.0016228827462967709}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.033843243122101, valid_loss : 3.602355480194092\n",
      "fold: 0, epoch: 0,                       train_loss : 6.310345808664958, valid_loss : 6.256405591964722\n",
      "fold: 0, epoch: 1,                       train_loss : 6.097095463011, valid_loss : 6.020406007766724\n",
      "fold: 0, epoch: 2,                       train_loss : 5.758882072236803, valid_loss : 5.436586856842041\n",
      "fold: 0, epoch: 3,                       train_loss : 4.6415457063251075, valid_loss : 4.304366827011108\n",
      "fold: 0, epoch: 4,                       train_loss : 4.155680431260003, valid_loss : 4.210556268692017\n",
      "fold: 0, epoch: 5,                       train_loss : 4.132543603579204, valid_loss : 4.193015217781067\n",
      "fold: 0, epoch: 6,                       train_loss : 4.132271554734972, valid_loss : 4.191190481185913\n",
      "fold: 0, epoch: 7,                       train_loss : 4.131710555818346, valid_loss : 4.189541935920715\n",
      "fold: 0, epoch: 8,                       train_loss : 4.123888081974453, valid_loss : 4.189741373062134\n",
      "fold: 0, epoch: 9,                       train_loss : 4.123398529158698, valid_loss : 4.201174020767212\n",
      "fold: 0, epoch: 10,                       train_loss : 4.141964475313823, valid_loss : 4.20485246181488\n",
      "fold: 0, epoch: 11,                       train_loss : 4.127063499556647, valid_loss : 4.220452547073364\n",
      "fold: 0, epoch: 12,                       train_loss : 4.122002575132582, valid_loss : 4.202104091644287\n",
      "fold: 0, epoch: 13,                       train_loss : 4.120250489976671, valid_loss : 4.193370342254639\n",
      "fold: 0, epoch: 14,                       train_loss : 4.134644097752041, valid_loss : 4.195626497268677\n",
      "fold: 0, epoch: 15,                       train_loss : 4.139413171344334, valid_loss : 4.203806161880493\n",
      "fold: 0, epoch: 16,                       train_loss : 4.128974662886725, valid_loss : 4.2032798528671265\n",
      "fold: 0, epoch: 17,                       train_loss : 4.123063604036967, valid_loss : 4.207116603851318\n",
      "fold: 0, epoch: 18,                       train_loss : 4.1165856917699175, valid_loss : 4.20039176940918\n",
      "fold: 1, epoch: 0,                       train_loss : 4.101322955555386, valid_loss : 4.350998640060425\n",
      "fold: 2, epoch: 0,                       train_loss : 4.0998622046576605, valid_loss : 4.35263991355896\n",
      "fold: 3, epoch: 0,                       train_loss : 4.158508208062914, valid_loss : 3.983541488647461\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1264488034778175, valid_loss : 4.2274792194366455\n",
      "fold: 5, epoch: 0,                       train_loss : 4.158100816938612, valid_loss : 3.928858757019043\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1498675213919745, valid_loss : 4.031757116317749\n",
      "fold: 7, epoch: 0,                       train_loss : 4.109730031755236, valid_loss : 4.429497718811035\n",
      "fold: 8, epoch: 0,                       train_loss : 4.156093849076165, valid_loss : 4.0107234716415405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:51:04,730]\u001b[0m Trial 137 finished with value: 4.141884219646454 and parameters: {'num_layers': 5, 'hidden_size': 110, 'batch_size': 150, 'learning_rate': 0.00299703075647203}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.157537579536438, valid_loss : 3.9138039350509644\n",
      "fold: 0, epoch: 0,                       train_loss : 5.975520406450544, valid_loss : 6.181524435679118\n",
      "fold: 0, epoch: 1,                       train_loss : 5.967278503236317, valid_loss : 6.138602097829183\n",
      "fold: 0, epoch: 2,                       train_loss : 5.96058143888201, valid_loss : 6.3186642328898115\n",
      "fold: 0, epoch: 3,                       train_loss : 5.935442856379917, valid_loss : 5.967894872029622\n",
      "fold: 0, epoch: 4,                       train_loss : 5.935771942138672, valid_loss : 6.035402615865071\n",
      "fold: 0, epoch: 5,                       train_loss : 5.900079545520601, valid_loss : 6.863071123758952\n",
      "fold: 0, epoch: 6,                       train_loss : 5.924377918243408, valid_loss : 6.9201962153116865\n",
      "fold: 0, epoch: 7,                       train_loss : 5.90003099895659, valid_loss : 6.488049507141113\n",
      "fold: 0, epoch: 8,                       train_loss : 5.858657178424654, valid_loss : 5.749831676483154\n",
      "fold: 0, epoch: 9,                       train_loss : 5.910895052410307, valid_loss : 5.749099572499593\n",
      "fold: 0, epoch: 10,                       train_loss : 5.849558921087356, valid_loss : 6.068462053934733\n",
      "fold: 0, epoch: 11,                       train_loss : 5.847935267857143, valid_loss : 6.371642430623372\n",
      "fold: 0, epoch: 12,                       train_loss : 5.804354849315825, valid_loss : 6.2591525713602705\n",
      "fold: 0, epoch: 13,                       train_loss : 5.7954816818237305, valid_loss : 6.251676718393962\n",
      "fold: 0, epoch: 14,                       train_loss : 5.803251084827242, valid_loss : 6.131560802459717\n",
      "fold: 0, epoch: 15,                       train_loss : 5.754182247888474, valid_loss : 6.677759170532227\n",
      "fold: 1, epoch: 0,                       train_loss : 5.76521787189302, valid_loss : 6.235668182373047\n",
      "fold: 2, epoch: 0,                       train_loss : 5.845730872381301, valid_loss : 4.9167342980702715\n",
      "fold: 3, epoch: 0,                       train_loss : 5.762418769654774, valid_loss : 5.314124584197998\n",
      "fold: 4, epoch: 0,                       train_loss : 5.655348573412214, valid_loss : 6.577130158742269\n",
      "fold: 5, epoch: 0,                       train_loss : 5.700006939115978, valid_loss : 5.179013172785441\n",
      "fold: 6, epoch: 0,                       train_loss : 5.697354952494304, valid_loss : 5.483869870503743\n",
      "fold: 7, epoch: 0,                       train_loss : 5.611313433874221, valid_loss : 5.739102999369304\n",
      "fold: 8, epoch: 0,                       train_loss : 5.633427165803456, valid_loss : 5.43735408782959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:51:28,883]\u001b[0m Trial 138 finished with value: 5.6541336854298905 and parameters: {'num_layers': 6, 'hidden_size': 120, 'batch_size': 130, 'learning_rate': 0.00021922651929371338}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 5.632336003439767, valid_loss : 5.909239927927653\n",
      "fold: 0, epoch: 0,                       train_loss : 6.604463124275208, valid_loss : 5.529590924580892\n",
      "fold: 0, epoch: 1,                       train_loss : 6.113153123855591, valid_loss : 6.13770850499471\n",
      "fold: 0, epoch: 2,                       train_loss : 5.843310862779617, valid_loss : 6.053569475809733\n",
      "fold: 0, epoch: 3,                       train_loss : 5.9789718866348265, valid_loss : 6.959048748016357\n",
      "fold: 0, epoch: 4,                       train_loss : 5.99443666934967, valid_loss : 6.111693541208903\n",
      "fold: 0, epoch: 5,                       train_loss : 5.421393090486527, valid_loss : 5.713770389556885\n",
      "fold: 0, epoch: 6,                       train_loss : 5.384025812149048, valid_loss : 5.235428015391032\n",
      "fold: 0, epoch: 7,                       train_loss : 5.437052989006043, valid_loss : 5.168547948201497\n",
      "fold: 0, epoch: 8,                       train_loss : 5.084435892105103, valid_loss : 5.7367753982543945\n",
      "fold: 0, epoch: 9,                       train_loss : 5.540914678573609, valid_loss : 5.566762765248616\n",
      "fold: 0, epoch: 10,                       train_loss : 5.20291543006897, valid_loss : 4.639248768488566\n",
      "fold: 0, epoch: 11,                       train_loss : 4.807755577564239, valid_loss : 5.736306349436442\n",
      "fold: 0, epoch: 12,                       train_loss : 4.817349910736084, valid_loss : 4.179339965184529\n",
      "fold: 0, epoch: 13,                       train_loss : 4.701742613315583, valid_loss : 4.478645960489909\n",
      "fold: 0, epoch: 14,                       train_loss : 4.841899776458741, valid_loss : 4.688835620880127\n",
      "fold: 0, epoch: 15,                       train_loss : 4.528910434246063, valid_loss : 5.103746096293132\n",
      "fold: 1, epoch: 0,                       train_loss : 4.81609035730362, valid_loss : 3.6738558610280356\n",
      "fold: 2, epoch: 0,                       train_loss : 4.462656676769257, valid_loss : 3.6951181888580322\n",
      "fold: 3, epoch: 0,                       train_loss : 4.368861794471741, valid_loss : 4.476198196411133\n",
      "fold: 4, epoch: 0,                       train_loss : 4.52641578912735, valid_loss : 4.4288530349731445\n",
      "fold: 5, epoch: 0,                       train_loss : 5.011046290397644, valid_loss : 3.8072938919067383\n",
      "fold: 6, epoch: 0,                       train_loss : 4.256609511375427, valid_loss : 4.70010248819987\n",
      "fold: 7, epoch: 0,                       train_loss : 4.494476866722107, valid_loss : 4.1876193682352705\n",
      "fold: 8, epoch: 0,                       train_loss : 4.266219067573547, valid_loss : 4.559766213099162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:51:48,880]\u001b[0m Trial 139 finished with value: 4.216611615816752 and parameters: {'num_layers': 3, 'hidden_size': 100, 'batch_size': 140, 'learning_rate': 0.006767060225227834}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.458898198604584, valid_loss : 4.4579689502716064\n",
      "fold: 0, epoch: 0,                       train_loss : 6.366008591651917, valid_loss : 6.696459452311198\n",
      "fold: 0, epoch: 1,                       train_loss : 5.68134845495224, valid_loss : 5.314482688903809\n",
      "fold: 0, epoch: 2,                       train_loss : 4.086273455619812, valid_loss : 4.668710629145305\n",
      "fold: 0, epoch: 3,                       train_loss : 4.002856403589249, valid_loss : 3.7645832697550454\n",
      "fold: 0, epoch: 4,                       train_loss : 4.11450686454773, valid_loss : 4.046491543451945\n",
      "fold: 0, epoch: 5,                       train_loss : 4.045810532569885, valid_loss : 4.584996620814006\n",
      "fold: 0, epoch: 6,                       train_loss : 4.0092366456985475, valid_loss : 3.956169684727987\n",
      "fold: 0, epoch: 7,                       train_loss : 4.037693721055985, valid_loss : 3.754954179128011\n",
      "fold: 0, epoch: 8,                       train_loss : 4.031906086206436, valid_loss : 4.059602419535319\n",
      "fold: 0, epoch: 9,                       train_loss : 4.0839770317077635, valid_loss : 4.125568628311157\n",
      "fold: 0, epoch: 10,                       train_loss : 4.196265935897827, valid_loss : 4.400665521621704\n",
      "fold: 0, epoch: 11,                       train_loss : 4.1908384442329405, valid_loss : 4.603907108306885\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1181405782699585, valid_loss : 3.7318955262502036\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1049710512161255, valid_loss : 4.333184321721395\n",
      "fold: 0, epoch: 14,                       train_loss : 4.046478259563446, valid_loss : 3.935652732849121\n",
      "fold: 0, epoch: 15,                       train_loss : 4.192447054386139, valid_loss : 3.769984801610311\n",
      "fold: 0, epoch: 16,                       train_loss : 4.023022270202636, valid_loss : 3.982166131337484\n",
      "fold: 1, epoch: 0,                       train_loss : 4.051552522182464, valid_loss : 4.2419984340667725\n",
      "fold: 2, epoch: 0,                       train_loss : 4.05060613155365, valid_loss : 4.609345356623332\n",
      "fold: 3, epoch: 0,                       train_loss : 4.030992496013641, valid_loss : 5.982926845550537\n",
      "fold: 4, epoch: 0,                       train_loss : 4.182360744476318, valid_loss : 4.1287608941396075\n",
      "fold: 5, epoch: 0,                       train_loss : 4.102175569534301, valid_loss : 4.297668377558391\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1323166847229, valid_loss : 3.628308057785034\n",
      "fold: 7, epoch: 0,                       train_loss : 4.178087866306305, valid_loss : 4.269563674926758\n",
      "fold: 8, epoch: 0,                       train_loss : 4.0517718374729155, valid_loss : 4.142045815785726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:52:11,181]\u001b[0m Trial 140 finished with value: 4.417219320933024 and parameters: {'num_layers': 6, 'hidden_size': 110, 'batch_size': 140, 'learning_rate': 0.007876176777683661}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.02939760684967, valid_loss : 5.13968022664388\n",
      "fold: 0, epoch: 0,                       train_loss : 5.552857285454159, valid_loss : 4.229810953140259\n",
      "fold: 0, epoch: 1,                       train_loss : 4.298041990825108, valid_loss : 3.825211763381958\n",
      "fold: 0, epoch: 2,                       train_loss : 4.240448236465454, valid_loss : 3.2489476203918457\n",
      "fold: 0, epoch: 3,                       train_loss : 4.22057074592227, valid_loss : 3.878897269566854\n",
      "fold: 0, epoch: 4,                       train_loss : 4.223926033292498, valid_loss : 3.6369630495707193\n",
      "fold: 0, epoch: 5,                       train_loss : 4.220369350342524, valid_loss : 3.7266746362050376\n",
      "fold: 0, epoch: 6,                       train_loss : 4.191156058084397, valid_loss : 3.5753568013509116\n",
      "fold: 0, epoch: 7,                       train_loss : 4.1993178980691095, valid_loss : 3.7446398735046387\n",
      "fold: 0, epoch: 8,                       train_loss : 4.177042620522635, valid_loss : 3.643988927205404\n",
      "fold: 0, epoch: 9,                       train_loss : 4.2354917753310435, valid_loss : 3.711782455444336\n",
      "fold: 0, epoch: 10,                       train_loss : 4.212872391655331, valid_loss : 3.486722389856974\n",
      "fold: 0, epoch: 11,                       train_loss : 4.181480578013828, valid_loss : 3.5846310456593833\n",
      "fold: 0, epoch: 12,                       train_loss : 4.201639686311994, valid_loss : 3.4891825517018638\n",
      "fold: 0, epoch: 13,                       train_loss : 4.220133497601464, valid_loss : 3.487734238306681\n",
      "fold: 1, epoch: 0,                       train_loss : 4.130834386462257, valid_loss : 5.064966678619385\n",
      "fold: 2, epoch: 0,                       train_loss : 4.137737183343797, valid_loss : 4.085956494013469\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1664338793073386, valid_loss : 4.197750091552734\n",
      "fold: 4, epoch: 0,                       train_loss : 4.114616201037452, valid_loss : 4.343537251154582\n",
      "fold: 5, epoch: 0,                       train_loss : 4.117856627418881, valid_loss : 4.053732077280681\n",
      "fold: 6, epoch: 0,                       train_loss : 4.118962866919381, valid_loss : 4.293693383534749\n",
      "fold: 7, epoch: 0,                       train_loss : 4.116637388865153, valid_loss : 4.069998105367024\n",
      "fold: 8, epoch: 0,                       train_loss : 4.166779098056612, valid_loss : 4.09736696879069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:52:31,918]\u001b[0m Trial 141 finished with value: 4.209497896830241 and parameters: {'num_layers': 6, 'hidden_size': 110, 'batch_size': 130, 'learning_rate': 0.010454921853512293}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.10100067229498, valid_loss : 4.639030297597249\n",
      "fold: 0, epoch: 0,                       train_loss : 6.331938399208917, valid_loss : 5.632673501968384\n",
      "fold: 0, epoch: 1,                       train_loss : 5.5668828752305775, valid_loss : 4.319962382316589\n",
      "fold: 0, epoch: 2,                       train_loss : 4.213039252493116, valid_loss : 3.943297863006592\n",
      "fold: 0, epoch: 3,                       train_loss : 4.175647735595703, valid_loss : 3.9705452919006348\n",
      "fold: 0, epoch: 4,                       train_loss : 4.140439020262824, valid_loss : 3.945836901664734\n",
      "fold: 0, epoch: 5,                       train_loss : 4.166150013605754, valid_loss : 3.964391589164734\n",
      "fold: 0, epoch: 6,                       train_loss : 4.168224652608235, valid_loss : 3.9799457788467407\n",
      "fold: 0, epoch: 7,                       train_loss : 4.153034528096517, valid_loss : 3.965833902359009\n",
      "fold: 0, epoch: 8,                       train_loss : 4.156715936130947, valid_loss : 3.947980046272278\n",
      "fold: 0, epoch: 9,                       train_loss : 4.157737228605482, valid_loss : 3.949396014213562\n",
      "fold: 0, epoch: 10,                       train_loss : 4.16020421187083, valid_loss : 3.976802110671997\n",
      "fold: 0, epoch: 11,                       train_loss : 4.159921964009603, valid_loss : 3.962380051612854\n",
      "fold: 0, epoch: 12,                       train_loss : 4.15867367055681, valid_loss : 3.947964668273926\n",
      "fold: 0, epoch: 13,                       train_loss : 4.151019480493334, valid_loss : 4.023441314697266\n",
      "fold: 1, epoch: 0,                       train_loss : 4.143579191631741, valid_loss : 4.121008634567261\n",
      "fold: 2, epoch: 0,                       train_loss : 4.125026292271084, valid_loss : 4.2435842752456665\n",
      "fold: 3, epoch: 0,                       train_loss : 4.115898264778985, valid_loss : 4.48574686050415\n",
      "fold: 4, epoch: 0,                       train_loss : 4.159607966740926, valid_loss : 4.031537294387817\n",
      "fold: 5, epoch: 0,                       train_loss : 4.162067453066508, valid_loss : 3.8020331859588623\n",
      "fold: 6, epoch: 0,                       train_loss : 4.188413858413696, valid_loss : 3.6316561698913574\n",
      "fold: 7, epoch: 0,                       train_loss : 4.144513805707295, valid_loss : 4.131679534912109\n",
      "fold: 8, epoch: 0,                       train_loss : 4.13429499997033, valid_loss : 4.169541597366333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:52:50,599]\u001b[0m Trial 142 finished with value: 4.137284100055695 and parameters: {'num_layers': 6, 'hidden_size': 120, 'batch_size': 150, 'learning_rate': 0.005717119003887535}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.060970571306017, valid_loss : 4.812755584716797\n",
      "fold: 0, epoch: 0,                       train_loss : 5.599347776836819, valid_loss : 5.87404727935791\n",
      "fold: 0, epoch: 1,                       train_loss : 5.124500883950128, valid_loss : 5.317946434020996\n",
      "fold: 0, epoch: 2,                       train_loss : 4.3976353539360895, valid_loss : 4.69754958152771\n",
      "fold: 0, epoch: 3,                       train_loss : 4.084289564026727, valid_loss : 4.690367937088013\n",
      "fold: 0, epoch: 4,                       train_loss : 4.0777005487018165, valid_loss : 4.683743000030518\n",
      "fold: 0, epoch: 5,                       train_loss : 4.07737750477261, valid_loss : 4.687990665435791\n",
      "fold: 0, epoch: 6,                       train_loss : 4.070349256197612, valid_loss : 4.684197187423706\n",
      "fold: 0, epoch: 7,                       train_loss : 4.062469575140211, valid_loss : 4.688358783721924\n",
      "fold: 0, epoch: 8,                       train_loss : 4.064595739046733, valid_loss : 4.6782450675964355\n",
      "fold: 0, epoch: 9,                       train_loss : 4.0816888146930275, valid_loss : 4.682504177093506\n",
      "fold: 0, epoch: 10,                       train_loss : 4.079909046490987, valid_loss : 4.675053596496582\n",
      "fold: 0, epoch: 11,                       train_loss : 4.073575417200725, valid_loss : 4.683189630508423\n",
      "fold: 0, epoch: 12,                       train_loss : 4.0827307436201306, valid_loss : 4.688476085662842\n",
      "fold: 0, epoch: 13,                       train_loss : 4.064932200643751, valid_loss : 4.694312334060669\n",
      "fold: 0, epoch: 14,                       train_loss : 4.072247770097521, valid_loss : 4.685598850250244\n",
      "fold: 0, epoch: 15,                       train_loss : 4.079244613647461, valid_loss : 4.68393611907959\n",
      "fold: 0, epoch: 16,                       train_loss : 4.077825758192274, valid_loss : 4.681318759918213\n",
      "fold: 0, epoch: 17,                       train_loss : 4.069839715957642, valid_loss : 4.685069561004639\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1167530881034, valid_loss : 4.350125074386597\n",
      "fold: 2, epoch: 0,                       train_loss : 4.065140022171868, valid_loss : 4.7226197719573975\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1797511842515735, valid_loss : 3.7687331438064575\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1307418081495495, valid_loss : 4.213043928146362\n",
      "fold: 5, epoch: 0,                       train_loss : 4.180824359258016, valid_loss : 3.759437918663025\n",
      "fold: 6, epoch: 0,                       train_loss : 4.125478770997789, valid_loss : 4.289417028427124\n",
      "fold: 7, epoch: 0,                       train_loss : 4.09417556391822, valid_loss : 4.5191755294799805\n",
      "fold: 8, epoch: 0,                       train_loss : 4.170672323968676, valid_loss : 3.8790448904037476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:53:09,331]\u001b[0m Trial 143 finished with value: 4.135827672481537 and parameters: {'num_layers': 6, 'hidden_size': 100, 'batch_size': 150, 'learning_rate': 0.004587208755156053}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.25058376789093, valid_loss : 3.1816258430480957\n",
      "fold: 0, epoch: 0,                       train_loss : 6.42313826084137, valid_loss : 6.019999663035075\n",
      "fold: 0, epoch: 1,                       train_loss : 6.531301093101502, valid_loss : 7.007642904917399\n",
      "fold: 0, epoch: 2,                       train_loss : 6.310852432250977, valid_loss : 6.797498067220052\n",
      "fold: 0, epoch: 3,                       train_loss : 6.187786817550659, valid_loss : 5.57890780766805\n",
      "fold: 0, epoch: 4,                       train_loss : 6.364336585998535, valid_loss : 5.407658418019612\n",
      "fold: 0, epoch: 5,                       train_loss : 5.819927716255188, valid_loss : 5.648906230926514\n",
      "fold: 0, epoch: 6,                       train_loss : 5.543004393577576, valid_loss : 5.1765618324279785\n",
      "fold: 0, epoch: 7,                       train_loss : 5.358661484718323, valid_loss : 4.9757927258809405\n",
      "fold: 0, epoch: 8,                       train_loss : 5.282372915744782, valid_loss : 4.271728436152141\n",
      "fold: 0, epoch: 9,                       train_loss : 4.3600900053977965, valid_loss : 4.528424263000488\n",
      "fold: 0, epoch: 10,                       train_loss : 4.139037847518921, valid_loss : 4.938631455103557\n",
      "fold: 0, epoch: 11,                       train_loss : 4.165127789974212, valid_loss : 4.188402811686198\n",
      "fold: 0, epoch: 12,                       train_loss : 3.98795907497406, valid_loss : 4.573653062184651\n",
      "fold: 0, epoch: 13,                       train_loss : 4.094006967544556, valid_loss : 3.8764614264170327\n",
      "fold: 0, epoch: 14,                       train_loss : 4.1283908724784855, valid_loss : 4.138196070988973\n",
      "fold: 0, epoch: 15,                       train_loss : 4.24017196893692, valid_loss : 3.90708597501119\n",
      "fold: 0, epoch: 16,                       train_loss : 4.070970261096955, valid_loss : 3.7669328848520913\n",
      "fold: 0, epoch: 17,                       train_loss : 4.053224885463715, valid_loss : 4.460126876831055\n",
      "fold: 0, epoch: 18,                       train_loss : 4.1561684846878055, valid_loss : 4.1079933643341064\n",
      "fold: 0, epoch: 19,                       train_loss : 4.0471901297569275, valid_loss : 4.833134174346924\n",
      "fold: 1, epoch: 0,                       train_loss : 3.917972147464752, valid_loss : 5.164966901143392\n",
      "fold: 2, epoch: 0,                       train_loss : 3.9833149909973145, valid_loss : 3.909508228302002\n",
      "fold: 3, epoch: 0,                       train_loss : 4.124187874794006, valid_loss : 4.7091108957926435\n",
      "fold: 4, epoch: 0,                       train_loss : 4.010986468195915, valid_loss : 3.6246312459309897\n",
      "fold: 5, epoch: 0,                       train_loss : 4.372653245925903, valid_loss : 4.424033323923747\n",
      "fold: 6, epoch: 0,                       train_loss : 4.0569971084594725, valid_loss : 3.9333628018697104\n",
      "fold: 7, epoch: 0,                       train_loss : 4.037864285707474, valid_loss : 4.181151469548543\n",
      "fold: 8, epoch: 0,                       train_loss : 4.090586590766907, valid_loss : 3.291976014773051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:53:38,675]\u001b[0m Trial 144 finished with value: 4.100172547499338 and parameters: {'num_layers': 6, 'hidden_size': 140, 'batch_size': 140, 'learning_rate': 0.0005137579084429126}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.150557267665863, valid_loss : 3.9960517088572183\n",
      "fold: 0, epoch: 0,                       train_loss : 5.481273969014485, valid_loss : 5.526862621307373\n",
      "fold: 0, epoch: 1,                       train_loss : 4.510540281023298, valid_loss : 4.14520788192749\n",
      "fold: 0, epoch: 2,                       train_loss : 4.165427264713106, valid_loss : 3.9823757807413735\n",
      "fold: 0, epoch: 3,                       train_loss : 4.100824537731352, valid_loss : 3.8112866083780923\n",
      "fold: 0, epoch: 4,                       train_loss : 4.146020242146084, valid_loss : 4.469580094019572\n",
      "fold: 0, epoch: 5,                       train_loss : 4.116479907717023, valid_loss : 3.9036666552225747\n",
      "fold: 0, epoch: 6,                       train_loss : 4.114701611655099, valid_loss : 4.542275587717692\n",
      "fold: 0, epoch: 7,                       train_loss : 4.141936256771996, valid_loss : 3.903904755910238\n",
      "fold: 0, epoch: 8,                       train_loss : 4.133311839330764, valid_loss : 3.8837509950002036\n",
      "fold: 0, epoch: 9,                       train_loss : 4.134922527131581, valid_loss : 4.195270697275798\n",
      "fold: 0, epoch: 10,                       train_loss : 4.14790415763855, valid_loss : 4.954712152481079\n",
      "fold: 0, epoch: 11,                       train_loss : 4.120591674532209, valid_loss : 4.096148173014323\n",
      "fold: 0, epoch: 12,                       train_loss : 4.140626396451678, valid_loss : 4.789129654566447\n",
      "fold: 0, epoch: 13,                       train_loss : 4.175544500350952, valid_loss : 4.365434010823567\n",
      "fold: 0, epoch: 14,                       train_loss : 4.137289183480399, valid_loss : 4.018202781677246\n",
      "fold: 1, epoch: 0,                       train_loss : 4.062054361615862, valid_loss : 4.921027660369873\n",
      "fold: 2, epoch: 0,                       train_loss : 4.161662896474202, valid_loss : 3.7324682076772056\n",
      "fold: 3, epoch: 0,                       train_loss : 4.156371037165324, valid_loss : 3.8908603191375732\n",
      "fold: 4, epoch: 0,                       train_loss : 4.178756168910435, valid_loss : 3.647793928782145\n",
      "fold: 5, epoch: 0,                       train_loss : 4.190815210342407, valid_loss : 3.4685160319010415\n",
      "fold: 6, epoch: 0,                       train_loss : 4.154071353730702, valid_loss : 3.876884380976359\n",
      "fold: 7, epoch: 0,                       train_loss : 4.103214377448673, valid_loss : 4.339269240697225\n",
      "fold: 8, epoch: 0,                       train_loss : 4.11891652288891, valid_loss : 4.25343656539917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:54:05,515]\u001b[0m Trial 145 finished with value: 4.026015750567118 and parameters: {'num_layers': 6, 'hidden_size': 150, 'batch_size': 130, 'learning_rate': 0.006785403156023539}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.082921153023129, valid_loss : 4.318614562352498\n",
      "fold: 0, epoch: 0,                       train_loss : 6.034244275093078, valid_loss : 5.7178928057352705\n",
      "fold: 0, epoch: 1,                       train_loss : 6.019554281234742, valid_loss : 5.355600992838542\n",
      "fold: 0, epoch: 2,                       train_loss : 5.500341022014618, valid_loss : 5.117573102315267\n",
      "fold: 0, epoch: 3,                       train_loss : 5.254418396949768, valid_loss : 4.806466102600098\n",
      "fold: 0, epoch: 4,                       train_loss : 5.047095334529876, valid_loss : 4.3000030517578125\n",
      "fold: 0, epoch: 5,                       train_loss : 4.733294677734375, valid_loss : 4.155770778656006\n",
      "fold: 0, epoch: 6,                       train_loss : 4.206197762489319, valid_loss : 4.8145590623219805\n",
      "fold: 0, epoch: 7,                       train_loss : 4.20133798122406, valid_loss : 4.156322320302327\n",
      "fold: 0, epoch: 8,                       train_loss : 4.336554944515228, valid_loss : 3.8138602574666343\n",
      "fold: 0, epoch: 9,                       train_loss : 4.107876932621002, valid_loss : 4.650760809580485\n",
      "fold: 0, epoch: 10,                       train_loss : 4.083669590950012, valid_loss : 3.509685675303141\n",
      "fold: 0, epoch: 11,                       train_loss : 4.155642294883728, valid_loss : 4.037138779958089\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1157321572303776, valid_loss : 3.8407113552093506\n",
      "fold: 0, epoch: 13,                       train_loss : 4.094210946559906, valid_loss : 4.816543181737264\n",
      "fold: 0, epoch: 14,                       train_loss : 4.015433019399643, valid_loss : 3.5644267400105796\n",
      "fold: 0, epoch: 15,                       train_loss : 4.071606695652008, valid_loss : 3.911271890004476\n",
      "fold: 0, epoch: 16,                       train_loss : 4.0654316425323485, valid_loss : 3.575333913167318\n",
      "fold: 0, epoch: 17,                       train_loss : 4.138352525234223, valid_loss : 3.4899048805236816\n",
      "fold: 0, epoch: 18,                       train_loss : 4.0706260204315186, valid_loss : 3.645549933115641\n",
      "fold: 0, epoch: 19,                       train_loss : 4.071653437614441, valid_loss : 4.303494771321614\n",
      "fold: 1, epoch: 0,                       train_loss : 4.0598526954650875, valid_loss : 3.6696155865987143\n",
      "fold: 2, epoch: 0,                       train_loss : 4.309863543510437, valid_loss : 4.067368984222412\n",
      "fold: 3, epoch: 0,                       train_loss : 3.9986856341362, valid_loss : 4.706620852152507\n",
      "fold: 4, epoch: 0,                       train_loss : 4.002350342273712, valid_loss : 4.862892071406047\n",
      "fold: 5, epoch: 0,                       train_loss : 4.047840344905853, valid_loss : 4.376066207885742\n",
      "fold: 6, epoch: 0,                       train_loss : 4.410474133491516, valid_loss : 3.9295838673909507\n",
      "fold: 7, epoch: 0,                       train_loss : 4.154828524589538, valid_loss : 3.634263753890991\n",
      "fold: 8, epoch: 0,                       train_loss : 4.219939112663269, valid_loss : 3.8799030780792236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:54:33,228]\u001b[0m Trial 146 finished with value: 4.052618781725565 and parameters: {'num_layers': 3, 'hidden_size': 130, 'batch_size': 140, 'learning_rate': 0.009240524062715007}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.329190361499786, valid_loss : 3.909968535105387\n",
      "fold: 0, epoch: 0,                       train_loss : 5.943947190823763, valid_loss : 5.480220317840576\n",
      "fold: 0, epoch: 1,                       train_loss : 5.4761768631313155, valid_loss : 5.006580034891765\n",
      "fold: 0, epoch: 2,                       train_loss : 4.435485435568768, valid_loss : 3.834460496902466\n",
      "fold: 0, epoch: 3,                       train_loss : 4.249636121418165, valid_loss : 3.882338364919027\n",
      "fold: 0, epoch: 4,                       train_loss : 4.12960121942603, valid_loss : 3.8714003562927246\n",
      "fold: 0, epoch: 5,                       train_loss : 4.1005936498227324, valid_loss : 3.9629125595092773\n",
      "fold: 0, epoch: 6,                       train_loss : 4.142614343891973, valid_loss : 3.9445086320241294\n",
      "fold: 0, epoch: 7,                       train_loss : 4.170005984928297, valid_loss : 3.9849499066670737\n",
      "fold: 0, epoch: 8,                       train_loss : 4.148708861807118, valid_loss : 4.079353888829549\n",
      "fold: 0, epoch: 9,                       train_loss : 4.13569738553918, valid_loss : 4.01796023050944\n",
      "fold: 0, epoch: 10,                       train_loss : 4.204942361168239, valid_loss : 3.982800006866455\n",
      "fold: 0, epoch: 11,                       train_loss : 4.122436927712482, valid_loss : 3.9899906317392984\n",
      "fold: 0, epoch: 12,                       train_loss : 4.109604451967322, valid_loss : 3.9131067593892417\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1748178523519766, valid_loss : 4.044029792149861\n",
      "fold: 1, epoch: 0,                       train_loss : 4.071999207786892, valid_loss : 4.343554973602295\n",
      "fold: 2, epoch: 0,                       train_loss : 4.1196877023448115, valid_loss : 4.370527108510335\n",
      "fold: 3, epoch: 0,                       train_loss : 4.165119492489358, valid_loss : 3.6980247497558594\n",
      "fold: 4, epoch: 0,                       train_loss : 4.15319798303687, valid_loss : 3.868405024210612\n",
      "fold: 5, epoch: 0,                       train_loss : 4.0424100419749385, valid_loss : 4.8465352058410645\n",
      "fold: 6, epoch: 0,                       train_loss : 4.0697895236637285, valid_loss : 4.0645120938618975\n",
      "fold: 7, epoch: 0,                       train_loss : 4.159855002942293, valid_loss : 3.788660764694214\n",
      "fold: 8, epoch: 0,                       train_loss : 4.09379592149154, valid_loss : 4.1122080485026045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:54:44,104]\u001b[0m Trial 147 finished with value: 4.106868370374043 and parameters: {'num_layers': 5, 'hidden_size': 40, 'batch_size': 120, 'learning_rate': 0.00739579088233959}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.154044959856116, valid_loss : 4.14179523785909\n",
      "fold: 0, epoch: 0,                       train_loss : 5.872603940963745, valid_loss : 6.842425187428792\n",
      "fold: 0, epoch: 1,                       train_loss : 5.5373098134994505, valid_loss : 6.105478286743164\n",
      "fold: 0, epoch: 2,                       train_loss : 5.435690295696259, valid_loss : 6.08045228322347\n",
      "fold: 0, epoch: 3,                       train_loss : 5.869831538200378, valid_loss : 5.268471876780192\n",
      "fold: 0, epoch: 4,                       train_loss : 5.449595475196839, valid_loss : 5.9231492678324384\n",
      "fold: 0, epoch: 5,                       train_loss : 5.168632853031158, valid_loss : 5.346395969390869\n",
      "fold: 0, epoch: 6,                       train_loss : 5.782717180252075, valid_loss : 6.4579094250996905\n",
      "fold: 0, epoch: 7,                       train_loss : 5.21861081123352, valid_loss : 5.719669342041016\n",
      "fold: 0, epoch: 8,                       train_loss : 4.879956781864166, valid_loss : 5.916994094848633\n",
      "fold: 0, epoch: 9,                       train_loss : 4.78845089673996, valid_loss : 5.309674421946208\n",
      "fold: 0, epoch: 10,                       train_loss : 4.9237104773521425, valid_loss : 6.855103969573975\n",
      "fold: 0, epoch: 11,                       train_loss : 4.734323024749756, valid_loss : 6.164480209350586\n",
      "fold: 0, epoch: 12,                       train_loss : 4.503913497924804, valid_loss : 5.213582197825114\n",
      "fold: 0, epoch: 13,                       train_loss : 4.679125297069549, valid_loss : 4.9876681963602705\n",
      "fold: 0, epoch: 14,                       train_loss : 4.436097729206085, valid_loss : 4.715392827987671\n",
      "fold: 0, epoch: 15,                       train_loss : 4.562772130966186, valid_loss : 4.530950546264648\n",
      "fold: 0, epoch: 16,                       train_loss : 4.592810320854187, valid_loss : 5.858138879140218\n",
      "fold: 0, epoch: 17,                       train_loss : 4.783689069747925, valid_loss : 5.2385478019714355\n",
      "fold: 0, epoch: 18,                       train_loss : 4.238827967643738, valid_loss : 4.81691853205363\n",
      "fold: 1, epoch: 0,                       train_loss : 4.313015055656433, valid_loss : 3.9610118865966797\n",
      "fold: 2, epoch: 0,                       train_loss : 4.425331580638885, valid_loss : 3.9483729203542075\n",
      "fold: 3, epoch: 0,                       train_loss : 4.408525121212006, valid_loss : 3.5619415442148843\n",
      "fold: 4, epoch: 0,                       train_loss : 4.297766172885895, valid_loss : 3.651131788889567\n",
      "fold: 5, epoch: 0,                       train_loss : 4.668333578109741, valid_loss : 4.029766082763672\n",
      "fold: 6, epoch: 0,                       train_loss : 4.201064264774322, valid_loss : 3.7236596743265786\n",
      "fold: 7, epoch: 0,                       train_loss : 4.146995973587036, valid_loss : 3.3577240308125815\n",
      "fold: 8, epoch: 0,                       train_loss : 4.096678054332733, valid_loss : 4.353697061538696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:55:05,840]\u001b[0m Trial 148 finished with value: 3.907833528518677 and parameters: {'num_layers': 6, 'hidden_size': 100, 'batch_size': 140, 'learning_rate': 0.00598472359466331}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.08338760137558, valid_loss : 3.9600797494252524\n",
      "fold: 0, epoch: 0,                       train_loss : 6.428823304176331, valid_loss : 6.158008098602295\n",
      "fold: 0, epoch: 1,                       train_loss : 5.26268025636673, valid_loss : 4.986702124277751\n",
      "fold: 0, epoch: 2,                       train_loss : 4.14559291601181, valid_loss : 4.173435052235921\n",
      "fold: 0, epoch: 3,                       train_loss : 4.028169691562653, valid_loss : 3.8276752630869546\n",
      "fold: 0, epoch: 4,                       train_loss : 3.962966713309288, valid_loss : 4.367697556813558\n",
      "fold: 0, epoch: 5,                       train_loss : 4.040508306026458, valid_loss : 4.939465602238973\n",
      "fold: 0, epoch: 6,                       train_loss : 3.9627871036529543, valid_loss : 4.316722869873047\n",
      "fold: 0, epoch: 7,                       train_loss : 4.405265700817108, valid_loss : 4.685227553049724\n",
      "fold: 0, epoch: 8,                       train_loss : 4.084857976436615, valid_loss : 3.960538705190023\n",
      "fold: 0, epoch: 9,                       train_loss : 4.000519430637359, valid_loss : 4.1772933801015215\n",
      "fold: 0, epoch: 10,                       train_loss : 4.004817402362823, valid_loss : 3.749991257985433\n",
      "fold: 0, epoch: 11,                       train_loss : 4.024651765823364, valid_loss : 4.07943868637085\n",
      "fold: 0, epoch: 12,                       train_loss : 4.295941591262817, valid_loss : 4.722874164581299\n",
      "fold: 0, epoch: 13,                       train_loss : 4.05142571926117, valid_loss : 4.118771394093831\n",
      "fold: 0, epoch: 14,                       train_loss : 4.087920725345612, valid_loss : 4.356130917867024\n",
      "fold: 0, epoch: 15,                       train_loss : 4.412892127037049, valid_loss : 4.88969890276591\n",
      "fold: 1, epoch: 0,                       train_loss : 4.179184150695801, valid_loss : 4.371166388193767\n",
      "fold: 2, epoch: 0,                       train_loss : 4.3978081226348875, valid_loss : 3.506908337275187\n",
      "fold: 3, epoch: 0,                       train_loss : 4.115199768543244, valid_loss : 3.990884860356649\n",
      "fold: 4, epoch: 0,                       train_loss : 4.0801638722419735, valid_loss : 3.973414182662964\n",
      "fold: 5, epoch: 0,                       train_loss : 4.060950875282288, valid_loss : 3.9249743620554605\n",
      "fold: 6, epoch: 0,                       train_loss : 4.323393487930298, valid_loss : 4.126566648483276\n",
      "fold: 7, epoch: 0,                       train_loss : 4.113042211532592, valid_loss : 4.560527960459392\n",
      "fold: 8, epoch: 0,                       train_loss : 4.012507009506225, valid_loss : 3.6236268679300943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:55:25,199]\u001b[0m Trial 149 finished with value: 4.01811470190684 and parameters: {'num_layers': 6, 'hidden_size': 100, 'batch_size': 140, 'learning_rate': 0.005920825665173988}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.0088648200035095, valid_loss : 4.353086153666179\n",
      "fold: 0, epoch: 0,                       train_loss : 6.426750130123562, valid_loss : 6.458808898925781\n",
      "fold: 0, epoch: 1,                       train_loss : 6.333450767729017, valid_loss : 6.362838506698608\n",
      "fold: 0, epoch: 2,                       train_loss : 6.202311780717638, valid_loss : 6.21788763999939\n",
      "fold: 0, epoch: 3,                       train_loss : 6.049024528927273, valid_loss : 6.018517971038818\n",
      "fold: 0, epoch: 4,                       train_loss : 5.803472571902805, valid_loss : 5.738809823989868\n",
      "fold: 0, epoch: 5,                       train_loss : 5.478313525517781, valid_loss : 5.373492002487183\n",
      "fold: 0, epoch: 6,                       train_loss : 4.960303412543403, valid_loss : 4.698024034500122\n",
      "fold: 0, epoch: 7,                       train_loss : 4.1839280128479, valid_loss : 4.322488069534302\n",
      "fold: 0, epoch: 8,                       train_loss : 4.104089034928216, valid_loss : 4.320132493972778\n",
      "fold: 0, epoch: 9,                       train_loss : 4.105859849188063, valid_loss : 4.318576097488403\n",
      "fold: 0, epoch: 10,                       train_loss : 4.132814592785305, valid_loss : 4.324119329452515\n",
      "fold: 0, epoch: 11,                       train_loss : 4.112506058481005, valid_loss : 4.32357656955719\n",
      "fold: 0, epoch: 12,                       train_loss : 4.127528892623054, valid_loss : 4.316209673881531\n",
      "fold: 0, epoch: 13,                       train_loss : 4.11104502942827, valid_loss : 4.31404173374176\n",
      "fold: 0, epoch: 14,                       train_loss : 4.117797931035359, valid_loss : 4.323024034500122\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1081490649117365, valid_loss : 4.314974784851074\n",
      "fold: 0, epoch: 16,                       train_loss : 4.126124103864034, valid_loss : 4.316938638687134\n",
      "fold: 0, epoch: 17,                       train_loss : 4.119275609652202, valid_loss : 4.319691181182861\n",
      "fold: 0, epoch: 18,                       train_loss : 4.111990888913472, valid_loss : 4.321717143058777\n",
      "fold: 0, epoch: 19,                       train_loss : 4.107910646332635, valid_loss : 4.319965600967407\n",
      "fold: 0, epoch: 20,                       train_loss : 4.113459044032627, valid_loss : 4.315288782119751\n",
      "fold: 0, epoch: 21,                       train_loss : 4.112030943234761, valid_loss : 4.310024857521057\n",
      "fold: 0, epoch: 22,                       train_loss : 4.115709185600281, valid_loss : 4.318958044052124\n",
      "fold: 0, epoch: 23,                       train_loss : 4.11528389983707, valid_loss : 4.325985431671143\n",
      "fold: 1, epoch: 0,                       train_loss : 4.189280390739441, valid_loss : 3.728495478630066\n",
      "fold: 2, epoch: 0,                       train_loss : 4.166319198078579, valid_loss : 3.948962092399597\n",
      "fold: 3, epoch: 0,                       train_loss : 4.183729251225789, valid_loss : 3.715957760810852\n",
      "fold: 4, epoch: 0,                       train_loss : 4.1264808840221825, valid_loss : 4.146258234977722\n",
      "fold: 5, epoch: 0,                       train_loss : 4.108503911230299, valid_loss : 4.374570846557617\n",
      "fold: 6, epoch: 0,                       train_loss : 4.096275753445095, valid_loss : 4.474436283111572\n",
      "fold: 7, epoch: 0,                       train_loss : 4.186815910869175, valid_loss : 3.686574935913086\n",
      "fold: 8, epoch: 0,                       train_loss : 4.106272101402283, valid_loss : 4.469935655593872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:55:49,888]\u001b[0m Trial 150 finished with value: 4.140990674495697 and parameters: {'num_layers': 5, 'hidden_size': 110, 'batch_size': 150, 'learning_rate': 0.0035330135833158815}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.086185110939874, valid_loss : 4.554690599441528\n",
      "fold: 0, epoch: 0,                       train_loss : 5.960757207870484, valid_loss : 5.217887083689372\n",
      "fold: 0, epoch: 1,                       train_loss : 5.347854995727539, valid_loss : 4.558098475138347\n",
      "fold: 0, epoch: 2,                       train_loss : 4.268206524848938, valid_loss : 5.080677032470703\n",
      "fold: 0, epoch: 3,                       train_loss : 4.248686790466309, valid_loss : 3.791719436645508\n",
      "fold: 0, epoch: 4,                       train_loss : 4.106169211864471, valid_loss : 4.330068270365397\n",
      "fold: 0, epoch: 5,                       train_loss : 4.025091683864593, valid_loss : 4.3377329508463545\n",
      "fold: 0, epoch: 6,                       train_loss : 4.003226113319397, valid_loss : 4.328188975652059\n",
      "fold: 0, epoch: 7,                       train_loss : 4.000270915031433, valid_loss : 3.9507394631703696\n",
      "fold: 0, epoch: 8,                       train_loss : 3.974788612127304, valid_loss : 4.367481708526611\n",
      "fold: 0, epoch: 9,                       train_loss : 4.221147155761718, valid_loss : 4.962396621704102\n",
      "fold: 0, epoch: 10,                       train_loss : 4.056911027431488, valid_loss : 4.06672469774882\n",
      "fold: 0, epoch: 11,                       train_loss : 4.054434537887573, valid_loss : 4.632157484690349\n",
      "fold: 0, epoch: 12,                       train_loss : 4.127464091777801, valid_loss : 3.8179890314737954\n",
      "fold: 0, epoch: 13,                       train_loss : 4.149669671058655, valid_loss : 4.14910348256429\n",
      "fold: 1, epoch: 0,                       train_loss : 4.061650192737579, valid_loss : 4.406950155893962\n",
      "fold: 2, epoch: 0,                       train_loss : 4.175875341892242, valid_loss : 4.49362850189209\n",
      "fold: 3, epoch: 0,                       train_loss : 4.2511110544204715, valid_loss : 4.4405585924784345\n",
      "fold: 4, epoch: 0,                       train_loss : 4.052316105365753, valid_loss : 5.93560791015625\n",
      "fold: 5, epoch: 0,                       train_loss : 4.253251445293427, valid_loss : 4.269513527552287\n",
      "fold: 6, epoch: 0,                       train_loss : 3.995379400253296, valid_loss : 4.670331557591756\n",
      "fold: 7, epoch: 0,                       train_loss : 4.06293203830719, valid_loss : 3.55621067682902\n",
      "fold: 8, epoch: 0,                       train_loss : 4.2062605857849125, valid_loss : 3.7355955441792807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:56:06,268]\u001b[0m Trial 151 finished with value: 4.37062250773112 and parameters: {'num_layers': 6, 'hidden_size': 90, 'batch_size': 140, 'learning_rate': 0.005468487062361773}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.231724119186401, valid_loss : 4.40610917409261\n",
      "fold: 0, epoch: 0,                       train_loss : 6.070889563787551, valid_loss : 5.867075284322103\n",
      "fold: 0, epoch: 1,                       train_loss : 4.694260472343082, valid_loss : 4.45883313814799\n",
      "fold: 0, epoch: 2,                       train_loss : 4.122376214890253, valid_loss : 4.73535696665446\n",
      "fold: 0, epoch: 3,                       train_loss : 4.134165559496198, valid_loss : 4.406452655792236\n",
      "fold: 0, epoch: 4,                       train_loss : 4.093222924641201, valid_loss : 4.545321782430013\n",
      "fold: 0, epoch: 5,                       train_loss : 4.072051967893328, valid_loss : 4.563320636749268\n",
      "fold: 0, epoch: 6,                       train_loss : 4.121203138714745, valid_loss : 5.005757808685303\n",
      "fold: 0, epoch: 7,                       train_loss : 4.1267697016398115, valid_loss : 4.310115734736125\n",
      "fold: 0, epoch: 8,                       train_loss : 4.108748742512295, valid_loss : 4.639734745025635\n",
      "fold: 0, epoch: 9,                       train_loss : 4.116418055125645, valid_loss : 4.62407128016154\n",
      "fold: 0, epoch: 10,                       train_loss : 4.111652782985142, valid_loss : 4.644349098205566\n",
      "fold: 0, epoch: 11,                       train_loss : 4.101364147095453, valid_loss : 4.313281536102295\n",
      "fold: 0, epoch: 12,                       train_loss : 4.091614484786987, valid_loss : 4.370159546534221\n",
      "fold: 0, epoch: 13,                       train_loss : 4.116527761731829, valid_loss : 4.245173295338948\n",
      "fold: 0, epoch: 14,                       train_loss : 4.113445281982422, valid_loss : 4.517247358957927\n",
      "fold: 0, epoch: 15,                       train_loss : 4.133356366838727, valid_loss : 4.432621002197266\n",
      "fold: 1, epoch: 0,                       train_loss : 4.131490230560303, valid_loss : 4.87612247467041\n",
      "fold: 2, epoch: 0,                       train_loss : 4.127902416955857, valid_loss : 4.043729066848755\n",
      "fold: 3, epoch: 0,                       train_loss : 4.071047941843669, valid_loss : 4.613012393315633\n",
      "fold: 4, epoch: 0,                       train_loss : 4.0925440561203725, valid_loss : 4.308562119801839\n",
      "fold: 5, epoch: 0,                       train_loss : 4.146384693327404, valid_loss : 3.9020551840464273\n",
      "fold: 6, epoch: 0,                       train_loss : 4.0649458680834085, valid_loss : 4.564088344573975\n",
      "fold: 7, epoch: 0,                       train_loss : 4.2152243341718405, valid_loss : 3.274049917856852\n",
      "fold: 8, epoch: 0,                       train_loss : 4.16184603600275, valid_loss : 3.872838815053304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:56:26,825]\u001b[0m Trial 152 finished with value: 4.159164174397786 and parameters: {'num_layers': 6, 'hidden_size': 100, 'batch_size': 130, 'learning_rate': 0.008542597545840955}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.14593996320452, valid_loss : 3.8920101324717202\n",
      "fold: 0, epoch: 0,                       train_loss : 6.281604903084891, valid_loss : 5.965981960296631\n",
      "fold: 0, epoch: 1,                       train_loss : 5.930203188033331, valid_loss : 5.62259308497111\n",
      "fold: 0, epoch: 2,                       train_loss : 5.125042370387486, valid_loss : 4.3860039710998535\n",
      "fold: 0, epoch: 3,                       train_loss : 4.174309401285081, valid_loss : 3.964193820953369\n",
      "fold: 0, epoch: 4,                       train_loss : 4.1331511452084495, valid_loss : 3.9475186665852866\n",
      "fold: 0, epoch: 5,                       train_loss : 4.134638740902855, valid_loss : 3.9800577958424888\n",
      "fold: 0, epoch: 6,                       train_loss : 4.146656819752285, valid_loss : 3.9355850219726562\n",
      "fold: 0, epoch: 7,                       train_loss : 4.127236445744832, valid_loss : 4.041507800420125\n",
      "fold: 0, epoch: 8,                       train_loss : 4.147427456719535, valid_loss : 4.035340944925944\n",
      "fold: 0, epoch: 9,                       train_loss : 4.138483898980277, valid_loss : 3.6965940793355307\n",
      "fold: 0, epoch: 10,                       train_loss : 4.12799866994222, valid_loss : 3.8520344893137612\n",
      "fold: 0, epoch: 11,                       train_loss : 4.135266883032663, valid_loss : 4.261781136194865\n",
      "fold: 0, epoch: 12,                       train_loss : 4.135862986246745, valid_loss : 3.8842945098876953\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1488579000745505, valid_loss : 3.9337488810221353\n",
      "fold: 0, epoch: 14,                       train_loss : 4.1553886617933005, valid_loss : 3.886161724726359\n",
      "fold: 0, epoch: 15,                       train_loss : 4.157002755573818, valid_loss : 4.361804246902466\n",
      "fold: 0, epoch: 16,                       train_loss : 4.132937102090745, valid_loss : 3.717756191889445\n",
      "fold: 0, epoch: 17,                       train_loss : 4.12652774084182, valid_loss : 3.8153813680013022\n",
      "fold: 1, epoch: 0,                       train_loss : 4.119773649034046, valid_loss : 4.143050114313762\n",
      "fold: 2, epoch: 0,                       train_loss : 4.12497649874006, valid_loss : 4.457137982050578\n",
      "fold: 3, epoch: 0,                       train_loss : 4.174257505507696, valid_loss : 3.724331855773926\n",
      "fold: 4, epoch: 0,                       train_loss : 4.114354485557193, valid_loss : 4.877557595570882\n",
      "fold: 5, epoch: 0,                       train_loss : 4.166903268723261, valid_loss : 3.8175268173217773\n",
      "fold: 6, epoch: 0,                       train_loss : 4.129591771534511, valid_loss : 4.149480819702148\n",
      "fold: 7, epoch: 0,                       train_loss : 4.158518779845465, valid_loss : 3.9670600096384683\n",
      "fold: 8, epoch: 0,                       train_loss : 4.182617823282878, valid_loss : 4.047613859176636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:56:50,989]\u001b[0m Trial 153 finished with value: 4.161157576243083 and parameters: {'num_layers': 6, 'hidden_size': 110, 'batch_size': 130, 'learning_rate': 0.0048270964408704455}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.058880703789847, valid_loss : 4.731222629547119\n",
      "fold: 0, epoch: 0,                       train_loss : 5.2401725133260095, valid_loss : 4.353815972805023\n",
      "fold: 0, epoch: 1,                       train_loss : 4.150276645024618, valid_loss : 4.715687096118927\n",
      "fold: 0, epoch: 2,                       train_loss : 4.134186013539632, valid_loss : 4.186713397502899\n",
      "fold: 0, epoch: 3,                       train_loss : 4.112810858090719, valid_loss : 4.781735360622406\n",
      "fold: 0, epoch: 4,                       train_loss : 4.102486888567607, valid_loss : 4.068309128284454\n",
      "fold: 0, epoch: 5,                       train_loss : 4.1307108163833615, valid_loss : 4.280444502830505\n",
      "fold: 0, epoch: 6,                       train_loss : 4.118343059221903, valid_loss : 4.541643798351288\n",
      "fold: 0, epoch: 7,                       train_loss : 4.1430806239446, valid_loss : 4.241148948669434\n",
      "fold: 0, epoch: 8,                       train_loss : 4.121552475293478, valid_loss : 4.116517603397369\n",
      "fold: 0, epoch: 9,                       train_loss : 4.120778687795004, valid_loss : 4.099120557308197\n",
      "fold: 0, epoch: 10,                       train_loss : 4.121856832504273, valid_loss : 4.401938855648041\n",
      "fold: 0, epoch: 11,                       train_loss : 4.120189706484477, valid_loss : 4.312021017074585\n",
      "fold: 0, epoch: 12,                       train_loss : 4.1359994570414225, valid_loss : 4.247014939785004\n",
      "fold: 0, epoch: 13,                       train_loss : 4.131069334348043, valid_loss : 4.191464424133301\n",
      "fold: 1, epoch: 0,                       train_loss : 4.081404248873393, valid_loss : 4.645676255226135\n",
      "fold: 2, epoch: 0,                       train_loss : 4.182887077331543, valid_loss : 4.053658723831177\n",
      "fold: 3, epoch: 0,                       train_loss : 4.1531537214914955, valid_loss : 4.046291947364807\n",
      "fold: 4, epoch: 0,                       train_loss : 4.14846982161204, valid_loss : 4.079879999160767\n",
      "fold: 5, epoch: 0,                       train_loss : 4.173707667986552, valid_loss : 4.59665846824646\n",
      "fold: 6, epoch: 0,                       train_loss : 4.1918929735819495, valid_loss : 3.6908264756202698\n",
      "fold: 7, epoch: 0,                       train_loss : 4.090040485064189, valid_loss : 4.156295120716095\n",
      "fold: 8, epoch: 0,                       train_loss : 4.117185020446778, valid_loss : 4.173495650291443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:57:21,645]\u001b[0m Trial 154 finished with value: 4.09763018488884 and parameters: {'num_layers': 6, 'hidden_size': 120, 'batch_size': 90, 'learning_rate': 0.006294971977454533}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.1996369043986, valid_loss : 3.4652100801467896\n",
      "fold: 0, epoch: 0,                       train_loss : 6.693459844589233, valid_loss : 5.5513254801432295\n",
      "fold: 0, epoch: 1,                       train_loss : 5.389466392993927, valid_loss : 4.469279130299886\n",
      "fold: 0, epoch: 2,                       train_loss : 4.168750071525574, valid_loss : 5.044005314509074\n",
      "fold: 0, epoch: 3,                       train_loss : 4.239468407630921, valid_loss : 3.582475026448568\n",
      "fold: 0, epoch: 4,                       train_loss : 4.10731817483902, valid_loss : 3.5655012130737305\n",
      "fold: 0, epoch: 5,                       train_loss : 4.010587188601494, valid_loss : 3.74129589398702\n",
      "fold: 0, epoch: 6,                       train_loss : 4.037904548645019, valid_loss : 3.6386450926462808\n",
      "fold: 0, epoch: 7,                       train_loss : 4.347992491722107, valid_loss : 3.6141648292541504\n",
      "fold: 0, epoch: 8,                       train_loss : 4.267099809646607, valid_loss : 3.626784642537435\n",
      "fold: 0, epoch: 9,                       train_loss : 4.237562036514282, valid_loss : 3.8198896249135337\n",
      "fold: 0, epoch: 10,                       train_loss : 4.054833352565765, valid_loss : 3.622236649195353\n",
      "fold: 0, epoch: 11,                       train_loss : 4.139082515239716, valid_loss : 3.521533727645874\n",
      "fold: 0, epoch: 12,                       train_loss : 4.034273159503937, valid_loss : 4.0378594398498535\n",
      "fold: 0, epoch: 13,                       train_loss : 4.458754372596741, valid_loss : 4.1748701731363935\n",
      "fold: 0, epoch: 14,                       train_loss : 4.264083075523376, valid_loss : 4.0677699247996015\n",
      "fold: 0, epoch: 15,                       train_loss : 4.089307737350464, valid_loss : 3.9934922059377036\n",
      "fold: 1, epoch: 0,                       train_loss : 4.024341118335724, valid_loss : 3.5610052744547525\n",
      "fold: 2, epoch: 0,                       train_loss : 4.135813021659851, valid_loss : 3.9123191038767495\n",
      "fold: 3, epoch: 0,                       train_loss : 4.508840298652649, valid_loss : 4.649135589599609\n",
      "fold: 4, epoch: 0,                       train_loss : 4.230121457576752, valid_loss : 4.362669150034587\n",
      "fold: 5, epoch: 0,                       train_loss : 4.1338212251663204, valid_loss : 4.871727466583252\n",
      "fold: 6, epoch: 0,                       train_loss : 3.974826690554619, valid_loss : 3.9585092067718506\n",
      "fold: 7, epoch: 0,                       train_loss : 4.1059651374816895, valid_loss : 3.7298421065012612\n",
      "fold: 8, epoch: 0,                       train_loss : 4.042551326751709, valid_loss : 3.8015814622243247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:57:41,357]\u001b[0m Trial 155 finished with value: 4.054539847373963 and parameters: {'num_layers': 6, 'hidden_size': 100, 'batch_size': 140, 'learning_rate': 0.007895297904349138}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.318140125274658, valid_loss : 4.177075386047363\n",
      "fold: 0, epoch: 0,                       train_loss : 6.212063153584798, valid_loss : 5.568040370941162\n",
      "fold: 0, epoch: 1,                       train_loss : 5.4194479253556995, valid_loss : 4.600617170333862\n",
      "fold: 0, epoch: 2,                       train_loss : 4.479208827018738, valid_loss : 3.923772692680359\n",
      "fold: 0, epoch: 3,                       train_loss : 4.1766221390830145, valid_loss : 3.927155375480652\n",
      "fold: 0, epoch: 4,                       train_loss : 4.178692287868923, valid_loss : 3.909999370574951\n",
      "fold: 0, epoch: 5,                       train_loss : 4.174070398012797, valid_loss : 3.900267004966736\n",
      "fold: 0, epoch: 6,                       train_loss : 4.167955716451009, valid_loss : 3.906646728515625\n",
      "fold: 0, epoch: 7,                       train_loss : 4.15151243739658, valid_loss : 3.897836685180664\n",
      "fold: 0, epoch: 8,                       train_loss : 4.160747607549031, valid_loss : 3.9047707319259644\n",
      "fold: 0, epoch: 9,                       train_loss : 4.163711706797282, valid_loss : 3.8996561765670776\n",
      "fold: 0, epoch: 10,                       train_loss : 4.1595463620291815, valid_loss : 3.9058109521865845\n",
      "fold: 0, epoch: 11,                       train_loss : 4.159234351581997, valid_loss : 3.9028401374816895\n",
      "fold: 0, epoch: 12,                       train_loss : 4.155793044302198, valid_loss : 3.9029574394226074\n",
      "fold: 0, epoch: 13,                       train_loss : 4.158530804846022, valid_loss : 3.90730619430542\n",
      "fold: 0, epoch: 14,                       train_loss : 4.168947524494595, valid_loss : 3.907163143157959\n",
      "fold: 0, epoch: 15,                       train_loss : 4.1721621884240045, valid_loss : 3.890008807182312\n",
      "fold: 0, epoch: 16,                       train_loss : 4.174596005015903, valid_loss : 3.894997715950012\n",
      "fold: 0, epoch: 17,                       train_loss : 4.161231875419617, valid_loss : 3.906316876411438\n",
      "fold: 1, epoch: 0,                       train_loss : 4.1337793005837336, valid_loss : 4.197941303253174\n",
      "fold: 2, epoch: 0,                       train_loss : 4.083076357841492, valid_loss : 4.54585325717926\n",
      "fold: 3, epoch: 0,                       train_loss : 4.054522885216607, valid_loss : 4.852130174636841\n",
      "fold: 4, epoch: 0,                       train_loss : 4.17564062277476, valid_loss : 3.8202099800109863\n",
      "fold: 5, epoch: 0,                       train_loss : 4.168950504726833, valid_loss : 3.8100037574768066\n",
      "fold: 6, epoch: 0,                       train_loss : 4.154820375972324, valid_loss : 3.9991403818130493\n",
      "fold: 7, epoch: 0,                       train_loss : 4.172074013286167, valid_loss : 4.008497834205627\n",
      "fold: 8, epoch: 0,                       train_loss : 4.165256248580085, valid_loss : 3.9117023944854736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:57:55,643]\u001b[0m Trial 156 finished with value: 4.134526646137237 and parameters: {'num_layers': 4, 'hidden_size': 70, 'batch_size': 150, 'learning_rate': 0.011976593402695591}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.118316438462999, valid_loss : 4.309778571128845\n",
      "fold: 0, epoch: 0,                       train_loss : 5.860540685199556, valid_loss : 5.153024673461914\n",
      "fold: 0, epoch: 1,                       train_loss : 4.609177192052205, valid_loss : 4.042522271474202\n",
      "fold: 0, epoch: 2,                       train_loss : 4.206758692151024, valid_loss : 4.314274390538533\n",
      "fold: 0, epoch: 3,                       train_loss : 4.166277192887806, valid_loss : 4.118557055791219\n",
      "fold: 0, epoch: 4,                       train_loss : 4.138372205552601, valid_loss : 3.985746701558431\n",
      "fold: 0, epoch: 5,                       train_loss : 4.1381783826010565, valid_loss : 3.8032871882120767\n",
      "fold: 0, epoch: 6,                       train_loss : 4.123639367875599, valid_loss : 3.7316733996073403\n",
      "fold: 0, epoch: 7,                       train_loss : 4.18082062403361, valid_loss : 4.305469751358032\n",
      "fold: 0, epoch: 8,                       train_loss : 4.15942028590611, valid_loss : 3.9045868714650473\n",
      "fold: 0, epoch: 9,                       train_loss : 4.152586460113525, valid_loss : 3.6961922645568848\n",
      "fold: 0, epoch: 10,                       train_loss : 4.149218014308384, valid_loss : 4.008758068084717\n",
      "fold: 0, epoch: 11,                       train_loss : 4.160382384345645, valid_loss : 4.028923273086548\n",
      "fold: 0, epoch: 12,                       train_loss : 4.159028779892695, valid_loss : 3.8140273888905845\n",
      "fold: 0, epoch: 13,                       train_loss : 4.1445486432030085, valid_loss : 4.124095598856608\n",
      "fold: 0, epoch: 14,                       train_loss : 4.165480046045213, valid_loss : 4.135403394699097\n",
      "fold: 0, epoch: 15,                       train_loss : 4.129840544291905, valid_loss : 4.135775566101074\n",
      "fold: 0, epoch: 16,                       train_loss : 4.136647780736287, valid_loss : 4.373920838038127\n",
      "fold: 1, epoch: 0,                       train_loss : 4.155044215066092, valid_loss : 3.882171154022217\n",
      "fold: 2, epoch: 0,                       train_loss : 4.108262289138067, valid_loss : 4.449344555536906\n",
      "fold: 3, epoch: 0,                       train_loss : 4.133780286425636, valid_loss : 4.477529287338257\n",
      "fold: 4, epoch: 0,                       train_loss : 4.171204146884737, valid_loss : 3.581892649332682\n",
      "fold: 5, epoch: 0,                       train_loss : 4.158284561974662, valid_loss : 3.6870402495066323\n",
      "fold: 6, epoch: 0,                       train_loss : 4.167718660263788, valid_loss : 3.6803066730499268\n",
      "fold: 7, epoch: 0,                       train_loss : 4.14861968585423, valid_loss : 4.223974704742432\n",
      "fold: 8, epoch: 0,                       train_loss : 4.103601410275414, valid_loss : 4.726953188578288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:58:26,952]\u001b[0m Trial 157 finished with value: 4.057448744773865 and parameters: {'num_layers': 6, 'hidden_size': 160, 'batch_size': 130, 'learning_rate': 0.004066420393012749}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.107148318063645, valid_loss : 4.169082721074422\n",
      "fold: 0, epoch: 0,                       train_loss : 6.4785233497619625, valid_loss : 6.260424613952637\n",
      "fold: 0, epoch: 1,                       train_loss : 5.977294683456421, valid_loss : 6.278759002685547\n",
      "fold: 0, epoch: 2,                       train_loss : 5.6518801093101505, valid_loss : 5.302494525909424\n",
      "fold: 0, epoch: 3,                       train_loss : 4.883734130859375, valid_loss : 4.250051180521647\n",
      "fold: 0, epoch: 4,                       train_loss : 4.38401335477829, valid_loss : 4.180265744527181\n",
      "fold: 0, epoch: 5,                       train_loss : 3.99908332824707, valid_loss : 4.557066758473714\n",
      "fold: 0, epoch: 6,                       train_loss : 4.329581844806671, valid_loss : 4.134677092234294\n",
      "fold: 0, epoch: 7,                       train_loss : 4.1573392987251285, valid_loss : 3.9208450317382812\n",
      "fold: 0, epoch: 8,                       train_loss : 4.160757434368134, valid_loss : 4.138398329416911\n",
      "fold: 0, epoch: 9,                       train_loss : 4.017436546087265, valid_loss : 3.579935868581136\n",
      "fold: 0, epoch: 10,                       train_loss : 4.0190549969673155, valid_loss : 5.797390858332316\n",
      "fold: 0, epoch: 11,                       train_loss : 4.094973480701446, valid_loss : 3.959305206934611\n",
      "fold: 0, epoch: 12,                       train_loss : 3.966383472084999, valid_loss : 3.928106943766276\n",
      "fold: 0, epoch: 13,                       train_loss : 4.120135939121246, valid_loss : 4.279951413472493\n",
      "fold: 0, epoch: 14,                       train_loss : 4.070019960403442, valid_loss : 4.290542205174764\n",
      "fold: 0, epoch: 15,                       train_loss : 4.480115556716919, valid_loss : 4.669912815093994\n",
      "fold: 0, epoch: 16,                       train_loss : 4.145962774753571, valid_loss : 4.021164099375407\n",
      "fold: 0, epoch: 17,                       train_loss : 4.065437018871307, valid_loss : 4.116325855255127\n",
      "fold: 1, epoch: 0,                       train_loss : 4.046503376960755, valid_loss : 3.51466703414917\n",
      "fold: 2, epoch: 0,                       train_loss : 3.9956325232982635, valid_loss : 4.567940870920817\n",
      "fold: 3, epoch: 0,                       train_loss : 4.126709234714508, valid_loss : 3.771390676498413\n",
      "fold: 4, epoch: 0,                       train_loss : 4.155126392841339, valid_loss : 4.607621192932129\n",
      "fold: 5, epoch: 0,                       train_loss : 4.052041459083557, valid_loss : 4.024062792460124\n",
      "fold: 6, epoch: 0,                       train_loss : 4.054594504833221, valid_loss : 4.3849992752075195\n",
      "fold: 7, epoch: 0,                       train_loss : 3.9944034218788147, valid_loss : 5.504840771357219\n",
      "fold: 8, epoch: 0,                       train_loss : 4.160251581668854, valid_loss : 3.971303145090739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:58:45,790]\u001b[0m Trial 158 finished with value: 4.199532969792684 and parameters: {'num_layers': 3, 'hidden_size': 80, 'batch_size': 140, 'learning_rate': 0.00686046237444854}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.159216320514679, valid_loss : 4.068568070729573\n",
      "fold: 0, epoch: 0,                       train_loss : 6.511760878562927, valid_loss : 6.430034319559733\n",
      "fold: 0, epoch: 1,                       train_loss : 4.791883206367492, valid_loss : 4.426177342732747\n",
      "fold: 0, epoch: 2,                       train_loss : 4.4592576146125795, valid_loss : 4.400594393412272\n",
      "fold: 0, epoch: 3,                       train_loss : 4.025552141666412, valid_loss : 4.339735190073649\n",
      "fold: 0, epoch: 4,                       train_loss : 4.048478090763092, valid_loss : 3.6422725518544516\n",
      "fold: 0, epoch: 5,                       train_loss : 3.997965383529663, valid_loss : 3.7993958791097007\n",
      "fold: 0, epoch: 6,                       train_loss : 4.11705619096756, valid_loss : 3.8167717456817627\n",
      "fold: 0, epoch: 7,                       train_loss : 4.2886369824409485, valid_loss : 4.384452819824219\n",
      "fold: 0, epoch: 8,                       train_loss : 4.173643398284912, valid_loss : 4.201408704121907\n",
      "fold: 0, epoch: 9,                       train_loss : 4.340192985534668, valid_loss : 4.401646852493286\n",
      "fold: 0, epoch: 10,                       train_loss : 4.092530655860901, valid_loss : 4.211276849110921\n",
      "fold: 0, epoch: 11,                       train_loss : 4.050231349468231, valid_loss : 4.766009489695231\n",
      "fold: 0, epoch: 12,                       train_loss : 4.300269913673401, valid_loss : 4.344457308451335\n",
      "fold: 0, epoch: 13,                       train_loss : 4.107850837707519, valid_loss : 4.1921703815460205\n",
      "fold: 0, epoch: 14,                       train_loss : 4.0749574422836305, valid_loss : 3.8884339332580566\n",
      "fold: 0, epoch: 15,                       train_loss : 4.060536170005799, valid_loss : 4.249069531758626\n",
      "fold: 1, epoch: 0,                       train_loss : 4.599504387378692, valid_loss : 3.715986649195353\n",
      "fold: 2, epoch: 0,                       train_loss : 4.43623777627945, valid_loss : 4.319702068964641\n",
      "fold: 3, epoch: 0,                       train_loss : 4.098135530948639, valid_loss : 4.833776791890462\n",
      "fold: 4, epoch: 0,                       train_loss : 4.121074306964874, valid_loss : 3.973982652028402\n",
      "fold: 5, epoch: 0,                       train_loss : 4.002618795633316, valid_loss : 3.9441816806793213\n",
      "fold: 6, epoch: 0,                       train_loss : 4.0091234803199765, valid_loss : 3.7823278109232583\n",
      "fold: 7, epoch: 0,                       train_loss : 4.070516407489777, valid_loss : 4.3311082522074384\n",
      "fold: 8, epoch: 0,                       train_loss : 4.080253458023071, valid_loss : 3.566667159398397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-24 15:58:57,667]\u001b[0m Trial 159 finished with value: 3.8983984390894575 and parameters: {'num_layers': 4, 'hidden_size': 50, 'batch_size': 140, 'learning_rate': 0.010129960355553753}. Best is trial 15 with value: 3.853500247001648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 9, epoch: 0,                       train_loss : 4.078335464000702, valid_loss : 2.873978773752848\n",
      "best_trial:\n",
      "[3.853500247001648]\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_layers' : trial.suggest_int(\"num_layers\",1,6),\n",
    "        \"hidden_size\" : trial.suggest_int(\"hidden_size\",10,190,10),\n",
    "        \"batch_size\" : trial.suggest_int(\"batch_size\", 10,190,10),\n",
    "        \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\",1e-4,0.05),\n",
    "    }\n",
    "    all_losses = run_training(fold = 10 , data = total,params = params, feature=geometric,\n",
    "                              property_ = property_,save_model = True)\n",
    "    \n",
    "    return np.mean(all_losses)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective,n_trials = 160)\n",
    "print(\"best_trial:\")\n",
    "trial_ = study.best_trial\n",
    "\n",
    "print(trial_.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 160\n",
      "Best trial: {'num_layers': 5, 'hidden_size': 80, 'batch_size': 140, 'learning_rate': 0.005948741334654186}\n",
      "best rmse is : [3.853500247001648]\n"
     ]
    }
   ],
   "source": [
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print(\"best rmse is :\",study.best_trial.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([120, 1])) that is different to the input size (torch.Size([120])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/mnt/disk1/jaejun/cyclegan/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([80, 1])) that is different to the input size (torch.Size([80])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0, epoch: 0,                   train_loss : 6.269705810546875, valid_loss : 6.266591291427613\n",
      "fold: 0, epoch: 1,                   train_loss : 6.263493938446045, valid_loss : 6.260414476394653\n",
      "fold: 0, epoch: 2,                   train_loss : 6.257352542877197, valid_loss : 6.254307775497437\n",
      "fold: 0, epoch: 3,                   train_loss : 6.25127950668335, valid_loss : 6.24826756477356\n",
      "fold: 0, epoch: 4,                   train_loss : 6.245271263122558, valid_loss : 6.2422901630401615\n",
      "fold: 0, epoch: 5,                   train_loss : 6.239323978424072, valid_loss : 6.236371974945069\n",
      "fold: 0, epoch: 6,                   train_loss : 6.233433895111084, valid_loss : 6.23050898551941\n",
      "fold: 0, epoch: 7,                   train_loss : 6.227597007751465, valid_loss : 6.224697284698486\n",
      "fold: 0, epoch: 8,                   train_loss : 6.221809329986573, valid_loss : 6.218932638168335\n",
      "fold: 0, epoch: 9,                   train_loss : 6.216066541671753, valid_loss : 6.213210563659668\n",
      "fold: 0, epoch: 10,                   train_loss : 6.21036392211914, valid_loss : 6.207526111602784\n",
      "fold: 0, epoch: 11,                   train_loss : 6.204696416854858, valid_loss : 6.201874198913575\n",
      "fold: 0, epoch: 12,                   train_loss : 6.199058427810669, valid_loss : 6.196248512268067\n",
      "fold: 0, epoch: 13,                   train_loss : 6.193443784713745, valid_loss : 6.190642948150635\n",
      "fold: 0, epoch: 14,                   train_loss : 6.187845611572266, valid_loss : 6.185049886703491\n",
      "fold: 0, epoch: 15,                   train_loss : 6.182255477905273, valid_loss : 6.179460735321045\n",
      "fold: 0, epoch: 16,                   train_loss : 6.176664705276489, valid_loss : 6.173865623474121\n",
      "fold: 0, epoch: 17,                   train_loss : 6.1710625171661375, valid_loss : 6.168253345489502\n",
      "fold: 0, epoch: 18,                   train_loss : 6.165436792373657, valid_loss : 6.162612009048462\n",
      "fold: 0, epoch: 19,                   train_loss : 6.159778366088867, valid_loss : 6.15693208694458\n",
      "fold: 0, epoch: 20,                   train_loss : 6.154070816040039, valid_loss : 6.151192378997803\n",
      "fold: 0, epoch: 21,                   train_loss : 6.148294563293457, valid_loss : 6.145375547409057\n",
      "fold: 0, epoch: 22,                   train_loss : 6.14243314743042, valid_loss : 6.139465322494507\n",
      "fold: 0, epoch: 23,                   train_loss : 6.136469917297363, valid_loss : 6.133445615768433\n",
      "fold: 0, epoch: 24,                   train_loss : 6.130390462875366, valid_loss : 6.127302989959717\n",
      "fold: 0, epoch: 25,                   train_loss : 6.124181890487671, valid_loss : 6.121025838851929\n",
      "fold: 0, epoch: 26,                   train_loss : 6.117833967208862, valid_loss : 6.11460578918457\n",
      "fold: 0, epoch: 27,                   train_loss : 6.111340417861938, valid_loss : 6.108037347793579\n",
      "fold: 0, epoch: 28,                   train_loss : 6.104697570800782, valid_loss : 6.101322727203369\n",
      "fold: 0, epoch: 29,                   train_loss : 6.097910203933716, valid_loss : 6.094459953308106\n",
      "fold: 0, epoch: 30,                   train_loss : 6.0909715843200685, valid_loss : 6.087445907592773\n",
      "fold: 0, epoch: 31,                   train_loss : 6.083882932662964, valid_loss : 6.080283250808716\n",
      "fold: 0, epoch: 32,                   train_loss : 6.076647090911865, valid_loss : 6.07297529220581\n",
      "fold: 0, epoch: 33,                   train_loss : 6.0692679309844975, valid_loss : 6.065525770187378\n",
      "fold: 0, epoch: 34,                   train_loss : 6.06174934387207, valid_loss : 6.057939176559448\n",
      "fold: 0, epoch: 35,                   train_loss : 6.054095697402954, valid_loss : 6.050219850540161\n",
      "fold: 0, epoch: 36,                   train_loss : 6.046311693191528, valid_loss : 6.0423719024658205\n",
      "fold: 0, epoch: 37,                   train_loss : 6.038401384353637, valid_loss : 6.034404296875\n",
      "fold: 0, epoch: 38,                   train_loss : 6.030378360748291, valid_loss : 6.026323451995849\n",
      "fold: 0, epoch: 39,                   train_loss : 6.022242460250855, valid_loss : 6.018135461807251\n",
      "fold: 0, epoch: 40,                   train_loss : 6.014004449844361, valid_loss : 6.009851541519165\n",
      "fold: 0, epoch: 41,                   train_loss : 6.005677480697631, valid_loss : 6.00147852897644\n",
      "fold: 0, epoch: 42,                   train_loss : 5.99725887298584, valid_loss : 5.993017387390137\n",
      "fold: 0, epoch: 43,                   train_loss : 5.988751544952392, valid_loss : 5.984467353820801\n",
      "fold: 0, epoch: 44,                   train_loss : 5.980163173675537, valid_loss : 5.975837736129761\n",
      "fold: 0, epoch: 45,                   train_loss : 5.971494960784912, valid_loss : 5.967137479782105\n",
      "fold: 0, epoch: 46,                   train_loss : 5.962757844924926, valid_loss : 5.958355445861816\n",
      "fold: 0, epoch: 47,                   train_loss : 5.953938436508179, valid_loss : 5.949501113891602\n",
      "fold: 0, epoch: 48,                   train_loss : 5.945047636032104, valid_loss : 5.940580101013183\n",
      "fold: 0, epoch: 49,                   train_loss : 5.93609468460083, valid_loss : 5.931591386795044\n",
      "fold: 0, epoch: 50,                   train_loss : 5.927074460983277, valid_loss : 5.922539587020874\n",
      "fold: 0, epoch: 51,                   train_loss : 5.917983322143555, valid_loss : 5.913413133621216\n",
      "fold: 0, epoch: 52,                   train_loss : 5.908835315704346, valid_loss : 5.904241704940796\n",
      "fold: 0, epoch: 53,                   train_loss : 5.899642353057861, valid_loss : 5.895041589736938\n",
      "fold: 0, epoch: 54,                   train_loss : 5.890427017211914, valid_loss : 5.88579836845398\n",
      "fold: 0, epoch: 55,                   train_loss : 5.881163396835327, valid_loss : 5.876518707275391\n",
      "fold: 0, epoch: 56,                   train_loss : 5.871854343414307, valid_loss : 5.867174224853516\n",
      "fold: 0, epoch: 57,                   train_loss : 5.862483243942261, valid_loss : 5.857781677246094\n",
      "fold: 0, epoch: 58,                   train_loss : 5.853063592910766, valid_loss : 5.848327932357788\n"
     ]
    }
   ],
   "source": [
    "run_training(fold = 10,data = total,params=Best_, feature = geometric,\n",
    "             property_ = property_, save_model = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 5,\n",
       " 'hidden_size': 80,\n",
       " 'batch_size': 140,\n",
       " 'learning_rate': 0.005948741334654186}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'num_layers' : 2,\n",
    "    \"hidden_size\" : 64,\n",
    "    \"batch_size\" : 120,\n",
    "    \"learning_rate\" : 1e-4,\n",
    "}\n",
    "\n",
    "study.best_trial.params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclegan",
   "language": "python",
   "name": "cyclegan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
